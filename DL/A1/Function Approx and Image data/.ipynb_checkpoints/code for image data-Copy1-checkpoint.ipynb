{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['plane.npy', 'ship.npy', 'truck.npy', 'bird.npy', 'horse.npy']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the pretrained model of Vgg_16 which uses batch_normalization\n",
    "net = models.vgg16_bn(pretrained=True)\n",
    "\n",
    "# set the load_path for all image file\n",
    "load_path = './images/'\n",
    "\n",
    "# set the save_path for the extracted features file for all the classes\n",
    "save_path = './Feature_extraction_2D/'\n",
    "#os.mkdir(save_path)\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# will get the names of the files present in the load path\n",
    "# The training data\n",
    "get_class_names = os.listdir(load_path)\n",
    "\n",
    "# for each class file\n",
    "get_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 512)\n"
     ]
    }
   ],
   "source": [
    "for i in get_class_names:\n",
    "    # To save the file with the same name for the extracted features\n",
    "    new_save_path = save_path + i\n",
    "    \n",
    "    # To load the class file\n",
    "    class_path = load_path + i\n",
    "\n",
    "    # to load the numpy file\n",
    "    img = np.load(class_path)\n",
    "\n",
    "    # To append the extracted features\n",
    "    arr = []\n",
    "\n",
    "    # for each image in the class file\n",
    "    for j in img:   \n",
    "\n",
    "        # converting the numpy array to tensor\n",
    "        j = torch.tensor(j)\n",
    "        \n",
    "        # reshaping the image to [batch_size,number_of_channel,height,width]\n",
    "        j = j.view([-1,3,32,32])\n",
    "        \n",
    "        # rescaling the image to [1,3,224,224]\n",
    "        # vgg_net the required input is of size 224*224 and single image so batch size 1 \n",
    "        j = F.interpolate(j,(224,224))\n",
    "        \n",
    "        # Extracting the features from the middle layer of the network\n",
    "        z = net.features(j)\n",
    "        \n",
    "        # Features extracted are of size [1,512,7,7]\n",
    "        # Taking the average pooling for each channel\n",
    "        m = F.avg_pool2d(z,(7,7),1,0)\n",
    "        \n",
    "        # Now the features are of size [1,512,1,1]\n",
    "        #reshaping the features to [512] \n",
    "        m = m.view([-1]).detach()\n",
    "        \n",
    "        # converting it back to numpy array\n",
    "        m = np.asarray(m)\n",
    "\n",
    "        # appending to the arr\n",
    "        arr.append(m)\n",
    "\n",
    "    arr = np.asarray(arr)\n",
    "    print(arr.shape)\n",
    "\n",
    "    # To save the numpy array  \n",
    "    np.save(new_save_path,arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plane.npy', 'ship.npy', 'truck.npy', 'bird.npy', 'horse.npy']\n",
      "0 plane.npy\n",
      "1 ship.npy\n",
      "2 truck.npy\n",
      "3 bird.npy\n",
      "4 horse.npy\n",
      "(1500, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle\n",
    "\n",
    "\n",
    "# To set the load path for the extracted 2d features\n",
    "# Change it to your team number\n",
    "path = './images/'\n",
    "class_names = os.listdir(path)\n",
    "\n",
    "print(class_names)\n",
    "\n",
    "# val is to assign different labels to each class\n",
    "val = 0\n",
    "# To store all the data_points\n",
    "data_points = []\n",
    "# To store all the corresponding class values\n",
    "data_points_class = []\n",
    "\n",
    "# for each class\n",
    "for i in class_names:\n",
    "    \n",
    "    # Load the corresponding class_file\n",
    "    load_name = os.path.join(path,i)\n",
    "    extracted_features = np.load(load_name)\n",
    "    \n",
    "    # for each data_point in the class\n",
    "    for j in extracted_features:\n",
    "        \n",
    "        # store it in the array\n",
    "        data_points.append(j)\n",
    "        # store the corresponding the class value\n",
    "        data_points_class.append(val)\n",
    "    \n",
    "    # The print is to show the corresponding class names and labels assigned to the class labels      \n",
    "    # Note the corresponding labels and class assigned \n",
    "    print(val,i)\n",
    "    val += 1\n",
    "\n",
    "\n",
    "# the stored data points are in a sequence which can affect the model performance\n",
    "# To randomlly shuffle the examples as to maintain the corresponding class label\n",
    "\n",
    "temp = list(zip(data_points,data_points_class))\n",
    "shuffle(temp)\n",
    "\n",
    "\n",
    "data_points,data_points_class = zip(*temp)\n",
    "data_points = np.asanyarray(data_points)\n",
    "data_points_class = np.asanyarray(data_points_class)\n",
    "# The final data_points in one array\n",
    "print(data_points.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim_hidden_1 = 40\n",
    "dim_hidden_2 = 30\n",
    "pca_components = 10\n",
    "C = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data_points, data_points_class,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 4. Estimator expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-099a44768def>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpca1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecomposition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mPCA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca_components\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mpca1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    339\u001b[0m             \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mitself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m         \"\"\"\n\u001b[0;32m--> 341\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/decomposition/pca.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         X = check_array(X, dtype=[np.float64, np.float32], ensure_2d=True,\n\u001b[0;32m--> 382\u001b[0;31m                         copy=self.copy)\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0;31m# Handle n_components==None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mallow_nd\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    538\u001b[0m             raise ValueError(\"Found array with dim %d. %s expected <= 2.\"\n\u001b[0;32m--> 539\u001b[0;31m                              % (array.ndim, estimator_name))\n\u001b[0m\u001b[1;32m    540\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m             _assert_all_finite(array,\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 4. Estimator expected <= 2."
     ]
    }
   ],
   "source": [
    "from sklearn import decomposition\n",
    "\n",
    "pca1 = decomposition.PCA(n_components = pca_components)\n",
    "pca1.fit(X_train)\n",
    "X_train = pca1.transform(X_train)\n",
    "print(X_train.shape)\n",
    "\n",
    "pca2 = decomposition.PCA(n_components = pca_components)\n",
    "pca2.fit(X_test)\n",
    "X_test = pca2.transform(X_test)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "ytrain = Y_train\n",
    "b = np.zeros((Y_train.size, Y_train.max()+1))\n",
    "b[np.arange(Y_train.size),Y_train] = 1\n",
    "Y_train=b\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "   return np.maximum(0,X)\n",
    "import math\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initparameters():\n",
    "  \n",
    " \n",
    "  \n",
    "    W1 = np.random.randn(dim_hidden_1,pca_components) * np.sqrt(2/pca_components)\n",
    "    b1 = np.zeros(shape=(dim_hidden_1, 1))\n",
    "    W2 = np.random.randn(dim_hidden_2, dim_hidden_1) * np.sqrt(2/dim_hidden_1)\n",
    "    b2 = np.zeros(shape=(dim_hidden_2, 1))\n",
    "    W3 = np.random.randn(5, dim_hidden_2) * np.sqrt(2/dim_hidden_2)\n",
    "    b3 = np.zeros(shape=(5, 1))\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3}\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GRADED FUNCTION: compute_cost\n",
    "\n",
    "def compute_cost(A3, Y, parameters):\n",
    "    \n",
    "    \n",
    "    m=1500\n",
    "    \n",
    "    logprobs = np.multiply(np.log(A3), Y) + np.multiply((1 - Y), np.log(1 - A3))\n",
    "    cost = - np.sum(logprobs) / m\n",
    "    cost = float(np.squeeze(cost))\n",
    "    \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_propagation(parameters, cache, X, Y):\n",
    "   \n",
    "    m=1500\n",
    "   \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "        \n",
    "    \n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']\n",
    "    A3 = cache['A3']\n",
    "    \n",
    "    \n",
    "    dZ3 = A3 - Y\n",
    "    dW3 = (1 / m) * np.dot(dZ3, A2.T)\n",
    "    db3 = (1 / m) * np.sum(dZ3, axis=1, keepdims=True)\n",
    "    dZ2 = np.multiply(np.dot(W3.T, dZ3), 1 - np.power(A2, 2))\n",
    "    dW2 = (1 / m) * np.dot(dZ2, A1.T)\n",
    "    db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = np.multiply(np.dot(W2.T, dZ2), 1 - np.power(A1, 2))\n",
    "    dW1 = (1 / m) * np.dot(dZ1, X.T)\n",
    "    db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2,\n",
    "             \"dW3\": dW3,\n",
    "             \"db3\": db3\n",
    "            }\n",
    "    \n",
    "    return grads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_parameters(parameters, grads, learning_rate = 0.8):\n",
    "    \n",
    "    \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Retrieve each gradient from the dictionary \"grads\"\n",
    "    ### START CODE HERE ### (≈ 4 lines of code)\n",
    "    dW1 = grads['dW1']\n",
    "    db1 = grads['db1']\n",
    "    dW2 = grads['dW2']\n",
    "    db2 = grads['db2']\n",
    "    dW3 = grads['dW3']\n",
    "    db3 = grads['db3']\n",
    "    ## END CODE HERE ###\n",
    "    \n",
    "    # Update rule for each parameter\n",
    "    ### START CODE HERE ### (≈ 4 lines of code)\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    W3 = W3 - learning_rate * dW3\n",
    "    b3 = b3 - learning_rate * db3\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3\n",
    "                 }\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_parameters_momentum(parameters, velocity, learning_rate = 0.8):\n",
    "    \n",
    "    \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Retrieve each gradient from the dictionary \"grads\"\n",
    "    ### START CODE HERE ### (≈ 4 lines of code)\n",
    "    dW1 = velocity['vW1']\n",
    "    db1 = velocity['vb1']\n",
    "    dW2 = velocity['vW2']\n",
    "    db2 = velocity['vb2']\n",
    "    dW3 = velocity['vW3']\n",
    "    db3 = velocity['vb3']\n",
    "    ## END CODE HERE ###\n",
    "    \n",
    "    # Update rule for each parameter\n",
    "    ### START CODE HERE ### (≈ 4 lines of code)\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    W3 = W3 - learning_rate * dW3\n",
    "    b3 = b3 - learning_rate * db3\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3\n",
    "                 }\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def update_parameters_adam(parameters, v_corrected, s_corrected,E = 1e-8, learning_rate = 0.8):\n",
    "    \n",
    "    \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    # Retrieve each gradient from the dictionary \"grads\"\n",
    "    ### START CODE HERE ### (≈ 4 lines of code)\n",
    "    dW1 = v_corrected['vW1'] / np.sqrt(s_corrected['vW1'] + E)\n",
    "    db1 = v_corrected['vb1'] / np.sqrt(s_corrected['vb1'] + E)\n",
    "    dW2 = v_corrected['vW2'] / np.sqrt(s_corrected['vW2'] + E)\n",
    "    db2 = v_corrected['vb2'] / np.sqrt(s_corrected['vb2'] + E)\n",
    "    dW3 = v_corrected['vW3'] / np.sqrt(s_corrected['vW3'] + E)\n",
    "    db3 = v_corrected['vb3'] / np.sqrt(s_corrected['vb3'] + E)\n",
    "    ## END CODE HERE ###\n",
    "    \n",
    "    \n",
    "    # Update rule for each parameter\n",
    "    ### START CODE HERE ### (≈ 4 lines of code)\n",
    "    W1 = W1 - learning_rate * dW1\n",
    "    b1 = b1 - learning_rate * db1\n",
    "    W2 = W2 - learning_rate * dW2\n",
    "    b2 = b2 - learning_rate * db2\n",
    "    W3 = W3 - learning_rate * dW3\n",
    "    b3 = b3 - learning_rate * db3\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    parameters = {\"W1\": W1,\n",
    "                  \"b1\": b1,\n",
    "                  \"W2\": W2,\n",
    "                  \"b2\": b2,\n",
    "                  \"W3\": W3,\n",
    "                  \"b3\": b3\n",
    "                 }\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_propagation(X, parameters):\n",
    "    \n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "   \n",
    "    \n",
    "    \n",
    "    Z1 = np.dot(W1, X) + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    \n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = np.tanh(Z2)\n",
    "    \n",
    "    Z3 = np.dot(W3, A2) + b3\n",
    "    A3 = sigmoid(Z3)\n",
    "    \n",
    "   \n",
    "    \n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2,\n",
    "             \"A3\": A3,\n",
    "             \"Z3 \":Z3}\n",
    "    \n",
    "    return A3, cache\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# GRADED FUNCTION: nn_model\n",
    "\n",
    "def nn_model(X, Y, parameters, learning_rate, num_iterations = 30000, print_cost=False,optmethod = 0,beta = 0.9, gamma = 0.99):\n",
    "    \n",
    "    # Loop (gradient descent)\n",
    "    costs=[]\n",
    "    velocity = {\"vW1\": np.zeros_like(parameters['W1']),\n",
    "             \"vb1\": np.zeros_like(parameters['b1']),\n",
    "             \"vW2\": np.zeros_like(parameters['W2']),\n",
    "             \"vb2\": np.zeros_like(parameters['b2']),\n",
    "             \"vW3\": np.zeros_like(parameters['W3']),\n",
    "             \"vb3\": np.zeros_like(parameters['b3'])\n",
    "            }\n",
    "    \n",
    "    rms_prop = {\"vW1\": np.zeros_like(parameters['W1']),\n",
    "             \"vb1\": np.zeros_like(parameters['b1']),\n",
    "             \"vW2\": np.zeros_like(parameters['W2']),\n",
    "             \"vb2\": np.zeros_like(parameters['b2']),\n",
    "             \"vW3\": np.zeros_like(parameters['W3']),\n",
    "             \"vb3\": np.zeros_like(parameters['b3'])\n",
    "            }\n",
    "    \n",
    "    t = 0\n",
    "    \n",
    "    for i in range(0, num_iterations):\n",
    "         \n",
    "        \n",
    "        # Forward propagation. Inputs: \"X, parameters\". Outputs: \"A2, cache\".\n",
    "        A3,cache = forward_propagation(X, parameters)\n",
    "        \n",
    "        # Cost function. Inputs: \"A2, Y, parameters\". Outputs: \"cost\".\n",
    "        cost = compute_cost(A3,Y,parameters)\n",
    "        if i % 100 == 0:\n",
    "            costs.append(cost)\n",
    "\n",
    "        # Backpropagation. Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\n",
    "        grads = backward_propagation(parameters, cache, X, Y)\n",
    " \n",
    "        #print(\"GRADS : \",grads)\n",
    "        \n",
    "        # Gradient descent parameter update. Inputs: \"parameters, grads\". Outputs: \"parameters\".\n",
    "        if(optmethod == 0):\n",
    "            parameters = update_parameters(parameters, grads,learning_rate)\n",
    "       \n",
    "        else:\n",
    "            velocity['vW1'] = beta * velocity['vW1'] + (1 - beta) * grads['dW1']\n",
    "            velocity['vb1'] = beta * velocity['vb1'] + (1 - beta) * grads['db1']\n",
    "            velocity['vW2'] = beta * velocity['vW2'] + (1 - beta) * grads['dW2']\n",
    "            velocity['vb2'] = beta * velocity['vb2'] + (1 - beta) * grads['db2']\n",
    "            velocity['vW3'] = beta * velocity['vW3'] + (1 - beta) * grads['dW3']\n",
    "            velocity['vb3'] = beta * velocity['vb3'] + (1 - beta) * grads['db3']\n",
    "            \n",
    "            if(optmethod == 1):\n",
    "                parameters = update_parameters_momentum(parameters, velocity , learning_rate)\n",
    "            else:\n",
    "                rms_prop['vW1'] = gamma * rms_prop['vW1'] + (1 - gamma) * np.power(grads['dW1'],2)\n",
    "                rms_prop['vb1'] = gamma * rms_prop['vb1'] + (1 - gamma) * np.power(grads['db1'],2)\n",
    "                rms_prop['vW2'] = gamma * rms_prop['vW2'] + (1 - gamma) * np.power(grads['dW2'],2)\n",
    "                rms_prop['vb2'] = gamma * rms_prop['vb2'] + (1 - gamma) * np.power(grads['db2'],2)\n",
    "                rms_prop['vW3'] = gamma * rms_prop['vW3'] + (1 - gamma) * np.power(grads['dW3'],2)\n",
    "                rms_prop['vb3'] = gamma * rms_prop['vb3'] + (1 - gamma) * np.power(grads['db3'],2)\n",
    "                \n",
    "                E = 1e-08\n",
    "                \n",
    "                v_correct = {\"vW1\": np.zeros_like(parameters['W1']),\n",
    "                \"vb1\": np.zeros_like(parameters['b1']),\n",
    "                \"vW2\": np.zeros_like(parameters['W2']),\n",
    "                \"vb2\": np.zeros_like(parameters['b2']),\n",
    "                \"vW3\": np.zeros_like(parameters['W3']),\n",
    "                \"vb3\": np.zeros_like(parameters['b3'])\n",
    "                }\n",
    "                \n",
    "                s_correct = {\"vW1\": np.zeros_like(parameters['W1']),\n",
    "                \"vb1\": np.zeros_like(parameters['b1']),\n",
    "                \"vW2\": np.zeros_like(parameters['W2']),\n",
    "                \"vb2\": np.zeros_like(parameters['b2']),\n",
    "                \"vW3\": np.zeros_like(parameters['W3']),\n",
    "                \"vb3\": np.zeros_like(parameters['b3'])\n",
    "                }\n",
    "                \n",
    "                t = t + 1\n",
    "                \n",
    "                v_correct['vW1'] = velocity['vW1']/(1 - np.power(beta,t))\n",
    "                v_correct['vb1'] = velocity['vb1']/(1 - np.power(beta,t))\n",
    "                v_correct['vW2'] = velocity['vW2']/(1 - np.power(beta,t))\n",
    "                v_correct['vb2'] = velocity['vb2']/(1 - np.power(beta,t))\n",
    "                v_correct['vW3'] = velocity['vW3']/(1 - np.power(beta,t))\n",
    "                v_correct['vb3'] = velocity['vb3']/(1 - np.power(beta,t))\n",
    "            \n",
    "                s_correct['vW1'] = rms_prop['vW1']/(1 - np.power(gamma,t))\n",
    "                s_correct['vb1'] = rms_prop['vb1']/(1 - np.power(gamma,t))\n",
    "                s_correct['vW2'] = rms_prop['vW2']/(1 - np.power(gamma,t))\n",
    "                s_correct['vb2'] = rms_prop['vb2']/(1 - np.power(gamma,t))\n",
    "                s_correct['vW3'] = rms_prop['vW3']/(1 - np.power(gamma,t))\n",
    "                s_correct['vb3'] = rms_prop['vb3']/(1 - np.power(gamma,t))\n",
    "                \n",
    "                parameters = update_parameters_adam(parameters, v_correct, s_correct,E = 1e-8, learning_rate = learning_rate)\n",
    "            \n",
    "                \n",
    "        if(i%1000==0):\n",
    "            print(\"cost \",cost)\n",
    "        ### END CODE HERE ###\n",
    "        \n",
    "        if(cost < 0.3):\n",
    "            break\n",
    "        \n",
    "        # Print the cost every 1000 iterations\n",
    "        \n",
    "            \n",
    "    return parameters,costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(parameters, X):\n",
    "    \"\"\"\n",
    "    Using the learned parameters, predicts a class for each example in X\n",
    "    \n",
    "    Arguments:\n",
    "    parameters -- python dictionary containing your parameters \n",
    "    X -- input data of size (n_x, m)\n",
    "    \n",
    "    Returns\n",
    "    predictions -- vector of predictions of our model (red: 0 / blue: 1)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Computes probabilities using forward propagation, and classifies to 0/1 using 0.5 as the threshold.\n",
    "    ### START CODE HERE ### (≈ 2 lines of code)\n",
    "    \n",
    "    A2, cache = forward_propagation(X, parameters)\n",
    "    predictions = np.argmax(A2,axis=0)\n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = initparameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost  2.7863550926175553\n",
      "cost  0.4419913909965612\n"
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "parameters,costs = nn_model(X_train.T, Y_train.T, params, lr,  num_iterations = 30000, print_cost=True,optmethod = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=predict(parameters, X_train.T)\n",
    "pred2=predict(parameters, X_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accuracy = 0.9708333333333333\n",
      "test accuracy = 0.23\n"
     ]
    }
   ],
   "source": [
    "count=0\n",
    "i=0\n",
    "while i<1200:\n",
    "    if(pred[i]==ytrain[i]):\n",
    "        count=count+1\n",
    "    i=i+1\n",
    "print(\"train accuracy =\",count/1200)\n",
    "\n",
    "count=0\n",
    "i=0\n",
    "while i<300:\n",
    "    if(pred2[i]==Y_test[i]):\n",
    "        count=count+1\n",
    "    i=i+1\n",
    "print(\"test accuracy =\",count/300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost  2.7863550926175553\n",
      "cost  1.990823338914957\n",
      "cost  1.9838288939214364\n",
      "cost  1.9784904238717924\n",
      "cost  1.9740885988876058\n",
      "cost  1.970493832796621\n",
      "cost  1.967630309776208\n",
      "cost  1.9653899610919832\n",
      "cost  1.9636448670122582\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-f3db4d4561fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.01\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcosts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mnum_iterations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_cost\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-48-88b24eeb7dba>\u001b[0m in \u001b[0;36mnn_model\u001b[0;34m(X, Y, parameters, learning_rate, num_iterations, print_cost, optmethod, beta, gamma)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[0;31m# Backpropagation. Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m         \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackward_propagation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m#print(\"GRADS : \",grads)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-fe8f5de84ce7>\u001b[0m in \u001b[0;36mbackward_propagation\u001b[0;34m(parameters, cache, X, Y)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mdW3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mdb3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdZ2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdZ3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mdW2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mdb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "lr = 0.01\n",
    "parameters,costs = nn_model(X_train.T, Y_train.T, params, lr,  num_iterations = 30000, print_cost=True, optmethod = 1, beta = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=predict(parameters, X_train.T)\n",
    "pred2=predict(parameters, X_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "i=0\n",
    "while i<1200:\n",
    "    if(pred[i]==ytrain[i]):\n",
    "        count=count+1\n",
    "    i=i+1\n",
    "print(\"train accuracy =\",count/1200)\n",
    "\n",
    "count=0\n",
    "i=0\n",
    "while i<300:\n",
    "    if(pred2[i]==Y_test[i]):\n",
    "        count=count+1\n",
    "    i=i+1\n",
    "print(\"test accuracy =\",count/300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "parameters,costs = nn_model(X_train.T, Y_train.T, params, lr,  num_iterations = 30000, print_cost=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred=predict(parameters, X_train.T)\n",
    "pred2=predict(parameters, X_test.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count=0\n",
    "i=0\n",
    "while i<1200:\n",
    "    if(pred[i]==ytrain[i]):\n",
    "        count=count+1\n",
    "    i=i+1\n",
    "print(\"train accuracy =\",count/1200)\n",
    "\n",
    "count=0\n",
    "i=0\n",
    "while i<300:\n",
    "    if(pred2[i]==Y_test[i]):\n",
    "        count=count+1\n",
    "    i=i+1\n",
    "print(\"test accuracy =\",count/300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
