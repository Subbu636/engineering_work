{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "\n",
    "# loading the pretrained model of Vgg_16 which uses batch_normalization\n",
    "net = models.vgg16_bn(pretrained=True)\n",
    "\n",
    "# set the load_path for all image file\n",
    "load_path = './images/'\n",
    "\n",
    "# set the save_path for the extracted features file for all the classes\n",
    "save_path = './Feature_extraction_2D/'\n",
    "#os.mkdir(save_path)\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# will get the names of the files present in the load path\n",
    "# The training data\n",
    "get_class_names = os.listdir(load_path)\n",
    "\n",
    "# for each class file\n",
    "get_class_names\n",
    "\n",
    "for i in get_class_names:\n",
    "    # To save the file with the same name for the extracted features\n",
    "    new_save_path = save_path + i\n",
    "    \n",
    "    # To load the class file\n",
    "    class_path = load_path + i\n",
    "\n",
    "    # to load the numpy file\n",
    "    img = np.load(class_path)\n",
    "\n",
    "    # To append the extracted features\n",
    "    arr = []\n",
    "\n",
    "    # for each image in the class file\n",
    "    for j in img:   \n",
    "\n",
    "        # converting the numpy array to tensor\n",
    "        j = torch.tensor(j)\n",
    "        \n",
    "        # reshaping the image to [batch_size,number_of_channel,height,width]\n",
    "        j = j.view([-1,3,32,32])\n",
    "        \n",
    "        # rescaling the image to [1,3,224,224]\n",
    "        # vgg_net the required input is of size 224*224 and single image so batch size 1 \n",
    "        j = F.interpolate(j,(224,224))\n",
    "        \n",
    "        # Extracting the features from the middle layer of the network\n",
    "        z = net.features(j)\n",
    "        \n",
    "        # Features extracted are of size [1,512,7,7]\n",
    "        # Taking the average pooling for each channel\n",
    "        m = F.avg_pool2d(z,(7,7),1,0)\n",
    "        \n",
    "        # Now the features are of size [1,512,1,1]\n",
    "        #reshaping the features to [512] \n",
    "        m = m.view([-1]).detach()\n",
    "        \n",
    "        # converting it back to numpy array\n",
    "        m = np.asarray(m)\n",
    "\n",
    "        # appending to the arr\n",
    "        arr.append(m)\n",
    "\n",
    "    arr = np.asarray(arr)\n",
    "    print(arr.shape)\n",
    "\n",
    "    # To save the numpy array  \n",
    "    np.save(new_save_path,arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pretty plot confusion matrix\n",
    "\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib.collections import QuadMesh\n",
    "import seaborn as sn\n",
    "import warnings\n",
    "\n",
    "\n",
    "def get_new_fig(fn, figsize=[9,9]):\n",
    "    \"\"\" Init graphics \"\"\"\n",
    "    fig1 = plt.figure(fn, figsize)\n",
    "    ax1 = fig1.gca()   #Get Current Axis\n",
    "    ax1.cla() # clear existing plot\n",
    "    return fig1, ax1\n",
    "#\n",
    "\n",
    "def configcell_text_and_colors(array_df, lin, col, oText, facecolors, posi, fz, fmt, show_null_values=0):\n",
    "    \"\"\"\n",
    "      config cell text and colors\n",
    "      and return text elements to add and to dell\n",
    "      @TODO: use fmt\n",
    "    \"\"\"\n",
    "    text_add = []; text_del = [];\n",
    "    cell_val = array_df[lin][col]\n",
    "    tot_all = array_df[-1][-1]\n",
    "    per = (float(cell_val) / tot_all) * 100\n",
    "    curr_column = array_df[:,col]\n",
    "    ccl = len(curr_column)\n",
    "\n",
    "    #last line  and/or last column\n",
    "    if(col == (ccl - 1)) or (lin == (ccl - 1)):\n",
    "        #tots and percents\n",
    "        if(cell_val != 0):\n",
    "            if(col == ccl - 1) and (lin == ccl - 1):\n",
    "                tot_rig = 0\n",
    "                for i in range(array_df.shape[0] - 1):\n",
    "                    tot_rig += array_df[i][i]\n",
    "                per_ok = (float(tot_rig) / cell_val) * 100\n",
    "            elif(col == ccl - 1):\n",
    "                tot_rig = array_df[lin][lin]\n",
    "                per_ok = (float(tot_rig) / cell_val) * 100\n",
    "            elif(lin == ccl - 1):\n",
    "                tot_rig = array_df[col][col]\n",
    "                per_ok = (float(tot_rig) / cell_val) * 100\n",
    "            per_err = 100 - per_ok\n",
    "        else:\n",
    "            per_ok = per_err = 0\n",
    "\n",
    "        per_ok_s = ['%.2f%%'%(per_ok), '100%'] [per_ok == 100]\n",
    "\n",
    "        #text to DEL\n",
    "        text_del.append(oText)\n",
    "\n",
    "        #text to ADD\n",
    "        font_prop = fm.FontProperties(weight='bold', size=fz)\n",
    "        text_kwargs = dict(color='w', ha=\"center\", va=\"center\", gid='sum', fontproperties=font_prop)\n",
    "        lis_txt = ['%d'%(cell_val), per_ok_s, '%.2f%%'%(per_err)]\n",
    "        lis_kwa = [text_kwargs]\n",
    "        dic = text_kwargs.copy(); dic['color'] = 'g'; lis_kwa.append(dic);\n",
    "        dic = text_kwargs.copy(); dic['color'] = 'r'; lis_kwa.append(dic);\n",
    "        lis_pos = [(oText._x, oText._y-0.3), (oText._x, oText._y), (oText._x, oText._y+0.3)]\n",
    "        for i in range(len(lis_txt)):\n",
    "            newText = dict(x=lis_pos[i][0], y=lis_pos[i][1], text=lis_txt[i], kw=lis_kwa[i])\n",
    "            #print 'lin: %s, col: %s, newText: %s' %(lin, col, newText)\n",
    "            text_add.append(newText)\n",
    "        #print '\\n'\n",
    "\n",
    "        #set background color for sum cells (last line and last column)\n",
    "        carr = [0.27, 0.30, 0.27, 1.0]\n",
    "        if(col == ccl - 1) and (lin == ccl - 1):\n",
    "            carr = [0.17, 0.20, 0.17, 1.0]\n",
    "        facecolors[posi] = carr\n",
    "\n",
    "    else:\n",
    "        if(per > 0):\n",
    "            txt = '%s\\n%.2f%%' %(cell_val, per)\n",
    "        else:\n",
    "            if(show_null_values == 0):\n",
    "                txt = ''\n",
    "            elif(show_null_values == 1):\n",
    "                txt = '0'\n",
    "            else:\n",
    "                txt = '0\\n0.0%'\n",
    "        oText.set_text(txt)\n",
    "\n",
    "        #main diagonal\n",
    "        if(col == lin):\n",
    "            #set color of the textin the diagonal to white\n",
    "            oText.set_color('w')\n",
    "            # set background color in the diagonal to blue\n",
    "            facecolors[posi] = [0.35, 0.8, 0.55, 1.0]\n",
    "        else:\n",
    "            oText.set_color('r')\n",
    "\n",
    "    return text_add, text_del\n",
    "#\n",
    "\n",
    "def insert_totals(df_cm):\n",
    "    \"\"\" insert total column and line (the last ones) \"\"\"\n",
    "    sum_col = []\n",
    "    for c in df_cm.columns:\n",
    "        sum_col.append( df_cm[c].sum() )\n",
    "    sum_lin = []\n",
    "    for item_line in df_cm.iterrows():\n",
    "        sum_lin.append( item_line[1].sum() )\n",
    "    df_cm['sum_lin'] = sum_lin\n",
    "    sum_col.append(np.sum(sum_lin))\n",
    "    df_cm.loc['sum_col'] = sum_col\n",
    "    #print ('\\ndf_cm:\\n', df_cm, '\\n\\b\\n')\n",
    "#\n",
    "\n",
    "def pretty_plot_confusion_matrix(df_cm,st,annot=True, cmap=\"Oranges\", fmt='.2f', fz=20,\n",
    "      lw=0.5, cbar=False, figsize=[8,8], show_null_values=0, pred_val_axis='y'):\n",
    "    \"\"\"\n",
    "      print conf matrix with default layout (like matlab)\n",
    "      params:\n",
    "        df_cm          dataframe (pandas) without totals\n",
    "        annot          print text in each cell\n",
    "        cmap           Oranges,Oranges_r,YlGnBu,Blues,RdBu, ... see:\n",
    "        fz             fontsize\n",
    "        lw             linewidth\n",
    "        pred_val_axis  where to show the prediction values (x or y axis)\n",
    "                        'col' or 'x': show predicted values in columns (x axis) instead lines\n",
    "                        'lin' or 'y': show predicted values in lines   (y axis)\n",
    "    \"\"\"\n",
    "    if(pred_val_axis in ('col', 'x')):\n",
    "        xlbl = 'Predicted'\n",
    "        ylbl = 'Actual'\n",
    "    else:\n",
    "        xlbl = 'Actual'\n",
    "        ylbl = 'Predicted'\n",
    "        df_cm = df_cm.T\n",
    "\n",
    "    # create \"Total\" column\n",
    "    insert_totals(df_cm)\n",
    "\n",
    "    #this is for print allways in the same window\n",
    "    fig, ax1 = get_new_fig('Conf matrix default', figsize)\n",
    "\n",
    "    #thanks for seaborn\n",
    "    ax = sn.heatmap(df_cm, annot=annot, annot_kws={\"size\": fz}, linewidths=lw, ax=ax1,\n",
    "                    cbar=cbar, cmap=cmap, linecolor='w', fmt=fmt)\n",
    "\n",
    "    #set ticklabels rotation\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation = 45, fontsize = 15)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation = 25, fontsize = 15)\n",
    "\n",
    "    # Turn off all the ticks\n",
    "    for t in ax.xaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "    for t in ax.yaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "\n",
    "    #face colors list\n",
    "    quadmesh = ax.findobj(QuadMesh)[0]\n",
    "    facecolors = quadmesh.get_facecolors()\n",
    "\n",
    "    #iter in text elements\n",
    "    array_df = np.array( df_cm.to_records(index=False).tolist() )\n",
    "    text_add = []; text_del = [];\n",
    "    posi = -1 #from left to right, bottom to top.\n",
    "    for t in ax.collections[0].axes.texts: #ax.texts:\n",
    "        pos = np.array( t.get_position()) - [0.5,0.5]\n",
    "        lin = int(pos[1]); col = int(pos[0]);\n",
    "        posi += 1\n",
    "        #print ('>>> pos: %s, posi: %s, val: %s, txt: %s' %(pos, posi, array_df[lin][col], t.get_text()))\n",
    "\n",
    "        #set text\n",
    "        txt_res = configcell_text_and_colors(array_df, lin, col, t, facecolors, posi, fz, fmt, show_null_values)\n",
    "\n",
    "        text_add.extend(txt_res[0])\n",
    "        text_del.extend(txt_res[1])\n",
    "\n",
    "    #remove the old ones\n",
    "    for item in text_del:\n",
    "        item.remove()\n",
    "    #append the new ones\n",
    "    for item in text_add:\n",
    "        ax.text(item['x'], item['y'], item['text'], **item['kw'])\n",
    "\n",
    "    #titles and legends\n",
    "    ax.set_title('Confusion matrix for'+st)\n",
    "    ax.set_xlabel(xlbl)\n",
    "    ax.set_ylabel(ylbl)\n",
    "    plt.ylim([len(df_cm), -.5])\n",
    "    plt.tight_layout()  #set layout slim\n",
    "    plt.show()\n",
    "#\n",
    "\n",
    "def plot_confusion_matrix_from_data(y_test,st,predictions, columns=None, annot=True, cmap=\"Oranges\",\n",
    "      fmt='.2f', fz=20, lw=0.5, cbar=False, figsize=[8,8], show_null_values=0, pred_val_axis='lin'):\n",
    "    \"\"\"\n",
    "        plot confusion matrix function with y_test (actual values) and predictions (predic),\n",
    "        whitout a confusion matrix yet\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from pandas import DataFrame\n",
    "\n",
    "    #data\n",
    "    if(not columns):\n",
    "        #labels axis integer:\n",
    "        ##columns = range(1, len(np.unique(y_test))+1)\n",
    "        #labels axis string:\n",
    "        from string import ascii_uppercase\n",
    "        columns = ['class %s' %(i) for i in list(ascii_uppercase)[0:len(np.unique(y_test))]]\n",
    "\n",
    "    confm = confusion_matrix(y_test, predictions)\n",
    "    cmap = 'Oranges';\n",
    "    fz = 20;\n",
    "    figsize=[9,9];\n",
    "    show_null_values = 2\n",
    "    df_cm = DataFrame(confm, index=columns, columns=columns)\n",
    "    pretty_plot_confusion_matrix(df_cm,st,fz=fz, cmap=cmap, figsize=figsize, show_null_values=show_null_values, pred_val_axis=pred_val_axis)\n",
    "#\n",
    "\n",
    "def the_plot_conf(test,pred,st):\n",
    "    \"\"\" test function with y_test (actual values) and predictions (predic) \"\"\"\n",
    "    #data\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    y_test = np.array(test)\n",
    "    predic = np.array(pred)\n",
    "    \"\"\"\n",
    "      Examples to validate output (confusion matrix plot)\n",
    "        actual: 5 and prediction 1   >>  3\n",
    "        actual: 2 and prediction 4   >>  1\n",
    "        actual: 3 and prediction 4   >>  10\n",
    "    \"\"\"\n",
    "    columns = []\n",
    "    annot = True;\n",
    "    cmap = 'Oranges';\n",
    "    fmt = '.2f'\n",
    "    lw = 0.5\n",
    "    cbar = False\n",
    "    show_null_values = 2\n",
    "    pred_val_axis = 'y'\n",
    "    #size::\n",
    "    fz = 20;\n",
    "    figsize = [9,9];\n",
    "    if(len(y_test) > 10):\n",
    "        fz=20; figsize=[14,14];\n",
    "    plot_confusion_matrix_from_data(y_test,\" \"+st,predic, columns,\n",
    "      annot, cmap, fmt, fz, lw, cbar, figsize, show_null_values, pred_val_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['truck.npy', 'plane.npy', 'ship.npy', 'bird.npy', 'horse.npy']\n"
     ]
    }
   ],
   "source": [
    "path = './Feature_extraction_2D/'\n",
    "class_names = os.listdir(path)\n",
    "\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 truck.npy\n",
      "1 plane.npy\n",
      "2 ship.npy\n",
      "3 bird.npy\n",
      "4 horse.npy\n"
     ]
    }
   ],
   "source": [
    "val = 0\n",
    "data_points = []\n",
    "data_points_class = []\n",
    "for i in class_names:\n",
    "    load_name = os.path.join(path,i)\n",
    "    extracted_features = np.load(load_name)\n",
    "    for j in extracted_features:\n",
    "        data_points.append(j)\n",
    "        data_points_class.append(val)\n",
    "    print(val,i)\n",
    "    val += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2 3 3 ... 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "temp = list(zip(data_points,data_points_class))\n",
    "shuffle(temp)\n",
    "\n",
    "data_points,data_points_class = zip(*temp)\n",
    "data_points = np.asanyarray(data_points)\n",
    "data_points_class = np.asanyarray(data_points_class)\n",
    "print(data_points_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 512)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting nodes\n",
    "\n",
    "dim_hidden_1 = 40\n",
    "dim_hidden_2 = 28\n",
    "pca_components = 512\n",
    "C = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data_points, data_points_class,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import decomposition\n",
    "\n",
    "# pca1 = decomposition.PCA(n_components = pca_components)\n",
    "# pca1.fit(X_train)\n",
    "# X_train = pca1.transform(X_train)\n",
    "# print(X_train.shape)\n",
    "\n",
    "# pca2 = decomposition.PCA(n_components = pca_components)\n",
    "# pca2.fit(X_test)\n",
    "# X_test = pca2.transform(X_test)\n",
    "# print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " ...\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "ytrain = Y_train\n",
    "b = np.zeros((Y_train.size, Y_train.max()+1))\n",
    "b[np.arange(Y_train.size),Y_train] = 1\n",
    "Y_train=b\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Initialization and Parameters\n",
    "\n",
    "\n",
    "learning_rate=0.001\n",
    "learning_Rate=0.001\n",
    "num_iterations=60000\n",
    "delta_cost = 1e-8\n",
    "beta = 0.9\n",
    "gamma = 0.99\n",
    "m=1200\n",
    "lam=0.4\n",
    "A_W1 = np.random.randn(dim_hidden_1,pca_components) * np.sqrt(2/pca_components)\n",
    "A_b1 = np.zeros(shape=(dim_hidden_1, 1))\n",
    "A_W2 = np.random.randn(dim_hidden_2, dim_hidden_1) * np.sqrt(2/dim_hidden_1)\n",
    "A_b2 = np.zeros(shape=(dim_hidden_2, 1))\n",
    "A_W3 = np.random.randn(5, dim_hidden_2) * np.sqrt(2/dim_hidden_2)\n",
    "A_b3 = np.zeros(shape=(5, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost 0.0 3.5420543184832893\n"
     ]
    }
   ],
   "source": [
    "opcode = 2\n",
    "\n",
    "W1=A_W1\n",
    "W2=A_W2\n",
    "W3=A_W3\n",
    "b1=A_b1\n",
    "b2=A_b2\n",
    "b3=A_b3\n",
    "\n",
    "costs=[]\n",
    "cost = 0\n",
    "vW1 = np.zeros_like(W1)\n",
    "vW2 = np.zeros_like(W2)\n",
    "vW3 = np.zeros_like(W3)\n",
    "vb1 = np.zeros_like(b1)\n",
    "vb2 = np.zeros_like(b2)\n",
    "vb3 = np.zeros_like(b3)\n",
    "\n",
    "rvW1 = np.zeros_like(W1)\n",
    "rvW2 = np.zeros_like(W2)\n",
    "rvW3 = np.zeros_like(W3)\n",
    "rvb1 = np.zeros_like(b1)\n",
    "rvb2 = np.zeros_like(b2)\n",
    "rvb3 = np.zeros_like(b3)\n",
    "\n",
    "# Training\n",
    "\n",
    "for i in range(0, num_iterations):\n",
    "# forward prop   \n",
    "    Z1 = np.dot(W1, X_train.T) + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    \n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = np.tanh(Z2)\n",
    "    \n",
    "    Z3 = np.dot(W3, A2) + b3\n",
    "    A3 = sigmoid(Z3)\n",
    "    \n",
    "#  cost    \n",
    "    prev_cost = cost\n",
    "    logprobs = np.multiply(np.log(A3), Y_train.T) + np.multiply((1 - Y_train.T), np.log(1 - A3))\n",
    "    cost =( - np.sum(logprobs) / m)+(lam * (np.sum(np.square(W1)) + np.sum(np.square(W2)) + np.sum(np.square(W3))) / (2 * m))\n",
    "    cost = float(np.squeeze(cost))\n",
    "    if i % 100 == 0:\n",
    "        costs.append(cost)\n",
    "\n",
    "# back prop\n",
    "    dZ3 = A3 - Y_train.T\n",
    "    dW3 = (1 / m) * np.dot(dZ3, A2.T)+((lam* W3) / m)\n",
    "    db3 = (1 / m) * np.sum(dZ3, axis=1, keepdims=True)\n",
    "    dZ2 = np.multiply(np.dot(W3.T, dZ3), 1 - np.power(A2, 2))\n",
    "    dW2 = (1 / m) * np.dot(dZ2, A1.T)+((lam * W2) / m)\n",
    "    db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = np.multiply(np.dot(W2.T, dZ2), 1 - np.power(A1, 2))\n",
    "    dW1 = (1 / m) * np.dot(dZ1, X_train)+(lam * W1) / m\n",
    "    db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    if(opcode == 0):\n",
    "        \n",
    "        W1 = W1 - learning_rate * dW1\n",
    "        b1 = b1 - learning_rate * db1\n",
    "        W2 = W2 - learning_rate * dW2\n",
    "        b2 = b2 - learning_rate * db2\n",
    "        W3 = W3 - learning_rate * dW3\n",
    "        b3 = b3 - learning_rate * db3\n",
    "        \n",
    "    else:\n",
    "        vW1 = beta * vW1 + (1 - beta) * dW1\n",
    "        vb1 = beta * vb1 + (1 - beta) * db1\n",
    "        vW2 = beta * vW2 + (1 - beta) * dW2\n",
    "        vb2 = beta * vb2 + (1 - beta) * db2\n",
    "        vW3 = beta * vW3 + (1 - beta) * dW3\n",
    "        vb3 = beta * vb3 + (1 - beta) * db3\n",
    "        if(opcode == 1):\n",
    "            \n",
    "            dW1 = vW1\n",
    "            db1 = vb1\n",
    "            dW2 = vW2\n",
    "            db2 = vb2\n",
    "            dW3 = vW3\n",
    "            db3 = vb3\n",
    "            \n",
    "            W1 = W1 - learning_rate * dW1\n",
    "            b1 = b1 - learning_rate * db1\n",
    "            W2 = W2 - learning_rate * dW2\n",
    "            b2 = b2 - learning_rate * db2\n",
    "            W3 = W3 - learning_rate * dW3\n",
    "            b3 = b3 - learning_rate * db3\n",
    "            \n",
    "        else:\n",
    "            rvW1 = gamma * rvW1 + (1 - gamma) * np.power(dW1,2)\n",
    "            rvb1 = gamma * rvb1 + (1 - gamma) * np.power(db1,2)\n",
    "            rvW2 = gamma * rvW2 + (1 - gamma) * np.power(dW2,2)\n",
    "            rvb2 = gamma * rvb2 + (1 - gamma) * np.power(db2,2)\n",
    "            rvW3 = gamma * rvW3 + (1 - gamma) * np.power(dW3,2)\n",
    "            rvb3 = gamma * rvb3 + (1 - gamma) * np.power(db3,2)\n",
    "\n",
    "            E = 1e-08\n",
    "            \n",
    "            vvW1=np.zeros_like(W1)\n",
    "            vvW2=np.zeros_like(W2)\n",
    "            vvW3=np.zeros_like(W3)\n",
    "            vvb1=np.zeros_like(b1)\n",
    "            vvb2=np.zeros_like(b2)\n",
    "            vvb3=np.zeros_like(b3)\n",
    "            \n",
    "            svW1=np.zeros_like(W1)\n",
    "            svW2=np.zeros_like(W2)\n",
    "            svW3=np.zeros_like(W3)\n",
    "            svb1=np.zeros_like(b1)\n",
    "            svb2=np.zeros_like(b2)\n",
    "            svb3=np.zeros_like(b3)\n",
    "\n",
    "\n",
    "            vvW1 = vW1/(1 - np.power(beta,(i+1)))\n",
    "            vvb1 = vb1/(1 - np.power(beta,(i+1)))\n",
    "            vvW2 = vW2/(1 - np.power(beta,(i+1)))\n",
    "            vvb2 = vb2/(1 - np.power(beta,(i+1)))\n",
    "            vvW3 = vW3/(1 - np.power(beta,(i+1)))\n",
    "            vvb3 = vb3/(1 - np.power(beta,(i+1)))\n",
    "\n",
    "            svW1 = rvW1/(1 - np.power(gamma,(i+1)))\n",
    "            svb1 = rvb1/(1 - np.power(gamma,(i+1)))\n",
    "            svW2 = rvW2/(1 - np.power(gamma,(i+1)))\n",
    "            svb2 = rvb2/(1 - np.power(gamma,(i+1)))\n",
    "            svW3 = rvW3/(1 - np.power(gamma,(i+1)))\n",
    "            svb3 = rvb3/(1 - np.power(gamma,(i+1)))\n",
    "            \n",
    "            dW1 = vvW1 / np.sqrt(svW1 + E)\n",
    "            db1 = vvb1 / np.sqrt(svb1 + E)\n",
    "            dW2 = vvW2 / np.sqrt(svW2 + E)\n",
    "            db2 = vvb2 / np.sqrt(svb2 + E)\n",
    "            dW3 = vvW3 / np.sqrt(svW3 + E)\n",
    "            db3 = vvb3 / np.sqrt(svb3 + E)\n",
    "            \n",
    "            W1 = W1 - learning_rate * dW1\n",
    "            b1 = b1 - learning_rate * db1\n",
    "            W2 = W2 - learning_rate * dW2\n",
    "            b2 = b2 - learning_rate * db2\n",
    "            W3 = W3 - learning_rate * dW3\n",
    "            b3 = b3 - learning_rate * db3\n",
    "            \n",
    "    if(i%1000==0):\n",
    "        print(\"cost \"+str(i/1000),cost)\n",
    "        \n",
    "    if(abs(prev_cost - cost) < delta_cost):\n",
    "        break\n",
    "\n",
    "# Avg. error vs Epoch plot\n",
    "\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Avg. error vs Epoch plot - Adam - Image data\")\n",
    "plt.show()\n",
    "\n",
    "# Working on training data\n",
    "\n",
    "Z1 = np.dot(W1, X_train.T) + b1\n",
    "A1 = np.tanh(Z1)\n",
    "\n",
    "Z2 = np.dot(W2, A1) + b2\n",
    "A2 = np.tanh(Z2)\n",
    "\n",
    "Z3 = np.dot(W3, A2) + b3\n",
    "A3 = sigmoid(Z3)\n",
    "\n",
    "pred = np.argmax(A3,axis=0)\n",
    "\n",
    "# Working on development data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Z1 = np.dot(W1, X_test.T) + b1\n",
    "A1 = np.tanh(Z1)\n",
    "\n",
    "Z2 = np.dot(W2, A1) + b2\n",
    "A2 = np.tanh(Z2)\n",
    "\n",
    "Z3 = np.dot(W3, A2) + b3\n",
    "A3 = sigmoid(Z3)\n",
    "\n",
    "pred1= np.argmax(A3,axis=0)\n",
    "\n",
    "# accuracy scores\n",
    "\n",
    "count=0\n",
    "i=0\n",
    "while i<1200:\n",
    "    if(pred[i]==ytrain[i]):\n",
    "        count=count+1\n",
    "    i=i+1\n",
    "print(\"train accuracy =\",count/1200)\n",
    "\n",
    "count=0\n",
    "i=0\n",
    "while i<300:\n",
    "    if(pred1[i]==Y_test[i]):\n",
    "        count=count+1\n",
    "    i=i+1\n",
    "print(\"test accuracy =\",count/300)\n",
    "\n",
    "the_plot_conf(pred,ytrain,'Training - Adam - Image Data')\n",
    "\n",
    "the_plot_conf(pred1,Y_test,'Development - Adam - Image Data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opcode = 1\n",
    "\n",
    "W1=A_W1\n",
    "W2=A_W2\n",
    "W3=A_W3\n",
    "b1=A_b1\n",
    "b2=A_b2\n",
    "b3=A_b3\n",
    "\n",
    "costs=[]\n",
    "cost = 0\n",
    "vW1 = np.zeros_like(W1)\n",
    "vW2 = np.zeros_like(W2)\n",
    "vW3 = np.zeros_like(W3)\n",
    "vb1 = np.zeros_like(b1)\n",
    "vb2 = np.zeros_like(b2)\n",
    "vb3 = np.zeros_like(b3)\n",
    "\n",
    "rvW1 = np.zeros_like(W1)\n",
    "rvW2 = np.zeros_like(W2)\n",
    "rvW3 = np.zeros_like(W3)\n",
    "rvb1 = np.zeros_like(b1)\n",
    "rvb2 = np.zeros_like(b2)\n",
    "rvb3 = np.zeros_like(b3)\n",
    "\n",
    "# Training\n",
    "\n",
    "for i in range(0, num_iterations):\n",
    "# forward prop   \n",
    "    Z1 = np.dot(W1, X_train.T) + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    \n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = np.tanh(Z2)\n",
    "    \n",
    "    Z3 = np.dot(W3, A2) + b3\n",
    "    A3 = sigmoid(Z3)\n",
    "    \n",
    "#  cost    \n",
    "    prev_cost = cost\n",
    "    logprobs = np.multiply(np.log(A3), Y_train.T) + np.multiply((1 - Y_train.T), np.log(1 - A3))\n",
    "    cost =( - np.sum(logprobs) / m)+(lam * (np.sum(np.square(W1)) + np.sum(np.square(W2)) + np.sum(np.square(W3))) / (2 * m))\n",
    "    cost = float(np.squeeze(cost))\n",
    "    if i % 100 == 0:\n",
    "        costs.append(cost)\n",
    "\n",
    "# back prop\n",
    "    dZ3 = A3 - Y_train.T\n",
    "    dW3 = (1 / m) * np.dot(dZ3, A2.T)+((lam* W3) / m)\n",
    "    db3 = (1 / m) * np.sum(dZ3, axis=1, keepdims=True)\n",
    "    dZ2 = np.multiply(np.dot(W3.T, dZ3), 1 - np.power(A2, 2))\n",
    "    dW2 = (1 / m) * np.dot(dZ2, A1.T)+((lam * W2) / m)\n",
    "    db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = np.multiply(np.dot(W2.T, dZ2), 1 - np.power(A1, 2))\n",
    "    dW1 = (1 / m) * np.dot(dZ1, X_train)+(lam * W1) / m\n",
    "    db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    if(opcode == 0):\n",
    "        \n",
    "        W1 = W1 - learning_rate * dW1\n",
    "        b1 = b1 - learning_rate * db1\n",
    "        W2 = W2 - learning_rate * dW2\n",
    "        b2 = b2 - learning_rate * db2\n",
    "        W3 = W3 - learning_rate * dW3\n",
    "        b3 = b3 - learning_rate * db3\n",
    "        \n",
    "    else:\n",
    "        vW1 = beta * vW1 + (1 - beta) * dW1\n",
    "        vb1 = beta * vb1 + (1 - beta) * db1\n",
    "        vW2 = beta * vW2 + (1 - beta) * dW2\n",
    "        vb2 = beta * vb2 + (1 - beta) * db2\n",
    "        vW3 = beta * vW3 + (1 - beta) * dW3\n",
    "        vb3 = beta * vb3 + (1 - beta) * db3\n",
    "        if(opcode == 1):\n",
    "            \n",
    "            W1 = W1 - learning_rate * vW1\n",
    "            b1 = b1 - learning_rate * vb1\n",
    "            W2 = W2 - learning_rate * vW2\n",
    "            b2 = b2 - learning_rate * vb2\n",
    "            W3 = W3 - learning_rate * vW3\n",
    "            b3 = b3 - learning_rate * vb3\n",
    "            \n",
    "        else:\n",
    "            rvW1 = gamma * rvW1 + (1 - gamma) * np.power(dW1,2)\n",
    "            rvb1 = gamma * rvb1 + (1 - gamma) * np.power(db1,2)\n",
    "            rvW2 = gamma * rvW2 + (1 - gamma) * np.power(dW2,2)\n",
    "            rvb2 = gamma * rvb2 + (1 - gamma) * np.power(db2,2)\n",
    "            rvW3 = gamma * rvW3 + (1 - gamma) * np.power(dW3,2)\n",
    "            rvb3 = gamma * rvb3 + (1 - gamma) * np.power(db3,2)\n",
    "\n",
    "            E = 1e-08\n",
    "            \n",
    "            vvW1=np.zeros_like(W1)\n",
    "            vvW2=np.zeros_like(W2)\n",
    "            vvW3=np.zeros_like(W3)\n",
    "            vvb1=np.zeros_like(b1)\n",
    "            vvb2=np.zeros_like(b2)\n",
    "            vvb3=np.zeros_like(b3)\n",
    "            \n",
    "            svW1=np.zeros_like(W1)\n",
    "            svW2=np.zeros_like(W2)\n",
    "            svW3=np.zeros_like(W3)\n",
    "            svb1=np.zeros_like(b1)\n",
    "            svb2=np.zeros_like(b2)\n",
    "            svb3=np.zeros_like(b3)\n",
    "\n",
    "\n",
    "            vvW1 = vW1/(1 - np.power(beta,(i+1)))\n",
    "            vvb1 = vb1/(1 - np.power(beta,(i+1)))\n",
    "            vvW2 = vW2/(1 - np.power(beta,(i+1)))\n",
    "            vvb2 = vb2/(1 - np.power(beta,(i+1)))\n",
    "            vvW3 = vW3/(1 - np.power(beta,(i+1)))\n",
    "            vvb3 = vb3/(1 - np.power(beta,(i+1)))\n",
    "\n",
    "            svW1 = rvW1/(1 - np.power(gamma,(i+1)))\n",
    "            svb1 = rvb1/(1 - np.power(gamma,(i+1)))\n",
    "            svW2 = rvW2/(1 - np.power(gamma,(i+1)))\n",
    "            svb2 = rvb2/(1 - np.power(gamma,(i+1)))\n",
    "            svW3 = rvW3/(1 - np.power(gamma,(i+1)))\n",
    "            svb3 = rvb3/(1 - np.power(gamma,(i+1)))\n",
    "            \n",
    "            dW1 = vvW1 / np.sqrt(svW1 + E)\n",
    "            db1 = vvb1 / np.sqrt(svb1 + E)\n",
    "            dW2 = vvW2 / np.sqrt(svW2 + E)\n",
    "            db2 = vvb2 / np.sqrt(svb2 + E)\n",
    "            dW3 = vvW3 / np.sqrt(svW3 + E)\n",
    "            db3 = vvb3 / np.sqrt(svb3 + E)\n",
    "            \n",
    "            W1 = W1 - learning_rate * dW1\n",
    "            b1 = b1 - learning_rate * db1\n",
    "            W2 = W2 - learning_rate * dW2\n",
    "            b2 = b2 - learning_rate * db2\n",
    "            W3 = W3 - learning_rate * dW3\n",
    "            b3 = b3 - learning_rate * db3\n",
    "            \n",
    "    if(i%1000==0):\n",
    "        print(\"cost \"+str(i/1000),cost)        \n",
    "    if(abs(prev_cost - cost) < delta_cost):\n",
    "        break\n",
    "\n",
    "# Avg. error vs Epoch plot\n",
    "\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Avg. error vs Epoch plot - Gen Delta - Image data\")\n",
    "plt.show()\n",
    "\n",
    "# Working on training data\n",
    "\n",
    "Z1 = np.dot(W1, X_train.T) + b1\n",
    "A1 = np.tanh(Z1)\n",
    "\n",
    "Z2 = np.dot(W2, A1) + b2\n",
    "A2 = np.tanh(Z2)\n",
    "\n",
    "Z3 = np.dot(W3, A2) + b3\n",
    "A3 = sigmoid(Z3)\n",
    "\n",
    "pred = np.argmax(A3,axis=0)\n",
    "\n",
    "# Working on development data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Z1 = np.dot(W1, X_test.T) + b1\n",
    "A1 = np.tanh(Z1)\n",
    "\n",
    "Z2 = np.dot(W2, A1) + b2\n",
    "A2 = np.tanh(Z2)\n",
    "\n",
    "Z3 = np.dot(W3, A2) + b3\n",
    "A3 = sigmoid(Z3)\n",
    "\n",
    "pred1= np.argmax(A3,axis=0)\n",
    "\n",
    "# accuracy scores\n",
    "\n",
    "count=0\n",
    "i=0\n",
    "while i<1200:\n",
    "    if(pred[i]==ytrain[i]):\n",
    "        count=count+1\n",
    "    i=i+1\n",
    "print(\"train accuracy =\",count/1200)\n",
    "\n",
    "count=0\n",
    "i=0\n",
    "while i<300:\n",
    "    if(pred1[i]==Y_test[i]):\n",
    "        count=count+1\n",
    "    i=i+1\n",
    "print(\"test accuracy =\",count/300)\n",
    "\n",
    "the_plot_conf(pred,ytrain,'Training - gen-Delta - Image Data')\n",
    "\n",
    "the_plot_conf(pred1,Y_test,'Development - gen-Delta - Image Data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opcode = 0\n",
    "\n",
    "W1=A_W1\n",
    "W2=A_W2\n",
    "W3=A_W3\n",
    "b1=A_b1\n",
    "b2=A_b2\n",
    "b3=A_b3\n",
    "\n",
    "costs=[]\n",
    "cost = 0\n",
    "vW1 = np.zeros_like(W1)\n",
    "vW2 = np.zeros_like(W2)\n",
    "vW3 = np.zeros_like(W3)\n",
    "vb1 = np.zeros_like(b1)\n",
    "vb2 = np.zeros_like(b2)\n",
    "vb3 = np.zeros_like(b3)\n",
    "\n",
    "rvW1 = np.zeros_like(W1)\n",
    "rvW2 = np.zeros_like(W2)\n",
    "rvW3 = np.zeros_like(W3)\n",
    "rvb1 = np.zeros_like(b1)\n",
    "rvb2 = np.zeros_like(b2)\n",
    "rvb3 = np.zeros_like(b3)\n",
    "\n",
    "# Training\n",
    "\n",
    "for i in range(0, num_iterations):\n",
    "# forward prop   \n",
    "    Z1 = np.dot(W1, X_train.T) + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    \n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = np.tanh(Z2)\n",
    "    \n",
    "    Z3 = np.dot(W3, A2) + b3\n",
    "    A3 = sigmoid(Z3)\n",
    "    \n",
    "#  cost    \n",
    "    prev_cost = cost\n",
    "    logprobs = np.multiply(np.log(A3), Y_train.T) + np.multiply((1 - Y_train.T), np.log(1 - A3))\n",
    "    cost =( - np.sum(logprobs) / m)+(lam * (np.sum(np.square(W1)) + np.sum(np.square(W2)) + np.sum(np.square(W3))) / (2 * m))\n",
    "    cost = float(np.squeeze(cost))\n",
    "    if i % 100 == 0:\n",
    "        costs.append(cost)\n",
    "\n",
    "# back prop\n",
    "    dZ3 = A3 - Y_train.T\n",
    "    dW3 = (1 / m) * np.dot(dZ3, A2.T)+((lam* W3) / m)\n",
    "    db3 = (1 / m) * np.sum(dZ3, axis=1, keepdims=True)\n",
    "    dZ2 = np.multiply(np.dot(W3.T, dZ3), 1 - np.power(A2, 2))\n",
    "    dW2 = (1 / m) * np.dot(dZ2, A1.T)+((lam * W2) / m)\n",
    "    db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = np.multiply(np.dot(W2.T, dZ2), 1 - np.power(A1, 2))\n",
    "    dW1 = (1 / m) * np.dot(dZ1, X_train)+(lam * W1) / m\n",
    "    db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    if(opcode == 0):\n",
    "        \n",
    "        W1 = W1 - learning_rate * dW1\n",
    "        b1 = b1 - learning_rate * db1\n",
    "        W2 = W2 - learning_rate * dW2\n",
    "        b2 = b2 - learning_rate * db2\n",
    "        W3 = W3 - learning_rate * dW3\n",
    "        b3 = b3 - learning_rate * db3\n",
    "        \n",
    "    else:\n",
    "        vW1 = beta * vW1 + (1 - beta) * dW1\n",
    "        vb1 = beta * vb1 + (1 - beta) * db1\n",
    "        vW2 = beta * vW2 + (1 - beta) * dW2\n",
    "        vb2 = beta * vb2 + (1 - beta) * db2\n",
    "        vW3 = beta * vW3 + (1 - beta) * dW3\n",
    "        vb3 = beta * vb3 + (1 - beta) * db3\n",
    "        if(opcode == 1):\n",
    "            \n",
    "            dW1 = vW1\n",
    "            db1 = vb1\n",
    "            dW2 = vW2\n",
    "            db2 = vb2\n",
    "            dW3 = vW3\n",
    "            db3 = vb3\n",
    "            \n",
    "            W1 = W1 - learning_rate * dW1\n",
    "            b1 = b1 - learning_rate * db1\n",
    "            W2 = W2 - learning_rate * dW2\n",
    "            b2 = b2 - learning_rate * db2\n",
    "            W3 = W3 - learning_rate * dW3\n",
    "            b3 = b3 - learning_rate * db3\n",
    "            \n",
    "        else:\n",
    "            rvW1 = gamma * rvW1 + (1 - gamma) * np.power(dW1,2)\n",
    "            rvb1 = gamma * rvb1 + (1 - gamma) * np.power(db1,2)\n",
    "            rvW2 = gamma * rvW2 + (1 - gamma) * np.power(dW2,2)\n",
    "            rvb2 = gamma * rvb2 + (1 - gamma) * np.power(db2,2)\n",
    "            rvW3 = gamma * rvW3 + (1 - gamma) * np.power(dW3,2)\n",
    "            rvb3 = gamma * rvb3 + (1 - gamma) * np.power(db3,2)\n",
    "\n",
    "            E = 1e-08\n",
    "            \n",
    "            vvW1=np.zeros_like(W1)\n",
    "            vvW2=np.zeros_like(W2)\n",
    "            vvW3=np.zeros_like(W3)\n",
    "            vvb1=np.zeros_like(b1)\n",
    "            vvb2=np.zeros_like(b2)\n",
    "            vvb3=np.zeros_like(b3)\n",
    "            \n",
    "            svW1=np.zeros_like(W1)\n",
    "            svW2=np.zeros_like(W2)\n",
    "            svW3=np.zeros_like(W3)\n",
    "            svb1=np.zeros_like(b1)\n",
    "            svb2=np.zeros_like(b2)\n",
    "            svb3=np.zeros_like(b3)\n",
    "\n",
    "\n",
    "            vvW1 = vW1/(1 - np.power(beta,(i+1)))\n",
    "            vvb1 = vb1/(1 - np.power(beta,(i+1)))\n",
    "            vvW2 = vW2/(1 - np.power(beta,(i+1)))\n",
    "            vvb2 = vb2/(1 - np.power(beta,(i+1)))\n",
    "            vvW3 = vW3/(1 - np.power(beta,(i+1)))\n",
    "            vvb3 = vb3/(1 - np.power(beta,(i+1)))\n",
    "\n",
    "            svW1 = rvW1/(1 - np.power(gamma,(i+1)))\n",
    "            svb1 = rvb1/(1 - np.power(gamma,(i+1)))\n",
    "            svW2 = rvW2/(1 - np.power(gamma,(i+1)))\n",
    "            svb2 = rvb2/(1 - np.power(gamma,(i+1)))\n",
    "            svW3 = rvW3/(1 - np.power(gamma,(i+1)))\n",
    "            svb3 = rvb3/(1 - np.power(gamma,(i+1)))\n",
    "            \n",
    "            dW1 = vvW1 / np.sqrt(svW1 + E)\n",
    "            db1 = vvb1 / np.sqrt(svb1 + E)\n",
    "            dW2 = vvW2 / np.sqrt(svW2 + E)\n",
    "            db2 = vvb2 / np.sqrt(svb2 + E)\n",
    "            dW3 = vvW3 / np.sqrt(svW3 + E)\n",
    "            db3 = vvb3 / np.sqrt(svb3 + E)\n",
    "            \n",
    "            W1 = W1 - learning_rate * dW1\n",
    "            b1 = b1 - learning_rate * db1\n",
    "            W2 = W2 - learning_rate * dW2\n",
    "            b2 = b2 - learning_rate * db2\n",
    "            W3 = W3 - learning_rate * dW3\n",
    "            b3 = b3 - learning_rate * db3\n",
    "            \n",
    "    if(i%1000==0):\n",
    "        print(\"cost \"+str(i/1000),cost)\n",
    "    if(abs(prev_cost - cost) < delta_cost):\n",
    "        break\n",
    "\n",
    "# Avg. error vs Epoch plot\n",
    "\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Avg. error vs Epoch plot -Delta - Image data\")\n",
    "plt.show()\n",
    "\n",
    "# Working on training data\n",
    "\n",
    "Z1 = np.dot(W1, X_train.T) + b1\n",
    "A1 = np.tanh(Z1)\n",
    "\n",
    "Z2 = np.dot(W2, A1) + b2\n",
    "A2 = np.tanh(Z2)\n",
    "\n",
    "Z3 = np.dot(W3, A2) + b3\n",
    "A3 = sigmoid(Z3)\n",
    "\n",
    "pred = np.argmax(A3,axis=0)\n",
    "\n",
    "# Working on development data\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Z1 = np.dot(W1, X_test.T) + b1\n",
    "A1 = np.tanh(Z1)\n",
    "\n",
    "Z2 = np.dot(W2, A1) + b2\n",
    "A2 = np.tanh(Z2)\n",
    "\n",
    "Z3 = np.dot(W3, A2) + b3\n",
    "A3 = sigmoid(Z3)\n",
    "\n",
    "pred1= np.argmax(A3,axis=0)\n",
    "\n",
    "# accuracy scores\n",
    "\n",
    "count=0\n",
    "i=0\n",
    "while i<1200:\n",
    "    if(pred[i]==ytrain[i]):\n",
    "        count=count+1\n",
    "    i=i+1\n",
    "print(\"train accuracy =\",count/1200)\n",
    "\n",
    "count=0\n",
    "i=0\n",
    "while i<300:\n",
    "    if(pred1[i]==Y_test[i]):\n",
    "        count=count+1\n",
    "    i=i+1\n",
    "print(\"test accuracy =\",count/300)\n",
    "\n",
    "the_plot_conf(pred,ytrain,'Training - Delta - Image Data')\n",
    "\n",
    "the_plot_conf(pred1,Y_test,'Development - Delta - Image Data')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
