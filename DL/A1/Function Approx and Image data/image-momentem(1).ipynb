{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision \n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['truck.npy', 'plane.npy', 'ship.npy', 'bird.npy', 'horse.npy']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading the pretrained model of Vgg_16 which uses batch_normalization\n",
    "net = models.vgg16_bn(pretrained=True)\n",
    "\n",
    "# set the load_path for all image file\n",
    "load_path = './images/'\n",
    "\n",
    "# set the save_path for the extracted features file for all the classes\n",
    "save_path = './Feature_extraction_2D/'\n",
    "#os.mkdir(save_path)\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# will get the names of the files present in the load path\n",
    "# The training data\n",
    "get_class_names = os.listdir(load_path)\n",
    "\n",
    "# for each class file\n",
    "get_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-556c3d4ecae2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;31m# Extracting the features from the middle layer of the network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# Features extracted are of size [1,512,7,7]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     96\u001b[0m             \u001b[0;31m# TODO: if statement only here to tell the jit to skip emitting this when it is None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmomentum\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# use cumulative moving average\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m                     \u001b[0mexponential_average_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_batches_tracked\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i in get_class_names:\n",
    "    # To save the file with the same name for the extracted features\n",
    "    new_save_path = save_path + i\n",
    "    \n",
    "    # To load the class file\n",
    "    class_path = load_path + i\n",
    "\n",
    "    # to load the numpy file\n",
    "    img = np.load(class_path)\n",
    "\n",
    "    # To append the extracted features\n",
    "    arr = []\n",
    "\n",
    "    # for each image in the class file\n",
    "    for j in img:   \n",
    "\n",
    "        # converting the numpy array to tensor\n",
    "        j = torch.tensor(j)\n",
    "        \n",
    "        # reshaping the image to [batch_size,number_of_channel,height,width]\n",
    "        j = j.view([-1,3,32,32])\n",
    "        \n",
    "        # rescaling the image to [1,3,224,224]\n",
    "        # vgg_net the required input is of size 224*224 and single image so batch size 1 \n",
    "        j = F.interpolate(j,(224,224))\n",
    "        \n",
    "        # Extracting the features from the middle layer of the network\n",
    "        z = net.features(j)\n",
    "        \n",
    "        # Features extracted are of size [1,512,7,7]\n",
    "        # Taking the average pooling for each channel\n",
    "        m = F.avg_pool2d(z,(7,7),1,0)\n",
    "        \n",
    "        # Now the features are of size [1,512,1,1]\n",
    "        #reshaping the features to [512] \n",
    "        m = m.view([-1]).detach()\n",
    "        \n",
    "        # converting it back to numpy array\n",
    "        m = np.asarray(m)\n",
    "\n",
    "        # appending to the arr\n",
    "        arr.append(m)\n",
    "\n",
    "    arr = np.asarray(arr)\n",
    "    print(arr.shape)\n",
    "\n",
    "    # To save the numpy array  \n",
    "    np.save(new_save_path,arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pretty plot confusion matrix\n",
    "\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.font_manager as fm\n",
    "from matplotlib.collections import QuadMesh\n",
    "import seaborn as sn\n",
    "import warnings\n",
    "\n",
    "\n",
    "def get_new_fig(fn, figsize=[9,9]):\n",
    "    \"\"\" Init graphics \"\"\"\n",
    "    fig1 = plt.figure(fn, figsize)\n",
    "    ax1 = fig1.gca()   #Get Current Axis\n",
    "    ax1.cla() # clear existing plot\n",
    "    return fig1, ax1\n",
    "#\n",
    "\n",
    "def configcell_text_and_colors(array_df, lin, col, oText, facecolors, posi, fz, fmt, show_null_values=0):\n",
    "    \"\"\"\n",
    "      config cell text and colors\n",
    "      and return text elements to add and to dell\n",
    "      @TODO: use fmt\n",
    "    \"\"\"\n",
    "    text_add = []; text_del = [];\n",
    "    cell_val = array_df[lin][col]\n",
    "    tot_all = array_df[-1][-1]\n",
    "    per = (float(cell_val) / tot_all) * 100\n",
    "    curr_column = array_df[:,col]\n",
    "    ccl = len(curr_column)\n",
    "\n",
    "    #last line  and/or last column\n",
    "    if(col == (ccl - 1)) or (lin == (ccl - 1)):\n",
    "        #tots and percents\n",
    "        if(cell_val != 0):\n",
    "            if(col == ccl - 1) and (lin == ccl - 1):\n",
    "                tot_rig = 0\n",
    "                for i in range(array_df.shape[0] - 1):\n",
    "                    tot_rig += array_df[i][i]\n",
    "                per_ok = (float(tot_rig) / cell_val) * 100\n",
    "            elif(col == ccl - 1):\n",
    "                tot_rig = array_df[lin][lin]\n",
    "                per_ok = (float(tot_rig) / cell_val) * 100\n",
    "            elif(lin == ccl - 1):\n",
    "                tot_rig = array_df[col][col]\n",
    "                per_ok = (float(tot_rig) / cell_val) * 100\n",
    "            per_err = 100 - per_ok\n",
    "        else:\n",
    "            per_ok = per_err = 0\n",
    "\n",
    "        per_ok_s = ['%.2f%%'%(per_ok), '100%'] [per_ok == 100]\n",
    "\n",
    "        #text to DEL\n",
    "        text_del.append(oText)\n",
    "\n",
    "        #text to ADD\n",
    "        font_prop = fm.FontProperties(weight='bold', size=fz)\n",
    "        text_kwargs = dict(color='w', ha=\"center\", va=\"center\", gid='sum', fontproperties=font_prop)\n",
    "        lis_txt = ['%d'%(cell_val), per_ok_s, '%.2f%%'%(per_err)]\n",
    "        lis_kwa = [text_kwargs]\n",
    "        dic = text_kwargs.copy(); dic['color'] = 'g'; lis_kwa.append(dic);\n",
    "        dic = text_kwargs.copy(); dic['color'] = 'r'; lis_kwa.append(dic);\n",
    "        lis_pos = [(oText._x, oText._y-0.3), (oText._x, oText._y), (oText._x, oText._y+0.3)]\n",
    "        for i in range(len(lis_txt)):\n",
    "            newText = dict(x=lis_pos[i][0], y=lis_pos[i][1], text=lis_txt[i], kw=lis_kwa[i])\n",
    "            #print 'lin: %s, col: %s, newText: %s' %(lin, col, newText)\n",
    "            text_add.append(newText)\n",
    "        #print '\\n'\n",
    "\n",
    "        #set background color for sum cells (last line and last column)\n",
    "        carr = [0.27, 0.30, 0.27, 1.0]\n",
    "        if(col == ccl - 1) and (lin == ccl - 1):\n",
    "            carr = [0.17, 0.20, 0.17, 1.0]\n",
    "        facecolors[posi] = carr\n",
    "\n",
    "    else:\n",
    "        if(per > 0):\n",
    "            txt = '%s\\n%.2f%%' %(cell_val, per)\n",
    "        else:\n",
    "            if(show_null_values == 0):\n",
    "                txt = ''\n",
    "            elif(show_null_values == 1):\n",
    "                txt = '0'\n",
    "            else:\n",
    "                txt = '0\\n0.0%'\n",
    "        oText.set_text(txt)\n",
    "\n",
    "        #main diagonal\n",
    "        if(col == lin):\n",
    "            #set color of the textin the diagonal to white\n",
    "            oText.set_color('w')\n",
    "            # set background color in the diagonal to blue\n",
    "            facecolors[posi] = [0.35, 0.8, 0.55, 1.0]\n",
    "        else:\n",
    "            oText.set_color('r')\n",
    "\n",
    "    return text_add, text_del\n",
    "#\n",
    "\n",
    "def insert_totals(df_cm):\n",
    "    \"\"\" insert total column and line (the last ones) \"\"\"\n",
    "    sum_col = []\n",
    "    for c in df_cm.columns:\n",
    "        sum_col.append( df_cm[c].sum() )\n",
    "    sum_lin = []\n",
    "    for item_line in df_cm.iterrows():\n",
    "        sum_lin.append( item_line[1].sum() )\n",
    "    df_cm['sum_lin'] = sum_lin\n",
    "    sum_col.append(np.sum(sum_lin))\n",
    "    df_cm.loc['sum_col'] = sum_col\n",
    "    #print ('\\ndf_cm:\\n', df_cm, '\\n\\b\\n')\n",
    "#\n",
    "\n",
    "def pretty_plot_confusion_matrix(df_cm,st,annot=True, cmap=\"Oranges\", fmt='.2f', fz=20,\n",
    "      lw=0.5, cbar=False, figsize=[8,8], show_null_values=0, pred_val_axis='y'):\n",
    "    \"\"\"\n",
    "      print conf matrix with default layout (like matlab)\n",
    "      params:\n",
    "        df_cm          dataframe (pandas) without totals\n",
    "        annot          print text in each cell\n",
    "        cmap           Oranges,Oranges_r,YlGnBu,Blues,RdBu, ... see:\n",
    "        fz             fontsize\n",
    "        lw             linewidth\n",
    "        pred_val_axis  where to show the prediction values (x or y axis)\n",
    "                        'col' or 'x': show predicted values in columns (x axis) instead lines\n",
    "                        'lin' or 'y': show predicted values in lines   (y axis)\n",
    "    \"\"\"\n",
    "    if(pred_val_axis in ('col', 'x')):\n",
    "        xlbl = 'Predicted'\n",
    "        ylbl = 'Actual'\n",
    "    else:\n",
    "        xlbl = 'Actual'\n",
    "        ylbl = 'Predicted'\n",
    "        df_cm = df_cm.T\n",
    "\n",
    "    # create \"Total\" column\n",
    "    insert_totals(df_cm)\n",
    "\n",
    "    #this is for print allways in the same window\n",
    "    fig, ax1 = get_new_fig('Conf matrix default', figsize)\n",
    "\n",
    "    #thanks for seaborn\n",
    "    ax = sn.heatmap(df_cm, annot=annot, annot_kws={\"size\": fz}, linewidths=lw, ax=ax1,\n",
    "                    cbar=cbar, cmap=cmap, linecolor='w', fmt=fmt)\n",
    "\n",
    "    #set ticklabels rotation\n",
    "    ax.set_xticklabels(ax.get_xticklabels(), rotation = 45, fontsize = 15)\n",
    "    ax.set_yticklabels(ax.get_yticklabels(), rotation = 25, fontsize = 15)\n",
    "\n",
    "    # Turn off all the ticks\n",
    "    for t in ax.xaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "    for t in ax.yaxis.get_major_ticks():\n",
    "        t.tick1On = False\n",
    "        t.tick2On = False\n",
    "\n",
    "    #face colors list\n",
    "    quadmesh = ax.findobj(QuadMesh)[0]\n",
    "    facecolors = quadmesh.get_facecolors()\n",
    "\n",
    "    #iter in text elements\n",
    "    array_df = np.array( df_cm.to_records(index=False).tolist() )\n",
    "    text_add = []; text_del = [];\n",
    "    posi = -1 #from left to right, bottom to top.\n",
    "    for t in ax.collections[0].axes.texts: #ax.texts:\n",
    "        pos = np.array( t.get_position()) - [0.5,0.5]\n",
    "        lin = int(pos[1]); col = int(pos[0]);\n",
    "        posi += 1\n",
    "        #print ('>>> pos: %s, posi: %s, val: %s, txt: %s' %(pos, posi, array_df[lin][col], t.get_text()))\n",
    "\n",
    "        #set text\n",
    "        txt_res = configcell_text_and_colors(array_df, lin, col, t, facecolors, posi, fz, fmt, show_null_values)\n",
    "\n",
    "        text_add.extend(txt_res[0])\n",
    "        text_del.extend(txt_res[1])\n",
    "\n",
    "    #remove the old ones\n",
    "    for item in text_del:\n",
    "        item.remove()\n",
    "    #append the new ones\n",
    "    for item in text_add:\n",
    "        ax.text(item['x'], item['y'], item['text'], **item['kw'])\n",
    "\n",
    "    #titles and legends\n",
    "    ax.set_title('Confusion matrix for'+st)\n",
    "    ax.set_xlabel(xlbl)\n",
    "    ax.set_ylabel(ylbl)\n",
    "    plt.ylim([len(df_cm), -.5])\n",
    "    plt.tight_layout()  #set layout slim\n",
    "    plt.show()\n",
    "#\n",
    "\n",
    "def plot_confusion_matrix_from_data(y_test,st,predictions, columns=None, annot=True, cmap=\"Oranges\",\n",
    "      fmt='.2f', fz=20, lw=0.5, cbar=False, figsize=[8,8], show_null_values=0, pred_val_axis='lin'):\n",
    "    \"\"\"\n",
    "        plot confusion matrix function with y_test (actual values) and predictions (predic),\n",
    "        whitout a confusion matrix yet\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "    from pandas import DataFrame\n",
    "\n",
    "    #data\n",
    "    if(not columns):\n",
    "        #labels axis integer:\n",
    "        ##columns = range(1, len(np.unique(y_test))+1)\n",
    "        #labels axis string:\n",
    "        from string import ascii_uppercase\n",
    "        columns = ['class %s' %(i) for i in list(ascii_uppercase)[0:len(np.unique(y_test))]]\n",
    "\n",
    "    confm = confusion_matrix(y_test, predictions)\n",
    "    cmap = 'Oranges';\n",
    "    fz = 20;\n",
    "    figsize=[9,9];\n",
    "    show_null_values = 2\n",
    "    df_cm = DataFrame(confm, index=columns, columns=columns)\n",
    "    pretty_plot_confusion_matrix(df_cm,st,fz=fz, cmap=cmap, figsize=figsize, show_null_values=show_null_values, pred_val_axis=pred_val_axis)\n",
    "#\n",
    "\n",
    "def the_plot_conf(test,pred,st):\n",
    "    \"\"\" test function with y_test (actual values) and predictions (predic) \"\"\"\n",
    "    #data\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "    y_test = np.array(test)\n",
    "    predic = np.array(pred)\n",
    "    \"\"\"\n",
    "      Examples to validate output (confusion matrix plot)\n",
    "        actual: 5 and prediction 1   >>  3\n",
    "        actual: 2 and prediction 4   >>  1\n",
    "        actual: 3 and prediction 4   >>  10\n",
    "    \"\"\"\n",
    "    columns = []\n",
    "    annot = True;\n",
    "    cmap = 'Oranges';\n",
    "    fmt = '.2f'\n",
    "    lw = 0.5\n",
    "    cbar = False\n",
    "    show_null_values = 2\n",
    "    pred_val_axis = 'y'\n",
    "    #size::\n",
    "    fz = 20;\n",
    "    figsize = [9,9];\n",
    "    if(len(y_test) > 10):\n",
    "        fz=20; figsize=[14,14];\n",
    "    plot_confusion_matrix_from_data(y_test,\" \"+st,predic, columns,\n",
    "      annot, cmap, fmt, fz, lw, cbar, figsize, show_null_values, pred_val_axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "  return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from random import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['truck.npy', 'plane.npy', 'ship.npy', 'bird.npy', 'horse.npy']\n"
     ]
    }
   ],
   "source": [
    "path = './Feature_extraction_2D/'\n",
    "class_names = os.listdir(path)\n",
    "\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 truck.npy\n",
      "1 plane.npy\n",
      "2 ship.npy\n",
      "3 bird.npy\n",
      "4 horse.npy\n"
     ]
    }
   ],
   "source": [
    "val = 0\n",
    "data_points = []\n",
    "data_points_class = []\n",
    "for i in class_names:\n",
    "    load_name = os.path.join(path,i)\n",
    "    extracted_features = np.load(load_name)\n",
    "    for j in extracted_features:\n",
    "        data_points.append(j)\n",
    "        data_points_class.append(val)\n",
    "    print(val,i)\n",
    "    val += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 1 ... 1 2 0]\n"
     ]
    }
   ],
   "source": [
    "temp = list(zip(data_points,data_points_class))\n",
    "shuffle(temp)\n",
    "\n",
    "data_points,data_points_class = zip(*temp)\n",
    "data_points = np.asanyarray(data_points)\n",
    "data_points_class = np.asanyarray(data_points_class)\n",
    "print(data_points_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 512)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(data_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting nodes\n",
    "\n",
    "dim_hidden_1 = 40\n",
    "dim_hidden_2 = 28\n",
    "pca_components = 512\n",
    "C = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data_points, data_points_class,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn import decomposition\n",
    "\n",
    "# pca1 = decomposition.PCA(n_components = pca_components)\n",
    "# pca1.fit(X_train)\n",
    "# X_train = pca1.transform(X_train)\n",
    "# print(X_train.shape)\n",
    "\n",
    "# pca2 = decomposition.PCA(n_components = pca_components)\n",
    "# pca2.fit(X_test)\n",
    "# X_test = pca2.transform(X_test)\n",
    "# print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " ...\n",
      " [0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "ytrain = Y_train\n",
    "b = np.zeros((Y_train.size, Y_train.max()+1))\n",
    "b[np.arange(Y_train.size),Y_train] = 1\n",
    "Y_train=b\n",
    "print(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Initialization and Parameters\n",
    "\n",
    "lam=1\n",
    "learning_rate=0.001\n",
    "learning_Rate=0.001\n",
    "num_iterations=10000\n",
    "delta_cost = 1e-8\n",
    "beta = 0.9\n",
    "gamma = 0.99\n",
    "\n",
    "\n",
    "\n",
    "W1 = np.random.randn(dim_hidden_1,pca_components) * np.sqrt(2/pca_components)\n",
    "b1 = np.zeros(shape=(dim_hidden_1, 1))\n",
    "W2 = np.random.randn(dim_hidden_2, dim_hidden_1) * np.sqrt(2/dim_hidden_1)\n",
    "b2 = np.zeros(shape=(dim_hidden_2, 1))\n",
    "W3 = np.random.randn(5, dim_hidden_2) * np.sqrt(2/dim_hidden_2)\n",
    "b3 = np.zeros(shape=(5, 1))\n",
    "\n",
    "parameters = {\"W1\": W1,\n",
    "              \"b1\": b1,\n",
    "              \"W2\": W2,\n",
    "              \"b2\": b2,\n",
    "              \"W3\": W3,\n",
    "              \"b3\": b3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "opcode = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "costs=[]\n",
    "cost = 0\n",
    "velocity = {\"vW1\": np.zeros_like(parameters['W1']),\n",
    "         \"vb1\": np.zeros_like(parameters['b1']),\n",
    "         \"vW2\": np.zeros_like(parameters['W2']),\n",
    "         \"vb2\": np.zeros_like(parameters['b2']),\n",
    "         \"vW3\": np.zeros_like(parameters['W3']),\n",
    "         \"vb3\": np.zeros_like(parameters['b3'])\n",
    "        }\n",
    "\n",
    "rms_prop = {\"vW1\": np.zeros_like(parameters['W1']),\n",
    "         \"vb1\": np.zeros_like(parameters['b1']),\n",
    "         \"vW2\": np.zeros_like(parameters['W2']),\n",
    "         \"vb2\": np.zeros_like(parameters['b2']),\n",
    "         \"vW3\": np.zeros_like(parameters['W3']),\n",
    "         \"vb3\": np.zeros_like(parameters['b3'])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost  3.127311596714532\n",
      "cost  2.527613650970297\n",
      "cost  2.526526247750298\n",
      "cost  2.525478909139331\n",
      "cost  2.52443948370034\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-17807a3e3230>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0mdW2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mA1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mW2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mdb2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mdZ1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdZ2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mdW1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlam\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mdb1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdZ1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Training\n",
    "\n",
    "for i in range(0, num_iterations):\n",
    "    W1 = parameters['W1']\n",
    "    b1 = parameters['b1']\n",
    "    W2 = parameters['W2']\n",
    "    b2 = parameters['b2']\n",
    "    W3 = parameters['W3']\n",
    "    b3 = parameters['b3']\n",
    "   \n",
    "    Z1 = np.dot(W1, X_train.T) + b1\n",
    "    A1 = np.tanh(Z1)\n",
    "    \n",
    "    Z2 = np.dot(W2, A1) + b2\n",
    "    A2 = np.tanh(Z2)\n",
    "    \n",
    "    Z3 = np.dot(W3, A2) + b3\n",
    "    A3 = sigmoid(Z3)\n",
    "    \n",
    "    cache = {\"Z1\": Z1,\n",
    "             \"A1\": A1,\n",
    "             \"Z2\": Z2,\n",
    "             \"A2\": A2,\n",
    "             \"A3\": A3,\n",
    "             \"Z3 \":Z3}\n",
    "# forward prop\n",
    "\n",
    "\n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "    m=1200\n",
    "    lam=0.4\n",
    "    prev_cost = cost\n",
    "    logprobs = np.multiply(np.log(A3), Y_train.T) + np.multiply((1 - Y_train.T), np.log(1 - A3))\n",
    "    cost =( - np.sum(logprobs) / m)+(lam * (np.sum(np.square(W1)) + np.sum(np.square(W2)) + np.sum(np.square(W3))) / (2 * m))\n",
    "    cost = float(np.squeeze(cost))\n",
    "#  cost\n",
    "    if i % 100 == 0:\n",
    "        costs.append(cost)\n",
    "    \n",
    "    m=1200\n",
    "   \n",
    "    W1 = parameters['W1']\n",
    "    W2 = parameters['W2']\n",
    "    W3 = parameters['W3']\n",
    "\n",
    "    A1 = cache['A1']\n",
    "    A2 = cache['A2']\n",
    "    A3 = cache['A3']\n",
    "    \n",
    "    lam=0.4\n",
    "    dZ3 = A3 - Y_train.T\n",
    "    dW3 = (1 / m) * np.dot(dZ3, A2.T)+((lam* W3) / m)\n",
    "    db3 = (1 / m) * np.sum(dZ3, axis=1, keepdims=True)\n",
    "    dZ2 = np.multiply(np.dot(W3.T, dZ3), 1 - np.power(A2, 2))\n",
    "    dW2 = (1 / m) * np.dot(dZ2, A1.T)+((lam * W2) / m)\n",
    "    db2 = (1 / m) * np.sum(dZ2, axis=1, keepdims=True)\n",
    "    dZ1 = np.multiply(np.dot(W2.T, dZ2), 1 - np.power(A1, 2))\n",
    "    dW1 = (1 / m) * np.dot(dZ1, X_train)+(lam * W1) / m\n",
    "    db1 = (1 / m) * np.sum(dZ1, axis=1, keepdims=True)\n",
    "    \n",
    "    grads = {\"dW1\": dW1,\n",
    "             \"db1\": db1,\n",
    "             \"dW2\": dW2,\n",
    "             \"db2\": db2,\n",
    "             \"dW3\": dW3,\n",
    "             \"db3\": db3\n",
    "            }\n",
    "# back prop\n",
    "\n",
    "    if(opcode == 0):\n",
    "        W1 = parameters['W1']\n",
    "        b1 = parameters['b1']\n",
    "        W2 = parameters['W2']\n",
    "        b2 = parameters['b2']\n",
    "        W3 = parameters['W3']\n",
    "        b3 = parameters['b3']\n",
    "        \n",
    "        dW1 = grads['dW1']\n",
    "        db1 = grads['db1']\n",
    "        dW2 = grads['dW2']\n",
    "        db2 = grads['db2']\n",
    "        dW3 = grads['dW3']\n",
    "        db3 = grads['db3']\n",
    "        \n",
    "        W1 = W1 - learning_rate * dW1\n",
    "        b1 = b1 - learning_rate * db1\n",
    "        W2 = W2 - learning_rate * dW2\n",
    "        b2 = b2 - learning_rate * db2\n",
    "        W3 = W3 - learning_rate * dW3\n",
    "        b3 = b3 - learning_rate * db3\n",
    "        \n",
    "        parameters = {\"W1\": W1,\n",
    "                      \"b1\": b1,\n",
    "                      \"W2\": W2,\n",
    "                      \"b2\": b2,\n",
    "                      \"W3\": W3,\n",
    "                      \"b3\": b3\n",
    "                     }\n",
    "    else:\n",
    "        velocity['vW1'] = beta * velocity['vW1'] + (1 - beta) * grads['dW1']\n",
    "        velocity['vb1'] = beta * velocity['vb1'] + (1 - beta) * grads['db1']\n",
    "        velocity['vW2'] = beta * velocity['vW2'] + (1 - beta) * grads['dW2']\n",
    "        velocity['vb2'] = beta * velocity['vb2'] + (1 - beta) * grads['db2']\n",
    "        velocity['vW3'] = beta * velocity['vW3'] + (1 - beta) * grads['dW3']\n",
    "        velocity['vb3'] = beta * velocity['vb3'] + (1 - beta) * grads['db3']\n",
    "        if(opcode == 1):\n",
    "            W1 = parameters['W1']\n",
    "            b1 = parameters['b1']\n",
    "            W2 = parameters['W2']\n",
    "            b2 = parameters['b2']\n",
    "            W3 = parameters['W3']\n",
    "            b3 = parameters['b3']\n",
    "            \n",
    "            dW1 = velocity['vW1']\n",
    "            db1 = velocity['vb1']\n",
    "            dW2 = velocity['vW2']\n",
    "            db2 = velocity['vb2']\n",
    "            dW3 = velocity['vW3']\n",
    "            db3 = velocity['vb3']\n",
    "            \n",
    "            W1 = W1 - learning_rate * dW1\n",
    "            b1 = b1 - learning_rate * db1\n",
    "            W2 = W2 - learning_rate * dW2\n",
    "            b2 = b2 - learning_rate * db2\n",
    "            W3 = W3 - learning_rate * dW3\n",
    "            b3 = b3 - learning_rate * db3\n",
    "            \n",
    "            parameters = {\"W1\": W1,\n",
    "                          \"b1\": b1,\n",
    "                          \"W2\": W2,\n",
    "                          \"b2\": b2,\n",
    "                          \"W3\": W3,\n",
    "                          \"b3\": b3\n",
    "                         }\n",
    "            \n",
    "        else:\n",
    "            rms_prop['vW1'] = gamma * rms_prop['vW1'] + (1 - gamma) * np.power(grads['dW1'],2)\n",
    "            rms_prop['vb1'] = gamma * rms_prop['vb1'] + (1 - gamma) * np.power(grads['db1'],2)\n",
    "            rms_prop['vW2'] = gamma * rms_prop['vW2'] + (1 - gamma) * np.power(grads['dW2'],2)\n",
    "            rms_prop['vb2'] = gamma * rms_prop['vb2'] + (1 - gamma) * np.power(grads['db2'],2)\n",
    "            rms_prop['vW3'] = gamma * rms_prop['vW3'] + (1 - gamma) * np.power(grads['dW3'],2)\n",
    "            rms_prop['vb3'] = gamma * rms_prop['vb3'] + (1 - gamma) * np.power(grads['db3'],2)\n",
    "\n",
    "            E = 1e-08\n",
    "\n",
    "            v_correct = {\"vW1\": np.zeros_like(parameters['W1']),\n",
    "            \"vb1\": np.zeros_like(parameters['b1']),\n",
    "            \"vW2\": np.zeros_like(parameters['W2']),\n",
    "            \"vb2\": np.zeros_like(parameters['b2']),\n",
    "            \"vW3\": np.zeros_like(parameters['W3']),\n",
    "            \"vb3\": np.zeros_like(parameters['b3'])\n",
    "            }\n",
    "\n",
    "            s_correct = {\"vW1\": np.zeros_like(parameters['W1']),\n",
    "            \"vb1\": np.zeros_like(parameters['b1']),\n",
    "            \"vW2\": np.zeros_like(parameters['W2']),\n",
    "            \"vb2\": np.zeros_like(parameters['b2']),\n",
    "            \"vW3\": np.zeros_like(parameters['W3']),\n",
    "            \"vb3\": np.zeros_like(parameters['b3'])\n",
    "            }\n",
    "\n",
    "\n",
    "            v_correct['vW1'] = velocity['vW1']/(1 - np.power(beta,(i+1)))\n",
    "            v_correct['vb1'] = velocity['vb1']/(1 - np.power(beta,(i+1)))\n",
    "            v_correct['vW2'] = velocity['vW2']/(1 - np.power(beta,(i+1)))\n",
    "            v_correct['vb2'] = velocity['vb2']/(1 - np.power(beta,(i+1)))\n",
    "            v_correct['vW3'] = velocity['vW3']/(1 - np.power(beta,(i+1)))\n",
    "            v_correct['vb3'] = velocity['vb3']/(1 - np.power(beta,(i+1)))\n",
    "\n",
    "            s_correct['vW1'] = rms_prop['vW1']/(1 - np.power(gamma,(i+1)))\n",
    "            s_correct['vb1'] = rms_prop['vb1']/(1 - np.power(gamma,(i+1)))\n",
    "            s_correct['vW2'] = rms_prop['vW2']/(1 - np.power(gamma,(i+1)))\n",
    "            s_correct['vb2'] = rms_prop['vb2']/(1 - np.power(gamma,(i+1)))\n",
    "            s_correct['vW3'] = rms_prop['vW3']/(1 - np.power(gamma,(i+1)))\n",
    "            s_correct['vb3'] = rms_prop['vb3']/(1 - np.power(gamma,(i+1)))\n",
    "            \n",
    "            W1 = parameters['W1']\n",
    "            b1 = parameters['b1']\n",
    "            W2 = parameters['W2']\n",
    "            b2 = parameters['b2']\n",
    "            W3 = parameters['W3']\n",
    "            b3 = parameters['b3']\n",
    "            \n",
    "            dW1 = v_correct['vW1'] / np.sqrt(s_correct['vW1'] + E)\n",
    "            db1 = v_correct['vb1'] / np.sqrt(s_correct['vb1'] + E)\n",
    "            dW2 = v_correct['vW2'] / np.sqrt(s_correct['vW2'] + E)\n",
    "            db2 = v_correct['vb2'] / np.sqrt(s_correct['vb2'] + E)\n",
    "            dW3 = v_correct['vW3'] / np.sqrt(s_correct['vW3'] + E)\n",
    "            db3 = v_correct['vb3'] / np.sqrt(s_correct['vb3'] + E)\n",
    "            \n",
    "            W1 = W1 - learning_rate * dW1\n",
    "            b1 = b1 - learning_rate * db1\n",
    "            W2 = W2 - learning_rate * dW2\n",
    "            b2 = b2 - learning_rate * db2\n",
    "            W3 = W3 - learning_rate * dW3\n",
    "            b3 = b3 - learning_rate * db3\n",
    "            \n",
    "            parameters = {\"W1\": W1,\n",
    "                          \"b1\": b1,\n",
    "                          \"W2\": W2,\n",
    "                          \"b2\": b2,\n",
    "                          \"W3\": W3,\n",
    "                          \"b3\": b3\n",
    "                         }\n",
    "            \n",
    "    if(i%1000==0):\n",
    "        print(\"cost \",cost)\n",
    "        \n",
    "    if(abs(prev_cost - cost) < delta_cost):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg. error vs Epoch plot\n",
    "\n",
    "plt.plot(costs)\n",
    "plt.ylabel('cost')\n",
    "plt.xlabel('iterations (per hundreds)')\n",
    "plt.title(\"Avg. error vs Epoch plot - Generalized Delta - Image data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working on training data\n",
    "\n",
    "W1 = parameters['W1']\n",
    "b1 = parameters['b1']\n",
    "W2 = parameters['W2']\n",
    "b2 = parameters['b2']\n",
    "W3 = parameters['W3']\n",
    "b3 = parameters['b3']\n",
    "\n",
    "\n",
    "\n",
    "Z1 = np.dot(W1, X_train.T) + b1\n",
    "A1 = np.tanh(Z1)\n",
    "\n",
    "Z2 = np.dot(W2, A1) + b2\n",
    "A2 = np.tanh(Z2)\n",
    "\n",
    "Z3 = np.dot(W3, A2) + b3\n",
    "A3 = sigmoid(Z3)\n",
    "\n",
    "\n",
    "\n",
    "cache = {\"Z1\": Z1,\n",
    "         \"A1\": A1,\n",
    "         \"Z2\": Z2,\n",
    "         \"A2\": A2,\n",
    "         \"A3\": A3,\n",
    "         \"Z3 \":Z3}\n",
    "\n",
    "pred = np.argmax(A3,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Working on development data\n",
    "\n",
    "W1 = parameters['W1']\n",
    "b1 = parameters['b1']\n",
    "W2 = parameters['W2']\n",
    "b2 = parameters['b2']\n",
    "W3 = parameters['W3']\n",
    "b3 = parameters['b3']\n",
    "\n",
    "\n",
    "\n",
    "Z1 = np.dot(W1, X_test.T) + b1\n",
    "A1 = np.tanh(Z1)\n",
    "\n",
    "Z2 = np.dot(W2, A1) + b2\n",
    "A2 = np.tanh(Z2)\n",
    "\n",
    "Z3 = np.dot(W3, A2) + b3\n",
    "A3 = sigmoid(Z3)\n",
    "\n",
    "\n",
    "\n",
    "cache = {\"Z1\": Z1,\n",
    "         \"A1\": A1,\n",
    "         \"Z2\": Z2,\n",
    "         \"A2\": A2,\n",
    "         \"A3\": A3,\n",
    "         \"Z3 \":Z3}\n",
    "\n",
    "pred1= np.argmax(A3,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy scores\n",
    "\n",
    "count=0\n",
    "i=0\n",
    "while i<1200:\n",
    "    if(pred[i]==ytrain[i]):\n",
    "        count=count+1\n",
    "    i=i+1\n",
    "print(\"train accuracy =\",count/1200)\n",
    "\n",
    "count=0\n",
    "i=0\n",
    "while i<300:\n",
    "    if(pred1[i]==Y_test[i]):\n",
    "        count=count+1\n",
    "    i=i+1\n",
    "print(\"test accuracy =\",count/300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_plot_conf(pred,ytrain,'Training - Generalized Delta - Image Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "the_plot_conf(pred1,Y_test,'Development - Generalized Delta - Image Data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
