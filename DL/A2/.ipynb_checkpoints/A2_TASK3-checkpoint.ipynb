{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import decomposition\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(24000, 784) (6000, 784)\n",
      "['Bag.csv' 'Coat.csv' 'Sandal.csv' 'Trouser.csv' 'T_shirt.csv']\n"
     ]
    }
   ],
   "source": [
    "dir_path = '11_ds_2/'\n",
    "class_names = np.load(dir_path+'class_names.npy')\n",
    "train_data = np.load(dir_path+'train_data.npy')\n",
    "train_target = np.load(dir_path+'train_target.npy')\n",
    "test_data = np.load(dir_path+'test_data.npy')\n",
    "test_target = np.load(dir_path+'test_target.npy')\n",
    "print(np.shape(train_data),np.shape(test_data))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_data = np.reshape(train_data[5],(28,28))\n",
    "plt.imshow(show_data,cmap='gray', vmin=0, vmax=255)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_target, test_target = train_test_split(data,target,test_size=0.2)\n",
    "np.shape(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AANN1\n",
    "\n",
    "dim = 828\n",
    "h1_dim = 1000\n",
    "h2_dim = 800\n",
    "h3_dim = 600\n",
    "h4_dim = 900\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "num_epochs = 500\n",
    "\n",
    "class AANN1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AANN1, self).__init__()\n",
    "        self.fc1 = nn.Linear(dim,h1_dim)\n",
    "        self.fc2 = nn.Linear(h1_dim,h2_dim)\n",
    "        self.fcl = nn.Linear(h2_dim, h3_dim)\n",
    "        self.fc3 = nn.Linear(h3_dim,h4_dim)\n",
    "        self.fc4 = nn.Linear(h4_dim,dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        m = nn.Tanh()\n",
    "        x = self.fc1(x)\n",
    "        x = m(self.fc2(x))\n",
    "        y = self.fcl(x)\n",
    "        x = m(self.fc3(y))\n",
    "        x = self.fc4(x)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training for AANN1\n",
    "\n",
    "# loading data\n",
    "tensor_data = torch.Tensor(train_data)\n",
    "tensor_data_test = torch.Tensor(test_data)\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(tensor_data,tensor_data)\n",
    "dataset_test = torch.utils.data.TensorDataset(tensor_data_test,tensor_data_test)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,shuffle=True,num_workers=8)\n",
    "loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size,shuffle=True,num_workers=8)\n",
    "\n",
    "aann1 = AANN1()\n",
    "criterion = nn.MSELoss(reduction='none')\n",
    "optimizer = optim.Adagrad(aann1.parameters(), lr=learning_rate,lr_decay=0)\n",
    "\n",
    "# training\n",
    "running_loss = 0.0\n",
    "count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, load_data in enumerate(loader):\n",
    "        \n",
    "        inputs, same_inputs = load_data\n",
    "        \n",
    "        # initialize with zeros all param\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs,_ = aann1(inputs)\n",
    "        loss = criterion(outputs,same_inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    if((epoch+1)%50 == 0):\n",
    "        print(epoch+1, running_loss/count)\n",
    "        running_loss = 0.0\n",
    "        count = 0\n",
    "\n",
    "# computing error\n",
    "error = 0\n",
    "num = 0\n",
    "with torch.no_grad():\n",
    "    for data in loader:\n",
    "        inputs, labels = data\n",
    "        outputs,_ = aann1(inputs)\n",
    "        diff = outputs-inputs\n",
    "        error += ((diff*diff).sum().item())\n",
    "        num += 1\n",
    "print('Train error',end=':')\n",
    "print(error/(num*dim))\n",
    "\n",
    "error = 0\n",
    "num = 0\n",
    "with torch.no_grad():\n",
    "    for data in loader_test:\n",
    "        inputs, labels = data\n",
    "        outputs,_ = aann1(inputs)\n",
    "        diff = outputs-inputs\n",
    "        error += ((diff*diff).sum().item())\n",
    "        num += 1\n",
    "print('Test error',end=':')\n",
    "print(error/(num*dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(aann1.state_dict(),'aann1_task2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AANN2\n",
    "\n",
    "dim = h3_dim # from previous, AANN1\n",
    "h1_dim = 800\n",
    "h2_dim = 500\n",
    "h3_dim = 300\n",
    "h4_dim = 500\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "num_epochs = 500\n",
    "\n",
    "class AANN2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AANN2, self).__init__()\n",
    "        self.fc1 = nn.Linear(dim,h1_dim)\n",
    "        self.fc2 = nn.Linear(h1_dim,h2_dim)\n",
    "        self.fcl = nn.Linear(h2_dim, h3_dim)\n",
    "        self.fc3 = nn.Linear(h3_dim,h4_dim)\n",
    "        self.fc4 = nn.Linear(h4_dim,dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        m = nn.Tanh()\n",
    "        x = self.fc1(x)\n",
    "        x = m(self.fc2(x))\n",
    "        y = self.fcl(x)\n",
    "        x = m(self.fc3(y))\n",
    "        x = self.fc4(x)\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training for AANN2\n",
    "\n",
    "# loading data\n",
    "_, tensor_data = aann1(torch.Tensor(train_data))\n",
    "_, tensor_data_test = aann1(torch.Tensor(test_data))\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(tensor_data,tensor_data)\n",
    "dataset_test = torch.utils.data.TensorDataset(tensor_data_test,tensor_data_test)\n",
    "loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size,shuffle=True,num_workers=8)\n",
    "loader_test = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size,shuffle=True,num_workers=8)\n",
    "\n",
    "aann2 = AANN2()\n",
    "criterion = nn.MSELoss(reduction='none')\n",
    "optimizer = optim.Adagrad(aann2.parameters(), lr=learning_rate,lr_decay=0)\n",
    "\n",
    "# training\n",
    "running_loss = 0.0\n",
    "count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, load_data in enumerate(loader):\n",
    "        \n",
    "        inputs, same_inputs = load_data\n",
    "        \n",
    "        # initialize with zeros all param\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs,_ = aann2(inputs)\n",
    "        loss = criterion(outputs,same_inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    if((epoch+1)%50 == 0):\n",
    "        print(epoch+1, running_loss/count)\n",
    "        running_loss = 0.0\n",
    "        count = 0\n",
    "\n",
    "# computing error\n",
    "error = 0\n",
    "num = 0\n",
    "with torch.no_grad():\n",
    "    for data in loader:\n",
    "        inputs, labels = data\n",
    "        outputs,_ = aann2(inputs)\n",
    "        diff = outputs-inputs\n",
    "        error += ((diff*diff).sum().item())\n",
    "        num += 1\n",
    "print('Train error',end=':')\n",
    "print(error/(num*dim))\n",
    "\n",
    "error = 0\n",
    "num = 0\n",
    "with torch.no_grad():\n",
    "    for data in loader_test:\n",
    "        inputs, labels = data\n",
    "        outputs,_ = aann2(inputs)\n",
    "        diff = outputs-inputs\n",
    "        error += ((diff*diff).sum().item())\n",
    "        num += 1\n",
    "print('Test error',end=':')\n",
    "print(error/(num*dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(aann2.state_dict(),'aann2_task2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aann_train = torch.Tensor(train_data)\n",
    "aann_test = torch.Tensor(test_data)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print(aann_train.size())\n",
    "    _, aann_train = aann1(aann_train)\n",
    "    _, aann_train = aann2(aann_train)\n",
    "    _, aann_test = aann1(aann_test)\n",
    "    _, aann_test = aann2(aann_test)\n",
    "    print(aann_train.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "dim = h3_dim # from output of aann2\n",
    "h1_dim = 40\n",
    "h2_dim = 28\n",
    "out_dim = len(class_names)\n",
    "learning_rate = 0.001\n",
    "momentum = 0.9\n",
    "num_epochs = 1000\n",
    "batch_size = 32  # general rule is to try 32, 64, 128 ... \n",
    "\n",
    "# DNN model developn \n",
    "\n",
    "class Nural_net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Nural_net, self).__init__()\n",
    "        self.fc1 = nn.Linear(dim,h1_dim) \n",
    "        self.fc2 = nn.Linear(h1_dim,h2_dim)\n",
    "        self.fc3 = nn.Linear(h2_dim,out_dim)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.sigmoid(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss fun and update method\n",
    "\n",
    "tensor_train_target = torch.LongTensor(train_target) # long otherwise takes as float\n",
    "\n",
    "tensor_test_target = torch.LongTensor(test_target)\n",
    "\n",
    "# num_workers - how many parallel data loadings\n",
    "train_dataset = torch.utils.data.TensorDataset(aann_train,tensor_train_target)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,shuffle=True,num_workers=8)\n",
    "\n",
    "test_dataset = torch.utils.data.TensorDataset(aann_test,tensor_test_target)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,shuffle=False,num_workers=8)\n",
    "\n",
    "net2 = Nural_net()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# ASDG for generalised delta ig\n",
    "# schochastic gradient descent with nestrov momentum\n",
    "optimizer = optim.SGD(net2.parameters(), lr=learning_rate, momentum=momentum)\n",
    "# optimizer = optim.Adagrad(net.parameters(), lr=learning_rate,lr_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "\n",
    "\n",
    "running_loss = 0.0\n",
    "count = 0\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    for i, load_data in enumerate(train_loader):\n",
    "        \n",
    "        inputs, labels = load_data\n",
    "        \n",
    "        # initialize with zeros all param\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = net2(inputs)\n",
    "        loss = criterion(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        count += 1\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "    if((epoch+1)%50 == 0):\n",
    "        print(epoch+1, running_loss/count)\n",
    "        running_loss = 0.0\n",
    "        count = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing\n",
    "\n",
    "# train data\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in train_loader:\n",
    "        inputs, labels = data\n",
    "        outputs = net2(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('train accuracy',end=':')\n",
    "print(correct/total)\n",
    "\n",
    "#test data\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        inputs, labels = data\n",
    "        outputs = net2(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('test accuracy',end=':')\n",
    "print(correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net2.state_dict(),'net_task2.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
