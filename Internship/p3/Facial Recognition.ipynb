{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Facial Recognition\n",
    "1 We are using open api face_recognition (Copyrights have to verified before deploying) <br>\n",
    "2 It takes a local file as input and recognizes an other image or video or live webcam recording <br>\n",
    "3 We can direct image from cloud bucket too <br>\n",
    "4 Code flow is putup in comments at every cell <br>\n",
    "5 Output will be a binary variable whether recognized or not <br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# facial recognition\n",
    "\n",
    "import face_recognition as fr\n",
    "import os\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no!\n"
     ]
    }
   ],
   "source": [
    "# recognizing faces in picture\n",
    "\n",
    "picture = fr.load_image_file(\"obama.jpg\")\n",
    "face_encoding = fr.face_encodings(picture)[0]\n",
    "\n",
    "\n",
    "uk_picture = fr.load_image_file(\"my_photo.jpg\")\n",
    "uk_encoding = fr.face_encodings(uk_picture)[0]\n",
    "\n",
    "\n",
    "results = fr.compare_faces([face_encoding], uk_encoding)\n",
    "\n",
    "if results[0] == True:\n",
    "    print(\"yes!\")\n",
    "else:\n",
    "    print(\"no!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "359.0\n"
     ]
    }
   ],
   "source": [
    "# opening video\n",
    "\n",
    "pic = fr.load_image_file(\"my_photo.jpg\")\n",
    "input_face_encoding = fr.face_encodings(pic)[0]\n",
    "\n",
    "vid = cv2.VideoCapture(\"my_video.webm\")\n",
    "frms = vid.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "print(frms)\n",
    "if(frms > 150):\n",
    "    num = 100\n",
    "else:\n",
    "    num = frms - 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created images 150\n"
     ]
    }
   ],
   "source": [
    "# create image frames\n",
    "\n",
    "frame_cnt = 0\n",
    "while(frame_cnt < num + 50):\n",
    "    ret,frame = vid.read() \n",
    "    if ret:\n",
    "        name = 'frame' + str(frame_cnt) + '.jpg'\n",
    "        if(frame_cnt >= num):\n",
    "            cv2.imwrite(name, frame)\n",
    "        frame_cnt += 1\n",
    "    else: \n",
    "        break\n",
    "print('created images '+str(frame_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recognised\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# recognize frames\n",
    "\n",
    "count = num\n",
    "match = 0\n",
    "while(count < num + 50):\n",
    "    pic = fr.load_image_file('frame' + str(count) + '.jpg')\n",
    "    try:\n",
    "        encode = fr.face_encodings(pic)[0]\n",
    "    except:\n",
    "        count += 1\n",
    "        continue\n",
    "    results = fr.compare_faces([input_face_encoding], encode)\n",
    "    count += 1\n",
    "    if(results[0]):\n",
    "        match += 1\n",
    "\n",
    "if(match > 0):\n",
    "    print('recognised')\n",
    "else:\n",
    "    print('not recognised')\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleted images 150\n"
     ]
    }
   ],
   "source": [
    "# delete images\n",
    "\n",
    "frame_cnt = 0\n",
    "while(frame_cnt < num + 50):\n",
    "    name = 'frame' + str(frame_cnt) + '.jpg'\n",
    "    if(frame_cnt >= num):\n",
    "        os.remove(name)\n",
    "    frame_cnt += 1\n",
    "print('deleted images '+str(frame_cnt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matched\n",
      "matched\n",
      "matched\n",
      "matched\n",
      "matched\n",
      "matched\n",
      "matched\n",
      "matched\n",
      "matched\n",
      "matched\n",
      "matched\n",
      "matched\n",
      "matched\n",
      "matched\n",
      "matched\n",
      "unmatched\n",
      "unmatched\n",
      "unmatched\n",
      "unmatched\n",
      "unmatched\n",
      "unmatched\n",
      "matched\n",
      "matched\n",
      "matched\n",
      "matched\n",
      "matched\n",
      "matched\n",
      "matched\n",
      "unmatched\n",
      "unmatched\n",
      "unmatched\n",
      "unmatched\n",
      "matched\n",
      "matched\n",
      "matched\n",
      "matched\n",
      "matched\n",
      "matched\n",
      "matched\n",
      "matched\n",
      "30\n"
     ]
    }
   ],
   "source": [
    "# live face recognition\n",
    "\n",
    "\"\"\"\n",
    "reads video from cam and inputs live \n",
    "recognition status\n",
    "\"\"\"\n",
    "\n",
    "pic = fr.load_image_file(\"my_photo.jpg\")\n",
    "input_face_encoding = fr.face_encodings(pic)[0]\n",
    "process_this_frame = True\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "count = 0\n",
    "match = 0\n",
    "\n",
    "# print(\"loop starts\")\n",
    "\n",
    "while (count < 40):\n",
    "    # print(count)\n",
    "    ret, frame = capture.read()\n",
    "    small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)\n",
    "    rgb_small_frame = small_frame[:, :, ::-1]\n",
    "    if process_this_frame:\n",
    "        face_location = fr.face_locations(rgb_small_frame)\n",
    "        try:\n",
    "            face_encoding = fr.face_encodings(rgb_small_frame, face_location)[0]\n",
    "            ans = fr.compare_faces([input_face_encoding], face_encoding)\n",
    "        except:\n",
    "            ans = [False]\n",
    "        count += 1\n",
    "        if(ans[0]):\n",
    "            match += 1\n",
    "            print('matched')\n",
    "        else:\n",
    "            print('unmatched')\n",
    "    process_this_frame = not process_this_frame\n",
    "    \n",
    "capture.release() \n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
