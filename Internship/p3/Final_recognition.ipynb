{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import face_recognition as fr\n",
    "import os\n",
    "import cv2\n",
    "from gcloud import storage\n",
    "import io\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "import python_speech_features as mfcc\n",
    "import audioread\n",
    "from scipy.io.wavfile import read\n",
    "from sklearn.mixture import GaussianMixture as GMM # some texts use GMM\n",
    "from sklearn import preprocessing # break the blackbox here\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# constant parameters\n",
    "\n",
    "jsonPath = '/home/subbu/PRML/Internship/p1/rankingtranscript-96316cee08ba.json'\n",
    "bucketName = 'rankingtranscript1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def photo_face_recognition(input_photo,testing_pic):\n",
    "    \n",
    "    # downloading files from cloud\n",
    "    storage_client = storage.Client.from_service_account_json(jsonPath)\n",
    "    bucket = storage_client.get_bucket(bucketName)\n",
    "    blob = bucket.get_blob(input_photo)\n",
    "    blob.download_to_filename(input_photo)\n",
    "    blob2 = bucket.get_blob(testing_pic)\n",
    "    blob2.download_to_filename(testing_pic)\n",
    "    \n",
    "    picture = fr.load_image_file(input_photo)\n",
    "    face_encoding = fr.face_encodings(picture)[0]\n",
    "\n",
    "\n",
    "    uk_picture = fr.load_image_file(testing_pic)\n",
    "    uk_encoding = fr.face_encodings(uk_picture)[0]\n",
    "\n",
    "\n",
    "    results = fr.compare_faces([face_encoding], uk_encoding)\n",
    "    \n",
    "    os.remove(input_photo)\n",
    "    os.remove(testing_pic)\n",
    "    \n",
    "    count = 0\n",
    "    for output in results:\n",
    "        if(output == True):\n",
    "            count += 1\n",
    "    if(count > 0):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def video_face_recognition(input_photo,testing_video):\n",
    "    \n",
    "    # downloading files from cloud\n",
    "    storage_client = storage.Client.from_service_account_json(jsonPath)\n",
    "    bucket = storage_client.get_bucket(bucketName)\n",
    "    blob = bucket.get_blob(input_photo)\n",
    "    blob.download_to_filename(input_photo)\n",
    "    blob2 = bucket.get_blob(testing_video)\n",
    "    blob2.download_to_filename(testing_video)\n",
    "    \n",
    "    pic = fr.load_image_file(input_photo)\n",
    "    input_face_encoding = fr.face_encodings(pic)[0]\n",
    "    \n",
    "    vid = cv2.VideoCapture(testing_video)\n",
    "    frms = vid.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    print(frms)\n",
    "    if(frms > 150):\n",
    "        num = 100\n",
    "    else:\n",
    "        num = frms - 60\n",
    "        \n",
    "    frame_cnt = 0\n",
    "    while(frame_cnt < num + 50):\n",
    "        ret,frame = vid.read() \n",
    "        if ret:\n",
    "            name = 'frame' + str(frame_cnt) + '.jpg'\n",
    "            if(frame_cnt >= num):\n",
    "                cv2.imwrite(name, frame)\n",
    "            frame_cnt += 1\n",
    "        else: \n",
    "            break\n",
    "    print('created images '+str(frame_cnt))\n",
    "    \n",
    "    count = num\n",
    "    match = 0\n",
    "    while(count < num + 50):\n",
    "        pic = fr.load_image_file('frame' + str(count) + '.jpg')\n",
    "        try:\n",
    "            encode = fr.face_encodings(pic)[0]\n",
    "        except:\n",
    "            count += 1\n",
    "            continue\n",
    "        results = fr.compare_faces([input_face_encoding], encode)\n",
    "        count += 1\n",
    "        if(results[0]):\n",
    "            match += 1\n",
    "    \n",
    "    print(match)\n",
    "    \n",
    "    # deleting local files\n",
    "    \n",
    "    frame_cnt = 0\n",
    "    while(frame_cnt < num + 50):\n",
    "        name = 'frame' + str(frame_cnt) + '.jpg'\n",
    "        if(frame_cnt >= num):\n",
    "            os.remove(name)\n",
    "        frame_cnt += 1\n",
    "    print('deleted images '+str(frame_cnt))\n",
    "    \n",
    "    os.remove(input_photo)\n",
    "    os.remove(testing_video)\n",
    "    \n",
    "    if(match > 0):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_recognition(input_audio,test_directory):\n",
    "    \n",
    "    sr,audio = read(input_audio)\n",
    "    \n",
    "    feature = mfcc.mfcc(audio,sr, 0.025, 0.01,20,nfft = 1200, appendEnergy = True)\n",
    "    feature = preprocessing.scale(feature)\n",
    "    \n",
    "    gmm = GMM(n_components = 16, max_iter = 200, covariance_type='diag',n_init = 3)\n",
    "    gmm.fit(feature)\n",
    "    \n",
    "    name = ''\n",
    "    score = -100000\n",
    "    wav_files = glob.glob(test_directory+'/*')\n",
    "    for one in wav_files:\n",
    "        srx,audiox = read(one)\n",
    "        featurex = mfcc.mfcc(audiox,srx, 0.025, 0.01,20,nfft = 1200, appendEnergy = True)\n",
    "        featurex = preprocessing.scale(featurex)\n",
    "        scorex = gmm.score(featurex)\n",
    "        if(score < scorex):\n",
    "            score = scorex\n",
    "            name = one\n",
    "    name = name[name.index('/')+1:name.index('.')]\n",
    "    \n",
    "    return name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trail runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1737.0\n",
      "created images 150\n",
      "50\n",
      "deleted images 150\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_face_recognition(\"obama.jpg\",\"test_obama.mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Karan_17'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_recognition('SampleData/Karan_17.wav','SampleData')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
