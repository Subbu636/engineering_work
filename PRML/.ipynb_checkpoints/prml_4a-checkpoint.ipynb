{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import multivariate_normal\n",
    "from math import sqrt\n",
    "import math\n",
    "#from matplotlib.mlab import PCA\n",
    "import numpy as np\n",
    "import numpy.linalg as linalg\n",
    "from random import sample\n",
    "import csv\n",
    "import copy\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializecentroids(data,k):\n",
    "    rand_ids = sample(range(data.shape[0]),k)\n",
    "    centroids = []\n",
    "    for i in rand_ids:\n",
    "        d = data.loc[i,:]\n",
    "        centroids.append(d)\n",
    "    #print(centroids)\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclid_dist(x,y):\n",
    "    n=len(x)\n",
    "    s=0\n",
    "    for i in range(n):\n",
    "        sq = (x[i]-y[i])**2\n",
    "        s +=sq\n",
    "    return sqrt(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assigncluster(data,k,centroids):\n",
    "    acluster=[]\n",
    "    for i in range(data.shape[0]):\n",
    "        minind=0\n",
    "        m=1000000\n",
    "        for j in range(len(centroids)):\n",
    "            a = euclid_dist(data.loc[i,:],centroids[j])\n",
    "            if a <= m:\n",
    "                m=a\n",
    "                minind=j\n",
    "        acluster.append(minind)\n",
    "    return acluster           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meaneuclid(datalist):\n",
    "    d=[]\n",
    "    for i in range(len(datalist[0])):\n",
    "        m=0\n",
    "        for j in range(len(datalist)):\n",
    "            m += datalist[j][i]\n",
    "        d.append(m/(len(datalist)))\n",
    "        \n",
    "    return d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimcentroid(data,k,assclusters):\n",
    "    centroids = []\n",
    "    dp=[]\n",
    "    for i in range(k):\n",
    "        dp=[]\n",
    "        for j in range(len(assclusters)):\n",
    "            if assclusters[j]==i:\n",
    "                dp.append(data.loc[j,:])\n",
    "        #print(dp)\n",
    "        #print(centroids)\n",
    "        centroids.append(meaneuclid(dp))\n",
    "    return centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kmeans(data,k):\n",
    "    centroids = initializecentroids(data,k)\n",
    "    iter_num=1\n",
    "    MAX=30\n",
    "    while iter_num <= MAX:\n",
    "        assignedclusters = assigncluster(data,k,centroids)\n",
    "        #print(assignedclusters)\n",
    "        oldcentroids = copy.deepcopy(centroids)\n",
    "        centroids = estimcentroid(data,k,assignedclusters)\n",
    "        iter_num+=1\n",
    "   # print (assignedclusters)\n",
    "    return assignedclusters,centroids      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counter(data,k):\n",
    "    #kmeans\n",
    "    asstates,cen = kmeans(pd.DataFrame(data),k)\n",
    "    #number of states = k\n",
    "    totc = np.zeros(k)\n",
    "    transc = np.zeros((k,k))\n",
    "    for i in range(np.size(data,0)):\n",
    "        a = asstates[i]\n",
    "        totc[a] = totc[a]+1\n",
    "    \n",
    "    for j in range(np.size(data,0) - 1):\n",
    "        a = asstates[j]\n",
    "        b = asstates[j+1]\n",
    "        transc[a][b] = transc[a][b]+1     \n",
    "    return totc,transc\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "onepath = r'/home/subbu/PRML/1/train'\n",
    "datal=[]\n",
    "filenames=glob.glob(onepath+\"/*.mfcc\")\n",
    "k = 3\n",
    "tfv = 0\n",
    "i = 0\n",
    "pic = np.zeros(k)\n",
    "transc = np.zeros((k,k))\n",
    "for file in filenames:\n",
    "    data = np.genfromtxt(file,dtype=float,delimiter=' ',skip_header=1)\n",
    "    tfv = tfv + np.size(data,0)\n",
    "    #print(i)\n",
    "    i= i+1\n",
    "    totalcount,transcount = counter(data,k)\n",
    "    pic = pic + totalcount\n",
    "    transc = transc + transcount\n",
    "pip = pic * (1/tfv)\n",
    "transsum = transc.sum(axis = 1)\n",
    "transp = np.zeros((k,k))\n",
    "for i in range(k):\n",
    "    transp[i][i]=transc[i][i]/transsum[i]\n",
    "    if i+1 != k:\n",
    "        transp[i][i+1]=transc[i][i+1]/transsum[i]\n",
    "\n",
    "#datal.append(data)\n",
    "#comb_np = np.vstack(datal)\n",
    "#oneframe = pd.DataFrame(comb_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.34014327 0.29663041 0.36322632]\n",
      "[[0.95429472 0.01891253 0.        ]\n",
      " [0.         0.93333333 0.04234234]\n",
      " [0.         0.         0.94300518]]\n"
     ]
    }
   ],
   "source": [
    "print(pip)\n",
    "print(transp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
