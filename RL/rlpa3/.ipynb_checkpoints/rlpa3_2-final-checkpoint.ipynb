{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import gym\n",
    "import random as rd\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Observations\n",
    "    1. On decreasing target update freq the varience of model increasing and on increasing convergence is taking longer\n",
    "    2. low discount factors unable to clearly differentiate the increase in steps after some treshlod\n",
    "    3. Increasing mini batch helping to achieve convergence faster\n",
    "    4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing DQN class\n",
    "\n",
    "class DQN:\n",
    "\n",
    "    REPLAY_MEMORY_SIZE = 4096 \t\t\t# number of tuples in experience replay  \n",
    "    EPSILON = 0.5 \t\t\t\t\t\t# epsilon of epsilon-greedy exploation\n",
    "    EPSILON_DECAY = 0.999 \t\t\t\t# exponential decay multiplier for epsilon\n",
    "    HIDDEN1_SIZE = 32 \t\t\t\t\t# size of hidden layer 1 --> try 16*\n",
    "    HIDDEN2_SIZE = 16 \t\t\t\t\t# size of hidden layer 2\n",
    "    EPISODES_NUM = 1000 \t\t\t\t# number of episodes to train on. Ideally shouldn't take longer than 2000\n",
    "    MAX_STEPS = 200 \t\t\t\t\t# maximum number of steps in an episode \n",
    "    LEARNING_RATE = 0.001 \t\t\t\t# learning rate and other parameters for SGD/RMSProp/Adam --> try 0.001*, 0.003\n",
    "    MINIBATCH_SIZE = 16 \t\t\t\t# size of minibatch sampled from the experience replay --> try 16*, 8\n",
    "    DISCOUNT_FACTOR = 0.999 \t\t\t\t# MDP's gamma --> try 0.999*, 0.99\n",
    "    TARGET_UPDATE_FREQ = 50 \t\t\t# number of steps (not episodes) after which to update the target networks --> try 50, 20*     \n",
    "    LOG_DIR = './logs' \t\t\t\t\t# directory wherein logging takes place\n",
    "    EPSILON_MIN = 0.05\n",
    "\n",
    "\n",
    "    # Create and initialize the environment\n",
    "    def __init__(self, env):\n",
    "        self.env = gym.make(env)\n",
    "        assert len(self.env.observation_space.shape) == 1\n",
    "        self.input_size = self.env.observation_space.shape[0]\t\t# In case of cartpole, 4 state features\n",
    "        self.output_size = self.env.action_space.n\t\t\t\t\t# In case of cartpole, 2 actions (right/left)\n",
    "        self.eps = self.EPSILON\n",
    "        self.episodic_rewards = []\n",
    "        self.episodic_steps = []\n",
    "\n",
    "    # Create the Q-network\n",
    "    def initialize_network(self):\n",
    "        \n",
    "        ############################################################\n",
    "        # Design your q-network here.\n",
    "        # \n",
    "        # Add hidden layers and the output layer. For instance:\n",
    "        # \n",
    "        # with tf.name_scope('output'):\n",
    "        #\tW_n = tf.Variable(\n",
    "        # \t\t\t tf.truncated_normal([self.HIDDEN_n-1_SIZE, self.output_size], \n",
    "        # \t\t\t stddev=0.01), name='W_n')\n",
    "        # \tb_n = tf.Variable(tf.zeros(self.output_size), name='b_n')\n",
    "        # \tself.Q = tf.matmul(h_n-1, W_n) + b_n\n",
    "        #\n",
    "        #############################################################\n",
    "        \n",
    "        # Model designed using keras layers\n",
    "        self.model = keras.Sequential([\n",
    "                layers.InputLayer(input_shape=(self.input_size,)),\n",
    "                layers.Dense(self.HIDDEN1_SIZE, activation='relu', name='hidden1', kernel_initializer='RandomNormal'),\n",
    "                layers.Dense(self.HIDDEN2_SIZE, activation='relu', name='hidden2', kernel_initializer='RandomNormal'),\n",
    "                layers.Dense(self.output_size, activation='linear', name='output', kernel_initializer='RandomNormal')\n",
    "        ])\n",
    "\n",
    "        ############################################################\n",
    "        # Next, compute the loss.\n",
    "        #\n",
    "        # First, compute the q-values. Note that you need to calculate these\n",
    "        # for the actions in the (s,a,s',r) tuples from the experience replay's minibatch\n",
    "        #\n",
    "        # Next, compute the l2 loss between these estimated q-values and \n",
    "        # the target (which is computed using the frozen target network)\n",
    "        #\n",
    "        ############################################################\n",
    "        \n",
    "        ############################################################\n",
    "        # Finally, choose a gradient descent algorithm : SGD/RMSProp/Adam. \n",
    "        #\n",
    "        # For instance:\n",
    "        # optimizer = tf.train.GradientDescentOptimizer(self.LEARNING_RATE)\n",
    "        # global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        # self.train_op = optimizer.minimize(self.loss, global_step=global_step)\n",
    "        #\n",
    "        ############################################################\n",
    "\n",
    "        # Assigned descent algo. and loss function in one line\n",
    "        self.model.compile(loss=keras.losses.MeanSquaredError(),optimizer=keras.optimizers.Adam(lr=self.LEARNING_RATE))\n",
    "        self.model.summary()\n",
    "        \n",
    "        # create a target model a clone to our model i.e. target network\n",
    "        self.target_model = keras.models.clone_model(self.model)\n",
    "        self.target_model.build((None, self.input_size))\n",
    "        self.target_model.compile(loss=keras.losses.MeanSquaredError(),optimizer=keras.optimizers.Adam(lr=self.LEARNING_RATE))\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "        ############################################################\n",
    "\n",
    "    def train(self, episodes_num=EPISODES_NUM):\n",
    "\n",
    "        # Initialize summary for TensorBoard \n",
    "        summary_writer = tf.summary.create_file_writer(self.LOG_DIR)\n",
    "        summary = tf.summary\n",
    "        # Alternatively, you could use animated real-time plots from matplotlib \n",
    "        # (https://stackoverflow.com/a/24228275/3284912)\n",
    "\n",
    "        ############################################################\n",
    "        # Initialize other variables (like the replay memory)\n",
    "        ############################################################\n",
    "        \n",
    "        # Using deque\n",
    "        self.replay_buffer = deque(maxlen=self.REPLAY_MEMORY_SIZE)\n",
    "        total_steps = 0\n",
    "\n",
    "        ############################################################\n",
    "        # Main training loop\n",
    "        # \n",
    "        # In each episode, \n",
    "        #\tpick the action for the given state, \n",
    "        #\tperform a 'step' in the environment to get the reward and next state,\n",
    "        #\tupdate the replay buffer,\n",
    "        #\tsample a random minibatch from the replay buffer,\n",
    "        # \tperform Q-learning,\n",
    "        #\tupdate the target network, if required.\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        # You'll need to write code in various places in the following skeleton\n",
    "        #\n",
    "        ############################################################\n",
    "\n",
    "        for episode in range(episodes_num):\n",
    "\n",
    "            state = np.array([self.env.reset()])\n",
    "\n",
    "            ############################################################\n",
    "            # Episode-specific initializations go here.\n",
    "            ############################################################\n",
    "            \n",
    "            episode_length = 0\n",
    "            score = 0\n",
    "            \n",
    "            ############################################################\n",
    "\n",
    "            while True:\n",
    "                ############################################################\n",
    "                # Pick the next action using epsilon greedy and execute it\n",
    "                ############################################################\n",
    "                episode_length += 1\n",
    "                total_steps += 1\n",
    "                if(rd.random() < self.eps):\n",
    "                    act = self.env.action_space.sample()\n",
    "                else:\n",
    "                    act = np.argmax(self.model.predict(state)[0])\n",
    "\n",
    "                ############################################################\n",
    "                # Step in the environment. Something like: \n",
    "                # next_state, reward, done, _ = self.env.step(action)\n",
    "                ############################################################\n",
    "\n",
    "                next_state, reward, done, _ = self.env.step(act)\n",
    "                next_state = np.array([next_state])\n",
    "                \n",
    "                ############################################################\n",
    "                # Update the (limited) replay buffer. \n",
    "                #\n",
    "                # Note : when the replay buffer is full, you'll need to \n",
    "                # remove an entry to accommodate a new one.\n",
    "                ############################################################\n",
    "\n",
    "                # The max length in deque removes oldest if buffer size exceeds it\n",
    "                self.replay_buffer.append((state,act,reward,next_state,done))\n",
    "                score += reward\n",
    "                state = next_state\n",
    "\n",
    "                ############################################################\n",
    "                # Sample a random minibatch and perform Q-learning (fetch max Q at s') \n",
    "                #\n",
    "                # Remember, the target (r + gamma * max Q) is computed    \n",
    "                # with the help of the target network.\n",
    "                # Compute this target and pass it to the network for computing \n",
    "                # and minimizing the loss with the current estimates\n",
    "                #\n",
    "                ############################################################\n",
    "                \n",
    "                # not starting network update until it has a batch size elements\n",
    "                if len(self.replay_buffer) == self.REPLAY_MEMORY_SIZE:\n",
    "                    batch_states = []\n",
    "                    batch_targets = []\n",
    "                    replay_batch = rd.sample(self.replay_buffer,self.MINIBATCH_SIZE)\n",
    "                    for st, act, rwd, nst, d in replay_batch:\n",
    "                        if d:\n",
    "                            y = rwd\n",
    "                        else:\n",
    "                            y = (rwd + self.DISCOUNT_FACTOR * np.max(self.target_model.predict(nst)[0]))\n",
    "                        tgt = self.model.predict(st)[0]\n",
    "                        tgt[act] = y\n",
    "                        batch_states.append(st[0])\n",
    "                        batch_targets.append(tgt)\n",
    "                        \n",
    "                    batch_states = np.array(batch_states)\n",
    "                    batch_targets = np.array(batch_targets)\n",
    "                    self.model.fit(batch_states, batch_targets, epochs=1, verbose = 0, workers=8, use_multiprocessing=True)\n",
    "                    \n",
    "                    if self.eps > self.EPSILON_MIN:\n",
    "                        self.eps *= self.EPSILON_DECAY\n",
    "                    elif self.eps < self.EPSILON_MIN:\n",
    "                        self.eps = self.EPSILON_MIN\n",
    "\n",
    "                ############################################################\n",
    "                # Update target weights. \n",
    "                #\n",
    "                # Something along the lines of:\n",
    "                # if total_steps % self.TARGET_UPDATE_FREQ == 0:\n",
    "                # \ttarget_weights = self.session.run(self.weights)\n",
    "                ############################################################\n",
    "\n",
    "                if total_steps%self.TARGET_UPDATE_FREQ == 0:\n",
    "                    self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "                ############################################################\n",
    "                # Break out of the loop if the episode ends\n",
    "                #\n",
    "                # Something like:\n",
    "                # if done or (episode_length == self.MAX_STEPS):\n",
    "                # \tbreak\n",
    "                #\n",
    "                ############################################################\n",
    "                \n",
    "                if done or episode_length == self.MAX_STEPS:\n",
    "                    self.episodic_rewards.append(score)\n",
    "                    self.episodic_steps.append(episode_length)\n",
    "                    break\n",
    "\n",
    "\n",
    "            ############################################################\n",
    "            # Logging. \n",
    "            #\n",
    "            # Very important. This is what gives an idea of how good the current\n",
    "            # experiment is, and if one should terminate and re-run with new parameters\n",
    "            # The earlier you learn how to read and visualize experiment logs quickly,\n",
    "            # the faster you'll be able to prototype and learn.\n",
    "            #\n",
    "            # Use any debugging information you think you need.\n",
    "            # For instance :\n",
    "\n",
    "            print(\"Training: Episode = %d, Length = %d, Global step = %d\" % (episode, episode_length, total_steps),end=', ')\n",
    "            print('Eps: '+str(self.eps))\n",
    "            with summary_writer.as_default():\n",
    "                summary.scalar(\"episode length\",episode ,step=episode_length)\n",
    "    \n",
    "    def save_model(self, name):\n",
    "        self.target_model.save(name)\n",
    "        \n",
    "    def load_model(self, name):\n",
    "        self.model = keras.models.load_model(name)\n",
    "        self.target_model = keras.models.load_model(name)\n",
    "\n",
    "    # Simple function to visually 'test' a policy\n",
    "    def playPolicy(self):\n",
    "\n",
    "        done = False\n",
    "        steps = 0\n",
    "        state = self.env.reset()\n",
    "\n",
    "        # we assume the CartPole task to be solved if the pole remains upright for 200 steps\n",
    "        while not done and steps < 200: \n",
    "            # self.env.render()\n",
    "            action = np.argmax(self.target_model.predict(np.array([state]))[0])\n",
    "            state, _, done, _ = self.env.step(action)\n",
    "            steps += 1\n",
    "\n",
    "        return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 722\n",
      "Trainable params: 722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Training: Episode = 0, Length = 15, Global step = 15, Eps: 0.5\n",
      "Training: Episode = 1, Length = 9, Global step = 24, Eps: 0.5\n",
      "Training: Episode = 2, Length = 14, Global step = 38, Eps: 0.5\n",
      "Training: Episode = 3, Length = 8, Global step = 46, Eps: 0.5\n",
      "Training: Episode = 4, Length = 8, Global step = 54, Eps: 0.5\n",
      "Training: Episode = 5, Length = 14, Global step = 68, Eps: 0.5\n",
      "Training: Episode = 6, Length = 21, Global step = 89, Eps: 0.5\n",
      "Training: Episode = 7, Length = 13, Global step = 102, Eps: 0.5\n",
      "Training: Episode = 8, Length = 27, Global step = 129, Eps: 0.5\n",
      "Training: Episode = 9, Length = 9, Global step = 138, Eps: 0.5\n",
      "Training: Episode = 10, Length = 21, Global step = 159, Eps: 0.5\n",
      "Training: Episode = 11, Length = 13, Global step = 172, Eps: 0.5\n",
      "Training: Episode = 12, Length = 10, Global step = 182, Eps: 0.5\n",
      "Training: Episode = 13, Length = 14, Global step = 196, Eps: 0.5\n",
      "Training: Episode = 14, Length = 11, Global step = 207, Eps: 0.5\n",
      "Training: Episode = 15, Length = 11, Global step = 218, Eps: 0.5\n",
      "Training: Episode = 16, Length = 9, Global step = 227, Eps: 0.5\n",
      "Training: Episode = 17, Length = 16, Global step = 243, Eps: 0.5\n",
      "Training: Episode = 18, Length = 11, Global step = 254, Eps: 0.5\n",
      "Training: Episode = 19, Length = 13, Global step = 267, Eps: 0.5\n",
      "Training: Episode = 20, Length = 9, Global step = 276, Eps: 0.5\n",
      "Training: Episode = 21, Length = 42, Global step = 318, Eps: 0.5\n",
      "Training: Episode = 22, Length = 14, Global step = 332, Eps: 0.5\n",
      "Training: Episode = 23, Length = 12, Global step = 344, Eps: 0.5\n",
      "Training: Episode = 24, Length = 9, Global step = 353, Eps: 0.5\n",
      "Training: Episode = 25, Length = 11, Global step = 364, Eps: 0.5\n",
      "Training: Episode = 26, Length = 10, Global step = 374, Eps: 0.5\n",
      "Training: Episode = 27, Length = 19, Global step = 393, Eps: 0.5\n",
      "Training: Episode = 28, Length = 25, Global step = 418, Eps: 0.5\n",
      "Training: Episode = 29, Length = 20, Global step = 438, Eps: 0.5\n",
      "Training: Episode = 30, Length = 16, Global step = 454, Eps: 0.5\n",
      "Training: Episode = 31, Length = 11, Global step = 465, Eps: 0.5\n",
      "Training: Episode = 32, Length = 11, Global step = 476, Eps: 0.5\n",
      "Training: Episode = 33, Length = 24, Global step = 500, Eps: 0.5\n",
      "Training: Episode = 34, Length = 11, Global step = 511, Eps: 0.5\n",
      "Training: Episode = 35, Length = 11, Global step = 522, Eps: 0.5\n",
      "Training: Episode = 36, Length = 14, Global step = 536, Eps: 0.5\n",
      "Training: Episode = 37, Length = 12, Global step = 548, Eps: 0.5\n",
      "Training: Episode = 38, Length = 9, Global step = 557, Eps: 0.5\n",
      "Training: Episode = 39, Length = 21, Global step = 578, Eps: 0.5\n",
      "Training: Episode = 40, Length = 16, Global step = 594, Eps: 0.5\n",
      "Training: Episode = 41, Length = 8, Global step = 602, Eps: 0.5\n",
      "Training: Episode = 42, Length = 20, Global step = 622, Eps: 0.5\n",
      "Training: Episode = 43, Length = 10, Global step = 632, Eps: 0.5\n",
      "Training: Episode = 44, Length = 11, Global step = 643, Eps: 0.5\n",
      "Training: Episode = 45, Length = 13, Global step = 656, Eps: 0.5\n",
      "Training: Episode = 46, Length = 11, Global step = 667, Eps: 0.5\n",
      "Training: Episode = 47, Length = 15, Global step = 682, Eps: 0.5\n",
      "Training: Episode = 48, Length = 15, Global step = 697, Eps: 0.5\n",
      "Training: Episode = 49, Length = 15, Global step = 712, Eps: 0.5\n",
      "Training: Episode = 50, Length = 12, Global step = 724, Eps: 0.5\n",
      "Training: Episode = 51, Length = 9, Global step = 733, Eps: 0.5\n",
      "Training: Episode = 52, Length = 12, Global step = 745, Eps: 0.5\n",
      "Training: Episode = 53, Length = 9, Global step = 754, Eps: 0.5\n",
      "Training: Episode = 54, Length = 14, Global step = 768, Eps: 0.5\n",
      "Training: Episode = 55, Length = 18, Global step = 786, Eps: 0.5\n",
      "Training: Episode = 56, Length = 13, Global step = 799, Eps: 0.5\n",
      "Training: Episode = 57, Length = 37, Global step = 836, Eps: 0.5\n",
      "Training: Episode = 58, Length = 14, Global step = 850, Eps: 0.5\n",
      "Training: Episode = 59, Length = 14, Global step = 864, Eps: 0.5\n",
      "Training: Episode = 60, Length = 18, Global step = 882, Eps: 0.5\n",
      "Training: Episode = 61, Length = 10, Global step = 892, Eps: 0.5\n",
      "Training: Episode = 62, Length = 15, Global step = 907, Eps: 0.5\n",
      "Training: Episode = 63, Length = 17, Global step = 924, Eps: 0.5\n",
      "Training: Episode = 64, Length = 17, Global step = 941, Eps: 0.5\n",
      "Training: Episode = 65, Length = 12, Global step = 953, Eps: 0.5\n",
      "Training: Episode = 66, Length = 17, Global step = 970, Eps: 0.5\n",
      "Training: Episode = 67, Length = 19, Global step = 989, Eps: 0.5\n",
      "Training: Episode = 68, Length = 20, Global step = 1009, Eps: 0.5\n",
      "Training: Episode = 69, Length = 10, Global step = 1019, Eps: 0.5\n",
      "Training: Episode = 70, Length = 15, Global step = 1034, Eps: 0.5\n",
      "Training: Episode = 71, Length = 13, Global step = 1047, Eps: 0.5\n",
      "Training: Episode = 72, Length = 30, Global step = 1077, Eps: 0.5\n",
      "Training: Episode = 73, Length = 12, Global step = 1089, Eps: 0.5\n",
      "Training: Episode = 74, Length = 10, Global step = 1099, Eps: 0.5\n",
      "Training: Episode = 75, Length = 24, Global step = 1123, Eps: 0.5\n",
      "Training: Episode = 76, Length = 10, Global step = 1133, Eps: 0.5\n",
      "Training: Episode = 77, Length = 11, Global step = 1144, Eps: 0.5\n",
      "Training: Episode = 78, Length = 14, Global step = 1158, Eps: 0.5\n",
      "Training: Episode = 79, Length = 11, Global step = 1169, Eps: 0.5\n",
      "Training: Episode = 80, Length = 14, Global step = 1183, Eps: 0.5\n",
      "Training: Episode = 81, Length = 40, Global step = 1223, Eps: 0.5\n",
      "Training: Episode = 82, Length = 13, Global step = 1236, Eps: 0.5\n",
      "Training: Episode = 83, Length = 18, Global step = 1254, Eps: 0.5\n",
      "Training: Episode = 84, Length = 8, Global step = 1262, Eps: 0.5\n",
      "Training: Episode = 85, Length = 17, Global step = 1279, Eps: 0.5\n",
      "Training: Episode = 86, Length = 9, Global step = 1288, Eps: 0.5\n",
      "Training: Episode = 87, Length = 11, Global step = 1299, Eps: 0.5\n",
      "Training: Episode = 88, Length = 20, Global step = 1319, Eps: 0.5\n",
      "Training: Episode = 89, Length = 13, Global step = 1332, Eps: 0.5\n",
      "Training: Episode = 90, Length = 12, Global step = 1344, Eps: 0.5\n",
      "Training: Episode = 91, Length = 9, Global step = 1353, Eps: 0.5\n",
      "Training: Episode = 92, Length = 16, Global step = 1369, Eps: 0.5\n",
      "Training: Episode = 93, Length = 15, Global step = 1384, Eps: 0.5\n",
      "Training: Episode = 94, Length = 18, Global step = 1402, Eps: 0.5\n",
      "Training: Episode = 95, Length = 12, Global step = 1414, Eps: 0.5\n",
      "Training: Episode = 96, Length = 16, Global step = 1430, Eps: 0.5\n",
      "Training: Episode = 97, Length = 34, Global step = 1464, Eps: 0.5\n",
      "Training: Episode = 98, Length = 8, Global step = 1472, Eps: 0.5\n",
      "Training: Episode = 99, Length = 9, Global step = 1481, Eps: 0.5\n",
      "Training: Episode = 100, Length = 11, Global step = 1492, Eps: 0.5\n",
      "Training: Episode = 101, Length = 9, Global step = 1501, Eps: 0.5\n",
      "Training: Episode = 102, Length = 25, Global step = 1526, Eps: 0.5\n",
      "Training: Episode = 103, Length = 15, Global step = 1541, Eps: 0.5\n",
      "Training: Episode = 104, Length = 10, Global step = 1551, Eps: 0.5\n",
      "Training: Episode = 105, Length = 25, Global step = 1576, Eps: 0.5\n",
      "Training: Episode = 106, Length = 10, Global step = 1586, Eps: 0.5\n",
      "Training: Episode = 107, Length = 14, Global step = 1600, Eps: 0.5\n",
      "Training: Episode = 108, Length = 10, Global step = 1610, Eps: 0.5\n",
      "Training: Episode = 109, Length = 11, Global step = 1621, Eps: 0.5\n",
      "Training: Episode = 110, Length = 14, Global step = 1635, Eps: 0.5\n",
      "Training: Episode = 111, Length = 37, Global step = 1672, Eps: 0.5\n",
      "Training: Episode = 112, Length = 9, Global step = 1681, Eps: 0.5\n",
      "Training: Episode = 113, Length = 13, Global step = 1694, Eps: 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Episode = 114, Length = 17, Global step = 1711, Eps: 0.5\n",
      "Training: Episode = 115, Length = 9, Global step = 1720, Eps: 0.5\n",
      "Training: Episode = 116, Length = 10, Global step = 1730, Eps: 0.5\n",
      "Training: Episode = 117, Length = 9, Global step = 1739, Eps: 0.5\n",
      "Training: Episode = 118, Length = 13, Global step = 1752, Eps: 0.5\n",
      "Training: Episode = 119, Length = 9, Global step = 1761, Eps: 0.5\n",
      "Training: Episode = 120, Length = 10, Global step = 1771, Eps: 0.5\n",
      "Training: Episode = 121, Length = 13, Global step = 1784, Eps: 0.5\n",
      "Training: Episode = 122, Length = 12, Global step = 1796, Eps: 0.5\n",
      "Training: Episode = 123, Length = 19, Global step = 1815, Eps: 0.5\n",
      "Training: Episode = 124, Length = 11, Global step = 1826, Eps: 0.5\n",
      "Training: Episode = 125, Length = 12, Global step = 1838, Eps: 0.5\n",
      "Training: Episode = 126, Length = 11, Global step = 1849, Eps: 0.5\n",
      "Training: Episode = 127, Length = 12, Global step = 1861, Eps: 0.5\n",
      "Training: Episode = 128, Length = 12, Global step = 1873, Eps: 0.5\n",
      "Training: Episode = 129, Length = 14, Global step = 1887, Eps: 0.5\n",
      "Training: Episode = 130, Length = 20, Global step = 1907, Eps: 0.5\n",
      "Training: Episode = 131, Length = 33, Global step = 1940, Eps: 0.5\n",
      "Training: Episode = 132, Length = 17, Global step = 1957, Eps: 0.5\n",
      "Training: Episode = 133, Length = 14, Global step = 1971, Eps: 0.5\n",
      "Training: Episode = 134, Length = 11, Global step = 1982, Eps: 0.5\n",
      "Training: Episode = 135, Length = 13, Global step = 1995, Eps: 0.5\n",
      "Training: Episode = 136, Length = 16, Global step = 2011, Eps: 0.5\n",
      "Training: Episode = 137, Length = 10, Global step = 2021, Eps: 0.5\n",
      "Training: Episode = 138, Length = 9, Global step = 2030, Eps: 0.5\n",
      "Training: Episode = 139, Length = 15, Global step = 2045, Eps: 0.5\n",
      "Training: Episode = 140, Length = 16, Global step = 2061, Eps: 0.5\n",
      "Training: Episode = 141, Length = 16, Global step = 2077, Eps: 0.5\n",
      "Training: Episode = 142, Length = 12, Global step = 2089, Eps: 0.5\n",
      "Training: Episode = 143, Length = 17, Global step = 2106, Eps: 0.5\n",
      "Training: Episode = 144, Length = 26, Global step = 2132, Eps: 0.5\n",
      "Training: Episode = 145, Length = 19, Global step = 2151, Eps: 0.5\n",
      "Training: Episode = 146, Length = 9, Global step = 2160, Eps: 0.5\n",
      "Training: Episode = 147, Length = 16, Global step = 2176, Eps: 0.5\n",
      "Training: Episode = 148, Length = 10, Global step = 2186, Eps: 0.5\n",
      "Training: Episode = 149, Length = 10, Global step = 2196, Eps: 0.5\n",
      "Training: Episode = 150, Length = 16, Global step = 2212, Eps: 0.5\n",
      "Training: Episode = 151, Length = 12, Global step = 2224, Eps: 0.5\n",
      "Training: Episode = 152, Length = 12, Global step = 2236, Eps: 0.5\n",
      "Training: Episode = 153, Length = 13, Global step = 2249, Eps: 0.5\n",
      "Training: Episode = 154, Length = 17, Global step = 2266, Eps: 0.5\n",
      "Training: Episode = 155, Length = 10, Global step = 2276, Eps: 0.5\n",
      "Training: Episode = 156, Length = 10, Global step = 2286, Eps: 0.5\n",
      "Training: Episode = 157, Length = 12, Global step = 2298, Eps: 0.5\n",
      "Training: Episode = 158, Length = 22, Global step = 2320, Eps: 0.5\n",
      "Training: Episode = 159, Length = 12, Global step = 2332, Eps: 0.5\n",
      "Training: Episode = 160, Length = 13, Global step = 2345, Eps: 0.5\n",
      "Training: Episode = 161, Length = 11, Global step = 2356, Eps: 0.5\n",
      "Training: Episode = 162, Length = 16, Global step = 2372, Eps: 0.5\n",
      "Training: Episode = 163, Length = 15, Global step = 2387, Eps: 0.5\n",
      "Training: Episode = 164, Length = 12, Global step = 2399, Eps: 0.5\n",
      "Training: Episode = 165, Length = 11, Global step = 2410, Eps: 0.5\n",
      "Training: Episode = 166, Length = 12, Global step = 2422, Eps: 0.5\n",
      "Training: Episode = 167, Length = 18, Global step = 2440, Eps: 0.5\n",
      "Training: Episode = 168, Length = 13, Global step = 2453, Eps: 0.5\n",
      "Training: Episode = 169, Length = 11, Global step = 2464, Eps: 0.5\n",
      "Training: Episode = 170, Length = 16, Global step = 2480, Eps: 0.5\n",
      "Training: Episode = 171, Length = 11, Global step = 2491, Eps: 0.5\n",
      "Training: Episode = 172, Length = 9, Global step = 2500, Eps: 0.5\n",
      "Training: Episode = 173, Length = 12, Global step = 2512, Eps: 0.5\n",
      "Training: Episode = 174, Length = 14, Global step = 2526, Eps: 0.5\n",
      "Training: Episode = 175, Length = 12, Global step = 2538, Eps: 0.5\n",
      "Training: Episode = 176, Length = 14, Global step = 2552, Eps: 0.5\n",
      "Training: Episode = 177, Length = 22, Global step = 2574, Eps: 0.5\n",
      "Training: Episode = 178, Length = 16, Global step = 2590, Eps: 0.5\n",
      "Training: Episode = 179, Length = 12, Global step = 2602, Eps: 0.5\n",
      "Training: Episode = 180, Length = 9, Global step = 2611, Eps: 0.5\n",
      "Training: Episode = 181, Length = 21, Global step = 2632, Eps: 0.5\n",
      "Training: Episode = 182, Length = 10, Global step = 2642, Eps: 0.5\n",
      "Training: Episode = 183, Length = 16, Global step = 2658, Eps: 0.5\n",
      "Training: Episode = 184, Length = 21, Global step = 2679, Eps: 0.5\n",
      "Training: Episode = 185, Length = 10, Global step = 2689, Eps: 0.5\n",
      "Training: Episode = 186, Length = 9, Global step = 2698, Eps: 0.5\n",
      "Training: Episode = 187, Length = 16, Global step = 2714, Eps: 0.5\n",
      "Training: Episode = 188, Length = 12, Global step = 2726, Eps: 0.5\n",
      "Training: Episode = 189, Length = 13, Global step = 2739, Eps: 0.5\n",
      "Training: Episode = 190, Length = 15, Global step = 2754, Eps: 0.5\n",
      "Training: Episode = 191, Length = 9, Global step = 2763, Eps: 0.5\n",
      "Training: Episode = 192, Length = 9, Global step = 2772, Eps: 0.5\n",
      "Training: Episode = 193, Length = 13, Global step = 2785, Eps: 0.5\n",
      "Training: Episode = 194, Length = 9, Global step = 2794, Eps: 0.5\n",
      "Training: Episode = 195, Length = 15, Global step = 2809, Eps: 0.5\n",
      "Training: Episode = 196, Length = 14, Global step = 2823, Eps: 0.5\n",
      "Training: Episode = 197, Length = 11, Global step = 2834, Eps: 0.5\n",
      "Training: Episode = 198, Length = 11, Global step = 2845, Eps: 0.5\n",
      "Training: Episode = 199, Length = 10, Global step = 2855, Eps: 0.5\n",
      "Training: Episode = 200, Length = 9, Global step = 2864, Eps: 0.5\n",
      "Training: Episode = 201, Length = 28, Global step = 2892, Eps: 0.5\n",
      "Training: Episode = 202, Length = 21, Global step = 2913, Eps: 0.5\n",
      "Training: Episode = 203, Length = 13, Global step = 2926, Eps: 0.5\n",
      "Training: Episode = 204, Length = 15, Global step = 2941, Eps: 0.5\n",
      "Training: Episode = 205, Length = 14, Global step = 2955, Eps: 0.5\n",
      "Training: Episode = 206, Length = 9, Global step = 2964, Eps: 0.5\n",
      "Training: Episode = 207, Length = 13, Global step = 2977, Eps: 0.5\n",
      "Training: Episode = 208, Length = 12, Global step = 2989, Eps: 0.5\n",
      "Training: Episode = 209, Length = 11, Global step = 3000, Eps: 0.5\n",
      "Training: Episode = 210, Length = 15, Global step = 3015, Eps: 0.5\n",
      "Training: Episode = 211, Length = 13, Global step = 3028, Eps: 0.5\n",
      "Training: Episode = 212, Length = 17, Global step = 3045, Eps: 0.5\n",
      "Training: Episode = 213, Length = 15, Global step = 3060, Eps: 0.5\n",
      "Training: Episode = 214, Length = 22, Global step = 3082, Eps: 0.5\n",
      "Training: Episode = 215, Length = 12, Global step = 3094, Eps: 0.5\n",
      "Training: Episode = 216, Length = 16, Global step = 3110, Eps: 0.5\n",
      "Training: Episode = 217, Length = 8, Global step = 3118, Eps: 0.5\n",
      "Training: Episode = 218, Length = 10, Global step = 3128, Eps: 0.5\n",
      "Training: Episode = 219, Length = 11, Global step = 3139, Eps: 0.5\n",
      "Training: Episode = 220, Length = 11, Global step = 3150, Eps: 0.5\n",
      "Training: Episode = 221, Length = 9, Global step = 3159, Eps: 0.5\n",
      "Training: Episode = 222, Length = 13, Global step = 3172, Eps: 0.5\n",
      "Training: Episode = 223, Length = 14, Global step = 3186, Eps: 0.5\n",
      "Training: Episode = 224, Length = 11, Global step = 3197, Eps: 0.5\n",
      "Training: Episode = 225, Length = 10, Global step = 3207, Eps: 0.5\n",
      "Training: Episode = 226, Length = 15, Global step = 3222, Eps: 0.5\n",
      "Training: Episode = 227, Length = 15, Global step = 3237, Eps: 0.5\n",
      "Training: Episode = 228, Length = 11, Global step = 3248, Eps: 0.5\n",
      "Training: Episode = 229, Length = 14, Global step = 3262, Eps: 0.5\n",
      "Training: Episode = 230, Length = 19, Global step = 3281, Eps: 0.5\n",
      "Training: Episode = 231, Length = 12, Global step = 3293, Eps: 0.5\n",
      "Training: Episode = 232, Length = 11, Global step = 3304, Eps: 0.5\n",
      "Training: Episode = 233, Length = 11, Global step = 3315, Eps: 0.5\n",
      "Training: Episode = 234, Length = 8, Global step = 3323, Eps: 0.5\n",
      "Training: Episode = 235, Length = 16, Global step = 3339, Eps: 0.5\n",
      "Training: Episode = 236, Length = 16, Global step = 3355, Eps: 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Episode = 237, Length = 14, Global step = 3369, Eps: 0.5\n",
      "Training: Episode = 238, Length = 10, Global step = 3379, Eps: 0.5\n",
      "Training: Episode = 239, Length = 11, Global step = 3390, Eps: 0.5\n",
      "Training: Episode = 240, Length = 14, Global step = 3404, Eps: 0.5\n",
      "Training: Episode = 241, Length = 14, Global step = 3418, Eps: 0.5\n",
      "Training: Episode = 242, Length = 21, Global step = 3439, Eps: 0.5\n",
      "Training: Episode = 243, Length = 11, Global step = 3450, Eps: 0.5\n",
      "Training: Episode = 244, Length = 22, Global step = 3472, Eps: 0.5\n",
      "Training: Episode = 245, Length = 9, Global step = 3481, Eps: 0.5\n",
      "Training: Episode = 246, Length = 8, Global step = 3489, Eps: 0.5\n",
      "Training: Episode = 247, Length = 13, Global step = 3502, Eps: 0.5\n",
      "Training: Episode = 248, Length = 15, Global step = 3517, Eps: 0.5\n",
      "Training: Episode = 249, Length = 13, Global step = 3530, Eps: 0.5\n",
      "Training: Episode = 250, Length = 14, Global step = 3544, Eps: 0.5\n",
      "Training: Episode = 251, Length = 13, Global step = 3557, Eps: 0.5\n",
      "Training: Episode = 252, Length = 11, Global step = 3568, Eps: 0.5\n",
      "Training: Episode = 253, Length = 22, Global step = 3590, Eps: 0.5\n",
      "Training: Episode = 254, Length = 10, Global step = 3600, Eps: 0.5\n",
      "Training: Episode = 255, Length = 14, Global step = 3614, Eps: 0.5\n",
      "Training: Episode = 256, Length = 9, Global step = 3623, Eps: 0.5\n",
      "Training: Episode = 257, Length = 12, Global step = 3635, Eps: 0.5\n",
      "Training: Episode = 258, Length = 10, Global step = 3645, Eps: 0.5\n",
      "Training: Episode = 259, Length = 18, Global step = 3663, Eps: 0.5\n",
      "Training: Episode = 260, Length = 12, Global step = 3675, Eps: 0.5\n",
      "Training: Episode = 261, Length = 11, Global step = 3686, Eps: 0.5\n",
      "Training: Episode = 262, Length = 17, Global step = 3703, Eps: 0.5\n",
      "Training: Episode = 263, Length = 15, Global step = 3718, Eps: 0.5\n",
      "Training: Episode = 264, Length = 15, Global step = 3733, Eps: 0.5\n",
      "Training: Episode = 265, Length = 13, Global step = 3746, Eps: 0.5\n",
      "Training: Episode = 266, Length = 10, Global step = 3756, Eps: 0.5\n",
      "Training: Episode = 267, Length = 8, Global step = 3764, Eps: 0.5\n",
      "Training: Episode = 268, Length = 15, Global step = 3779, Eps: 0.5\n",
      "Training: Episode = 269, Length = 12, Global step = 3791, Eps: 0.5\n",
      "Training: Episode = 270, Length = 17, Global step = 3808, Eps: 0.5\n",
      "Training: Episode = 271, Length = 19, Global step = 3827, Eps: 0.5\n",
      "Training: Episode = 272, Length = 18, Global step = 3845, Eps: 0.5\n",
      "Training: Episode = 273, Length = 13, Global step = 3858, Eps: 0.5\n",
      "Training: Episode = 274, Length = 10, Global step = 3868, Eps: 0.5\n",
      "Training: Episode = 275, Length = 15, Global step = 3883, Eps: 0.5\n",
      "Training: Episode = 276, Length = 13, Global step = 3896, Eps: 0.5\n",
      "Training: Episode = 277, Length = 11, Global step = 3907, Eps: 0.5\n",
      "Training: Episode = 278, Length = 9, Global step = 3916, Eps: 0.5\n",
      "Training: Episode = 279, Length = 11, Global step = 3927, Eps: 0.5\n",
      "Training: Episode = 280, Length = 10, Global step = 3937, Eps: 0.5\n",
      "Training: Episode = 281, Length = 11, Global step = 3948, Eps: 0.5\n",
      "Training: Episode = 282, Length = 10, Global step = 3958, Eps: 0.5\n",
      "Training: Episode = 283, Length = 15, Global step = 3973, Eps: 0.5\n",
      "Training: Episode = 284, Length = 13, Global step = 3986, Eps: 0.5\n",
      "Training: Episode = 285, Length = 10, Global step = 3996, Eps: 0.5\n",
      "Training: Episode = 286, Length = 19, Global step = 4015, Eps: 0.5\n",
      "Training: Episode = 287, Length = 15, Global step = 4030, Eps: 0.5\n",
      "Training: Episode = 288, Length = 9, Global step = 4039, Eps: 0.5\n",
      "Training: Episode = 289, Length = 10, Global step = 4049, Eps: 0.5\n",
      "Training: Episode = 290, Length = 12, Global step = 4061, Eps: 0.5\n",
      "Training: Episode = 291, Length = 12, Global step = 4073, Eps: 0.5\n",
      "Training: Episode = 292, Length = 26, Global step = 4099, Eps: 0.4980029980005\n",
      "Training: Episode = 293, Length = 12, Global step = 4111, Eps: 0.49205972090782\n",
      "Training: Episode = 294, Length = 10, Global step = 4121, Eps: 0.4871612074422248\n",
      "Training: Episode = 295, Length = 13, Global step = 4134, Eps: 0.48086597133924514\n",
      "Training: Episode = 296, Length = 16, Global step = 4150, Eps: 0.4732295513025135\n",
      "Training: Episode = 297, Length = 15, Global step = 4165, Eps: 0.46618058246095634\n",
      "Training: Episode = 298, Length = 12, Global step = 4177, Eps: 0.4606170810605298\n",
      "Training: Episode = 299, Length = 8, Global step = 4185, Eps: 0.4569450159279762\n",
      "Training: Episode = 300, Length = 16, Global step = 4201, Eps: 0.4496884740154788\n",
      "Training: Episode = 301, Length = 10, Global step = 4211, Eps: 0.44521177138835916\n",
      "Training: Episode = 302, Length = 13, Global step = 4224, Eps: 0.4394586178656664\n",
      "Training: Episode = 303, Length = 15, Global step = 4239, Eps: 0.4329126823974297\n",
      "Training: Episode = 304, Length = 18, Global step = 4257, Eps: 0.42518613781894554\n",
      "Training: Episode = 305, Length = 10, Global step = 4267, Eps: 0.4209533588838034\n",
      "Training: Episode = 306, Length = 12, Global step = 4279, Eps: 0.415929609097184\n",
      "Training: Episode = 307, Length = 13, Global step = 4292, Eps: 0.41055484802941705\n",
      "Training: Episode = 308, Length = 9, Global step = 4301, Eps: 0.4068745999367523\n",
      "Training: Episode = 309, Length = 9, Global step = 4310, Eps: 0.40322734189666776\n",
      "Training: Episode = 310, Length = 10, Global step = 4320, Eps: 0.39921316540538165\n",
      "Training: Episode = 311, Length = 14, Global step = 4334, Eps: 0.39366036457298037\n",
      "Training: Episode = 312, Length = 13, Global step = 4347, Eps: 0.38857337303606526\n",
      "Training: Episode = 313, Length = 11, Global step = 4358, Eps: 0.38432037348162884\n",
      "Training: Episode = 314, Length = 8, Global step = 4366, Eps: 0.3812565499691733\n",
      "Training: Episode = 315, Length = 9, Global step = 4375, Eps: 0.3778389342776898\n",
      "Training: Episode = 316, Length = 24, Global step = 4399, Eps: 0.36887432265379033\n",
      "Training: Episode = 317, Length = 38, Global step = 4437, Eps: 0.35511333226230424\n",
      "Training: Episode = 318, Length = 12, Global step = 4449, Eps: 0.35087533180565295\n",
      "Training: Episode = 319, Length = 9, Global step = 4458, Eps: 0.34773005590198536\n",
      "Training: Episode = 320, Length = 9, Global step = 4467, Eps: 0.3446129745153255\n",
      "Training: Episode = 321, Length = 16, Global step = 4483, Eps: 0.33914032812244943\n",
      "Training: Episode = 322, Length = 21, Global step = 4504, Eps: 0.33208915166701936\n",
      "Training: Episode = 323, Length = 9, Global step = 4513, Eps: 0.32911227665778886\n",
      "Training: Episode = 324, Length = 11, Global step = 4524, Eps: 0.32551008859469893\n",
      "Training: Episode = 325, Length = 11, Global step = 4535, Eps: 0.32194732707313334\n",
      "Training: Episode = 326, Length = 9, Global step = 4544, Eps: 0.3190613642301991\n",
      "Training: Episode = 327, Length = 14, Global step = 4558, Eps: 0.3146234238955273\n",
      "Training: Episode = 328, Length = 9, Global step = 4567, Eps: 0.311803113134963\n",
      "Training: Episode = 329, Length = 13, Global step = 4580, Eps: 0.30777390435388113\n",
      "Training: Episode = 330, Length = 11, Global step = 4591, Eps: 0.3044052682894572\n",
      "Training: Episode = 331, Length = 10, Global step = 4601, Eps: 0.3013748773788519\n",
      "Training: Episode = 332, Length = 13, Global step = 4614, Eps: 0.29748042523524315\n",
      "Training: Episode = 333, Length = 10, Global step = 4624, Eps: 0.2945189719667712\n",
      "Training: Episode = 334, Length = 10, Global step = 4634, Eps: 0.2915870003203402\n",
      "Training: Episode = 335, Length = 14, Global step = 4648, Eps: 0.2875312108865121\n",
      "Training: Episode = 336, Length = 9, Global step = 4657, Eps: 0.28495375699569636\n",
      "Training: Episode = 337, Length = 11, Global step = 4668, Eps: 0.28183489120191174\n",
      "Training: Episode = 338, Length = 9, Global step = 4677, Eps: 0.2793084995985226\n",
      "Training: Episode = 339, Length = 11, Global step = 4688, Eps: 0.2762514220765573\n",
      "Training: Episode = 340, Length = 9, Global step = 4697, Eps: 0.2737750811587165\n",
      "Training: Episode = 341, Length = 17, Global step = 4714, Eps: 0.2691579526728947\n",
      "Training: Episode = 342, Length = 12, Global step = 4726, Eps: 0.265945762583967\n",
      "Training: Episode = 343, Length = 15, Global step = 4741, Eps: 0.26198437980717554\n",
      "Training: Episode = 344, Length = 9, Global step = 4750, Eps: 0.25963592985287315\n",
      "Training: Episode = 345, Length = 9, Global step = 4759, Eps: 0.25730853160093536\n",
      "Training: Episode = 346, Length = 10, Global step = 4769, Eps: 0.2547469943457943\n",
      "Training: Episode = 347, Length = 10, Global step = 4779, Eps: 0.25221095750087535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Episode = 348, Length = 17, Global step = 4796, Eps: 0.2479575010088339\n",
      "Training: Episode = 349, Length = 8, Global step = 4804, Eps: 0.24598076994251455\n",
      "Training: Episode = 350, Length = 11, Global step = 4815, Eps: 0.2432884699097268\n",
      "Training: Episode = 351, Length = 8, Global step = 4823, Eps: 0.2413489606204687\n",
      "Training: Episode = 352, Length = 12, Global step = 4835, Eps: 0.23846864914692945\n",
      "Training: Episode = 353, Length = 8, Global step = 4843, Eps: 0.2365675637383652\n",
      "Training: Episode = 354, Length = 10, Global step = 4853, Eps: 0.23421250530286175\n",
      "Training: Episode = 355, Length = 12, Global step = 4865, Eps: 0.23141736185357617\n",
      "Training: Episode = 356, Length = 9, Global step = 4874, Eps: 0.2293429172119917\n",
      "Training: Episode = 357, Length = 15, Global step = 4889, Eps: 0.22592675042145732\n",
      "Training: Episode = 358, Length = 8, Global step = 4897, Eps: 0.22412564973100166\n",
      "Training: Episode = 359, Length = 13, Global step = 4910, Eps: 0.22122943414520363\n",
      "Training: Episode = 360, Length = 11, Global step = 4921, Eps: 0.21880804155853134\n",
      "Training: Episode = 361, Length = 16, Global step = 4937, Eps: 0.21533324772335521\n",
      "Training: Episode = 362, Length = 9, Global step = 4946, Eps: 0.2134029824298751\n",
      "Training: Episode = 363, Length = 14, Global step = 4960, Eps: 0.21043468288176212\n",
      "Training: Episode = 364, Length = 9, Global step = 4969, Eps: 0.20854832873438492\n",
      "Training: Episode = 365, Length = 9, Global step = 4978, Eps: 0.2066788840238011\n",
      "Training: Episode = 366, Length = 9, Global step = 4987, Eps: 0.20482619717240103\n",
      "Training: Episode = 367, Length = 13, Global step = 5000, Eps: 0.20217937461843435\n",
      "Training: Episode = 368, Length = 11, Global step = 5011, Eps: 0.19996648807026463\n",
      "Training: Episode = 369, Length = 11, Global step = 5022, Eps: 0.19777782192976168\n",
      "Training: Episode = 370, Length = 8, Global step = 5030, Eps: 0.19620112607161297\n",
      "Training: Episode = 371, Length = 10, Global step = 5040, Eps: 0.19424792035858773\n",
      "Training: Episode = 372, Length = 10, Global step = 5050, Eps: 0.19231415904241075\n",
      "Training: Episode = 373, Length = 41, Global step = 5091, Eps: 0.18458494539554676\n",
      "Training: Episode = 374, Length = 37, Global step = 5128, Eps: 0.17787681387539928\n",
      "Training: Episode = 375, Length = 35, Global step = 5163, Eps: 0.17175580714644242\n",
      "Training: Episode = 376, Length = 22, Global step = 5185, Eps: 0.168016591728612\n",
      "Training: Episode = 377, Length = 31, Global step = 5216, Eps: 0.1628854551238165\n",
      "Training: Episode = 378, Length = 37, Global step = 5253, Eps: 0.15696592006450702\n",
      "Training: Episode = 379, Length = 47, Global step = 5300, Eps: 0.1497556845367968\n",
      "Training: Episode = 380, Length = 53, Global step = 5353, Eps: 0.1420215318388441\n",
      "Training: Episode = 381, Length = 36, Global step = 5389, Eps: 0.1369972245364797\n",
      "Training: Episode = 382, Length = 32, Global step = 5421, Eps: 0.13268058936740468\n",
      "Training: Episode = 383, Length = 28, Global step = 5449, Eps: 0.12901525416993254\n",
      "Training: Episode = 384, Length = 30, Global step = 5479, Eps: 0.12520039789582046\n",
      "Training: Episode = 385, Length = 37, Global step = 5516, Eps: 0.12065040204615769\n",
      "Training: Episode = 386, Length = 35, Global step = 5551, Eps: 0.11649864158516128\n",
      "Training: Episode = 387, Length = 26, Global step = 5577, Eps: 0.11350723780001232\n",
      "Training: Episode = 388, Length = 45, Global step = 5622, Eps: 0.10851019037098111\n",
      "Training: Episode = 389, Length = 47, Global step = 5669, Eps: 0.10352577063572961\n",
      "Training: Episode = 390, Length = 50, Global step = 5719, Eps: 0.09847429569214099\n",
      "Training: Episode = 391, Length = 69, Global step = 5788, Eps: 0.09190551456095036\n",
      "Training: Episode = 392, Length = 40, Global step = 5828, Eps: 0.08830008059250749\n",
      "Training: Episode = 393, Length = 24, Global step = 5852, Eps: 0.08620507169570314\n",
      "Training: Episode = 394, Length = 26, Global step = 5878, Eps: 0.08399153362984461\n",
      "Training: Episode = 395, Length = 28, Global step = 5906, Eps: 0.08167124604316038\n",
      "Training: Episode = 396, Length = 43, Global step = 5949, Eps: 0.07823213369456122\n",
      "Training: Episode = 397, Length = 33, Global step = 5982, Eps: 0.0756913561974879\n",
      "Training: Episode = 398, Length = 31, Global step = 6013, Eps: 0.07337978277217472\n",
      "Training: Episode = 399, Length = 28, Global step = 6041, Eps: 0.07135264751554017\n",
      "Training: Episode = 400, Length = 44, Global step = 6085, Eps: 0.06827969524414705\n",
      "Training: Episode = 401, Length = 56, Global step = 6141, Eps: 0.06455931514783324\n",
      "Training: Episode = 402, Length = 38, Global step = 6179, Eps: 0.06215090648160016\n",
      "Training: Episode = 403, Length = 53, Global step = 6232, Eps: 0.058941114462474735\n",
      "Training: Episode = 404, Length = 31, Global step = 6263, Eps: 0.05714108443666422\n",
      "Training: Episode = 405, Length = 31, Global step = 6294, Eps: 0.055396026362493384\n",
      "Training: Episode = 406, Length = 44, Global step = 6338, Eps: 0.05301027963880381\n",
      "Training: Episode = 407, Length = 53, Global step = 6391, Eps: 0.05027255653629985\n",
      "Training: Episode = 408, Length = 44, Global step = 6435, Eps: 0.05\n",
      "Training: Episode = 409, Length = 66, Global step = 6501, Eps: 0.05\n",
      "Training: Episode = 410, Length = 37, Global step = 6538, Eps: 0.05\n",
      "Training: Episode = 411, Length = 38, Global step = 6576, Eps: 0.05\n",
      "Training: Episode = 412, Length = 29, Global step = 6605, Eps: 0.05\n",
      "Training: Episode = 413, Length = 36, Global step = 6641, Eps: 0.05\n",
      "Training: Episode = 414, Length = 40, Global step = 6681, Eps: 0.05\n",
      "Training: Episode = 415, Length = 31, Global step = 6712, Eps: 0.05\n",
      "Training: Episode = 416, Length = 37, Global step = 6749, Eps: 0.05\n",
      "Training: Episode = 417, Length = 27, Global step = 6776, Eps: 0.05\n",
      "Training: Episode = 418, Length = 32, Global step = 6808, Eps: 0.05\n",
      "Training: Episode = 419, Length = 41, Global step = 6849, Eps: 0.05\n",
      "Training: Episode = 420, Length = 42, Global step = 6891, Eps: 0.05\n",
      "Training: Episode = 421, Length = 41, Global step = 6932, Eps: 0.05\n",
      "Training: Episode = 422, Length = 45, Global step = 6977, Eps: 0.05\n",
      "Training: Episode = 423, Length = 43, Global step = 7020, Eps: 0.05\n",
      "Training: Episode = 424, Length = 27, Global step = 7047, Eps: 0.05\n",
      "Training: Episode = 425, Length = 39, Global step = 7086, Eps: 0.05\n",
      "Training: Episode = 426, Length = 43, Global step = 7129, Eps: 0.05\n",
      "Training: Episode = 427, Length = 36, Global step = 7165, Eps: 0.05\n",
      "Training: Episode = 428, Length = 33, Global step = 7198, Eps: 0.05\n",
      "Training: Episode = 429, Length = 40, Global step = 7238, Eps: 0.05\n",
      "Training: Episode = 430, Length = 31, Global step = 7269, Eps: 0.05\n",
      "Training: Episode = 431, Length = 42, Global step = 7311, Eps: 0.05\n",
      "Training: Episode = 432, Length = 37, Global step = 7348, Eps: 0.05\n",
      "Training: Episode = 433, Length = 35, Global step = 7383, Eps: 0.05\n",
      "Training: Episode = 434, Length = 41, Global step = 7424, Eps: 0.05\n",
      "Training: Episode = 435, Length = 32, Global step = 7456, Eps: 0.05\n",
      "Training: Episode = 436, Length = 27, Global step = 7483, Eps: 0.05\n",
      "Training: Episode = 437, Length = 43, Global step = 7526, Eps: 0.05\n",
      "Training: Episode = 438, Length = 43, Global step = 7569, Eps: 0.05\n",
      "Training: Episode = 439, Length = 37, Global step = 7606, Eps: 0.05\n",
      "Training: Episode = 440, Length = 44, Global step = 7650, Eps: 0.05\n",
      "Training: Episode = 441, Length = 37, Global step = 7687, Eps: 0.05\n",
      "Training: Episode = 442, Length = 41, Global step = 7728, Eps: 0.05\n",
      "Training: Episode = 443, Length = 45, Global step = 7773, Eps: 0.05\n",
      "Training: Episode = 444, Length = 35, Global step = 7808, Eps: 0.05\n",
      "Training: Episode = 445, Length = 43, Global step = 7851, Eps: 0.05\n",
      "Training: Episode = 446, Length = 41, Global step = 7892, Eps: 0.05\n",
      "Training: Episode = 447, Length = 37, Global step = 7929, Eps: 0.05\n",
      "Training: Episode = 448, Length = 30, Global step = 7959, Eps: 0.05\n",
      "Training: Episode = 449, Length = 35, Global step = 7994, Eps: 0.05\n",
      "Training: Episode = 450, Length = 40, Global step = 8034, Eps: 0.05\n",
      "Training: Episode = 451, Length = 36, Global step = 8070, Eps: 0.05\n",
      "Training: Episode = 452, Length = 58, Global step = 8128, Eps: 0.05\n",
      "Training: Episode = 453, Length = 31, Global step = 8159, Eps: 0.05\n",
      "Training: Episode = 454, Length = 86, Global step = 8245, Eps: 0.05\n",
      "Training: Episode = 455, Length = 40, Global step = 8285, Eps: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Episode = 456, Length = 36, Global step = 8321, Eps: 0.05\n",
      "Training: Episode = 457, Length = 50, Global step = 8371, Eps: 0.05\n",
      "Training: Episode = 458, Length = 33, Global step = 8404, Eps: 0.05\n",
      "Training: Episode = 459, Length = 38, Global step = 8442, Eps: 0.05\n",
      "Training: Episode = 460, Length = 70, Global step = 8512, Eps: 0.05\n",
      "Training: Episode = 461, Length = 90, Global step = 8602, Eps: 0.05\n",
      "Training: Episode = 462, Length = 46, Global step = 8648, Eps: 0.05\n",
      "Training: Episode = 463, Length = 70, Global step = 8718, Eps: 0.05\n",
      "Training: Episode = 464, Length = 127, Global step = 8845, Eps: 0.05\n",
      "Training: Episode = 465, Length = 86, Global step = 8931, Eps: 0.05\n",
      "Training: Episode = 466, Length = 91, Global step = 9022, Eps: 0.05\n",
      "Training: Episode = 467, Length = 64, Global step = 9086, Eps: 0.05\n",
      "Training: Episode = 468, Length = 52, Global step = 9138, Eps: 0.05\n",
      "Training: Episode = 469, Length = 76, Global step = 9214, Eps: 0.05\n",
      "Training: Episode = 470, Length = 111, Global step = 9325, Eps: 0.05\n",
      "Training: Episode = 471, Length = 63, Global step = 9388, Eps: 0.05\n",
      "Training: Episode = 472, Length = 60, Global step = 9448, Eps: 0.05\n",
      "Training: Episode = 473, Length = 40, Global step = 9488, Eps: 0.05\n",
      "Training: Episode = 474, Length = 40, Global step = 9528, Eps: 0.05\n",
      "Training: Episode = 475, Length = 56, Global step = 9584, Eps: 0.05\n",
      "Training: Episode = 476, Length = 88, Global step = 9672, Eps: 0.05\n",
      "Training: Episode = 477, Length = 51, Global step = 9723, Eps: 0.05\n",
      "Training: Episode = 478, Length = 74, Global step = 9797, Eps: 0.05\n",
      "Training: Episode = 479, Length = 51, Global step = 9848, Eps: 0.05\n",
      "Training: Episode = 480, Length = 68, Global step = 9916, Eps: 0.05\n",
      "Training: Episode = 481, Length = 111, Global step = 10027, Eps: 0.05\n",
      "Training: Episode = 482, Length = 105, Global step = 10132, Eps: 0.05\n",
      "Training: Episode = 483, Length = 49, Global step = 10181, Eps: 0.05\n",
      "Training: Episode = 484, Length = 58, Global step = 10239, Eps: 0.05\n",
      "Training: Episode = 485, Length = 62, Global step = 10301, Eps: 0.05\n",
      "Training: Episode = 486, Length = 73, Global step = 10374, Eps: 0.05\n",
      "Training: Episode = 487, Length = 90, Global step = 10464, Eps: 0.05\n",
      "Training: Episode = 488, Length = 61, Global step = 10525, Eps: 0.05\n",
      "Training: Episode = 489, Length = 70, Global step = 10595, Eps: 0.05\n",
      "Training: Episode = 490, Length = 51, Global step = 10646, Eps: 0.05\n",
      "Training: Episode = 491, Length = 53, Global step = 10699, Eps: 0.05\n",
      "Training: Episode = 492, Length = 55, Global step = 10754, Eps: 0.05\n",
      "Training: Episode = 493, Length = 114, Global step = 10868, Eps: 0.05\n",
      "Training: Episode = 494, Length = 52, Global step = 10920, Eps: 0.05\n",
      "Training: Episode = 495, Length = 70, Global step = 10990, Eps: 0.05\n",
      "Training: Episode = 496, Length = 79, Global step = 11069, Eps: 0.05\n",
      "Training: Episode = 497, Length = 69, Global step = 11138, Eps: 0.05\n",
      "Training: Episode = 498, Length = 59, Global step = 11197, Eps: 0.05\n",
      "Training: Episode = 499, Length = 53, Global step = 11250, Eps: 0.05\n",
      "Training: Episode = 500, Length = 111, Global step = 11361, Eps: 0.05\n",
      "Training: Episode = 501, Length = 93, Global step = 11454, Eps: 0.05\n",
      "Training: Episode = 502, Length = 115, Global step = 11569, Eps: 0.05\n",
      "Training: Episode = 503, Length = 96, Global step = 11665, Eps: 0.05\n",
      "Training: Episode = 504, Length = 52, Global step = 11717, Eps: 0.05\n",
      "Training: Episode = 505, Length = 46, Global step = 11763, Eps: 0.05\n",
      "Training: Episode = 506, Length = 69, Global step = 11832, Eps: 0.05\n",
      "Training: Episode = 507, Length = 87, Global step = 11919, Eps: 0.05\n",
      "Training: Episode = 508, Length = 200, Global step = 12119, Eps: 0.05\n",
      "Training: Episode = 509, Length = 102, Global step = 12221, Eps: 0.05\n",
      "Training: Episode = 510, Length = 69, Global step = 12290, Eps: 0.05\n",
      "Training: Episode = 511, Length = 60, Global step = 12350, Eps: 0.05\n",
      "Training: Episode = 512, Length = 70, Global step = 12420, Eps: 0.05\n",
      "Training: Episode = 513, Length = 53, Global step = 12473, Eps: 0.05\n",
      "Training: Episode = 514, Length = 104, Global step = 12577, Eps: 0.05\n",
      "Training: Episode = 515, Length = 119, Global step = 12696, Eps: 0.05\n",
      "Training: Episode = 516, Length = 88, Global step = 12784, Eps: 0.05\n",
      "Training: Episode = 517, Length = 80, Global step = 12864, Eps: 0.05\n",
      "Training: Episode = 518, Length = 83, Global step = 12947, Eps: 0.05\n",
      "Training: Episode = 519, Length = 78, Global step = 13025, Eps: 0.05\n",
      "Training: Episode = 520, Length = 88, Global step = 13113, Eps: 0.05\n",
      "Training: Episode = 521, Length = 93, Global step = 13206, Eps: 0.05\n",
      "Training: Episode = 522, Length = 89, Global step = 13295, Eps: 0.05\n",
      "Training: Episode = 523, Length = 53, Global step = 13348, Eps: 0.05\n",
      "Training: Episode = 524, Length = 107, Global step = 13455, Eps: 0.05\n",
      "Training: Episode = 525, Length = 59, Global step = 13514, Eps: 0.05\n",
      "Training: Episode = 526, Length = 77, Global step = 13591, Eps: 0.05\n",
      "Training: Episode = 527, Length = 45, Global step = 13636, Eps: 0.05\n",
      "Training: Episode = 528, Length = 32, Global step = 13668, Eps: 0.05\n",
      "Training: Episode = 529, Length = 45, Global step = 13713, Eps: 0.05\n",
      "Training: Episode = 530, Length = 65, Global step = 13778, Eps: 0.05\n",
      "Training: Episode = 531, Length = 45, Global step = 13823, Eps: 0.05\n",
      "Training: Episode = 532, Length = 58, Global step = 13881, Eps: 0.05\n",
      "Training: Episode = 533, Length = 100, Global step = 13981, Eps: 0.05\n",
      "Training: Episode = 534, Length = 63, Global step = 14044, Eps: 0.05\n",
      "Training: Episode = 535, Length = 87, Global step = 14131, Eps: 0.05\n",
      "Training: Episode = 536, Length = 46, Global step = 14177, Eps: 0.05\n",
      "Training: Episode = 537, Length = 57, Global step = 14234, Eps: 0.05\n",
      "Training: Episode = 538, Length = 148, Global step = 14382, Eps: 0.05\n",
      "Training: Episode = 539, Length = 60, Global step = 14442, Eps: 0.05\n",
      "Training: Episode = 540, Length = 191, Global step = 14633, Eps: 0.05\n",
      "Training: Episode = 541, Length = 53, Global step = 14686, Eps: 0.05\n",
      "Training: Episode = 542, Length = 51, Global step = 14737, Eps: 0.05\n",
      "Training: Episode = 543, Length = 85, Global step = 14822, Eps: 0.05\n",
      "Training: Episode = 544, Length = 80, Global step = 14902, Eps: 0.05\n",
      "Training: Episode = 545, Length = 52, Global step = 14954, Eps: 0.05\n",
      "Training: Episode = 546, Length = 59, Global step = 15013, Eps: 0.05\n",
      "Training: Episode = 547, Length = 107, Global step = 15120, Eps: 0.05\n",
      "Training: Episode = 548, Length = 83, Global step = 15203, Eps: 0.05\n",
      "Training: Episode = 549, Length = 106, Global step = 15309, Eps: 0.05\n",
      "Training: Episode = 550, Length = 108, Global step = 15417, Eps: 0.05\n",
      "Training: Episode = 551, Length = 146, Global step = 15563, Eps: 0.05\n",
      "Training: Episode = 552, Length = 67, Global step = 15630, Eps: 0.05\n",
      "Training: Episode = 553, Length = 82, Global step = 15712, Eps: 0.05\n",
      "Training: Episode = 554, Length = 50, Global step = 15762, Eps: 0.05\n",
      "Training: Episode = 555, Length = 107, Global step = 15869, Eps: 0.05\n",
      "Training: Episode = 556, Length = 80, Global step = 15949, Eps: 0.05\n",
      "Training: Episode = 557, Length = 96, Global step = 16045, Eps: 0.05\n",
      "Training: Episode = 558, Length = 73, Global step = 16118, Eps: 0.05\n",
      "Training: Episode = 559, Length = 108, Global step = 16226, Eps: 0.05\n",
      "Training: Episode = 560, Length = 70, Global step = 16296, Eps: 0.05\n",
      "Training: Episode = 561, Length = 59, Global step = 16355, Eps: 0.05\n",
      "Training: Episode = 562, Length = 55, Global step = 16410, Eps: 0.05\n",
      "Training: Episode = 563, Length = 18, Global step = 16428, Eps: 0.05\n",
      "Training: Episode = 564, Length = 53, Global step = 16481, Eps: 0.05\n",
      "Training: Episode = 565, Length = 57, Global step = 16538, Eps: 0.05\n",
      "Training: Episode = 566, Length = 54, Global step = 16592, Eps: 0.05\n",
      "Training: Episode = 567, Length = 53, Global step = 16645, Eps: 0.05\n",
      "Training: Episode = 568, Length = 173, Global step = 16818, Eps: 0.05\n",
      "Training: Episode = 569, Length = 54, Global step = 16872, Eps: 0.05\n",
      "Training: Episode = 570, Length = 58, Global step = 16930, Eps: 0.05\n",
      "Training: Episode = 571, Length = 200, Global step = 17130, Eps: 0.05\n",
      "Training: Episode = 572, Length = 200, Global step = 17330, Eps: 0.05\n",
      "Training: Episode = 573, Length = 200, Global step = 17530, Eps: 0.05\n",
      "Training: Episode = 574, Length = 200, Global step = 17730, Eps: 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Episode = 575, Length = 200, Global step = 17930, Eps: 0.05\n",
      "Training: Episode = 576, Length = 200, Global step = 18130, Eps: 0.05\n",
      "Training: Episode = 577, Length = 182, Global step = 18312, Eps: 0.05\n",
      "Training: Episode = 578, Length = 200, Global step = 18512, Eps: 0.05\n",
      "Training: Episode = 579, Length = 200, Global step = 18712, Eps: 0.05\n",
      "Training: Episode = 580, Length = 200, Global step = 18912, Eps: 0.05\n",
      "Training: Episode = 581, Length = 200, Global step = 19112, Eps: 0.05\n",
      "Training: Episode = 582, Length = 200, Global step = 19312, Eps: 0.05\n",
      "Training: Episode = 583, Length = 200, Global step = 19512, Eps: 0.05\n",
      "Training: Episode = 584, Length = 200, Global step = 19712, Eps: 0.05\n",
      "Training: Episode = 585, Length = 200, Global step = 19912, Eps: 0.05\n",
      "Training: Episode = 586, Length = 200, Global step = 20112, Eps: 0.05\n",
      "Training: Episode = 587, Length = 200, Global step = 20312, Eps: 0.05\n",
      "Training: Episode = 588, Length = 200, Global step = 20512, Eps: 0.05\n",
      "Training: Episode = 589, Length = 200, Global step = 20712, Eps: 0.05\n",
      "Training: Episode = 590, Length = 200, Global step = 20912, Eps: 0.05\n",
      "Training: Episode = 591, Length = 200, Global step = 21112, Eps: 0.05\n",
      "Training: Episode = 592, Length = 200, Global step = 21312, Eps: 0.05\n",
      "Training: Episode = 593, Length = 200, Global step = 21512, Eps: 0.05\n",
      "Training: Episode = 594, Length = 200, Global step = 21712, Eps: 0.05\n",
      "Training: Episode = 595, Length = 200, Global step = 21912, Eps: 0.05\n",
      "Training: Episode = 596, Length = 200, Global step = 22112, Eps: 0.05\n",
      "Training: Episode = 597, Length = 200, Global step = 22312, Eps: 0.05\n",
      "Training: Episode = 598, Length = 200, Global step = 22512, Eps: 0.05\n",
      "Training: Episode = 599, Length = 200, Global step = 22712, Eps: 0.05\n",
      "Training: Episode = 600, Length = 198, Global step = 22910, Eps: 0.05\n",
      "Training: Episode = 601, Length = 11, Global step = 22921, Eps: 0.05\n",
      "Training: Episode = 602, Length = 12, Global step = 22933, Eps: 0.05\n",
      "Training: Episode = 603, Length = 196, Global step = 23129, Eps: 0.05\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-b102fc773b03>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nStarting training...\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mdqn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"\\nFinished training...\\nCheck out some demonstrations\\n\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-ea13814769bb>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, episodes_num)\u001b[0m\n\u001b[0;32m    182\u001b[0m                             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrwd\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    183\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 184\u001b[1;33m                             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrwd\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDISCOUNT_FACTOR\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    185\u001b[0m                         \u001b[0mtgt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    186\u001b[0m                         \u001b[0mtgt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mact\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[0;32m     87\u001b[0m           method.__name__))\n\u001b[1;32m---> 88\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     89\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1247\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1249\u001b[1;33m           model=self)\n\u001b[0m\u001b[0;32m   1250\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m       \u001b[1;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[0;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1112\u001b[1;33m         model=model)\n\u001b[0m\u001b[0;32m   1113\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[0;32m    360\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mflat_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 362\u001b[1;33m     \u001b[0mindices_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    363\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    364\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36mflat_map\u001b[1;34m(self, map_func)\u001b[0m\n\u001b[0;32m   1650\u001b[0m       \u001b[0mDataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mA\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1651\u001b[0m     \"\"\"\n\u001b[1;32m-> 1652\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mFlatMapDataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1653\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1654\u001b[0m   def interleave(self,\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, input_dataset, map_func)\u001b[0m\n\u001b[0;32m   4069\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4070\u001b[0m     self._map_func = StructuredFunctionWrapper(\n\u001b[1;32m-> 4071\u001b[1;33m         map_func, self._transformation_name(), dataset=input_dataset)\n\u001b[0m\u001b[0;32m   4072\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_map_func\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutput_structure\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mDatasetSpec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4073\u001b[0m       raise TypeError(\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m   3219\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3220\u001b[0m         \u001b[1;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3221\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3223\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2530\u001b[0m     \"\"\"\n\u001b[0;32m   2531\u001b[0m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[1;32m-> 2532\u001b[1;33m         *args, **kwargs)\n\u001b[0m\u001b[0;32m   2533\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2534\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2494\u001b[0m       \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2495\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2496\u001b[1;33m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2497\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2498\u001b[0m         \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2775\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2777\u001b[1;33m       \u001b[0mgraph_function\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2779\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[1;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m   2665\u001b[0m             \u001b[0marg_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marg_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2666\u001b[0m             \u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moverride_flat_arg_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2667\u001b[1;33m             capture_by_value=self._capture_by_value),\n\u001b[0m\u001b[0;32m   2668\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_function_attributes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2669\u001b[0m         \u001b[1;31m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[0;32m    896\u001b[0m       \u001b[0mkwarg_shapes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     func_args = _get_defun_inputs_from_args(\n\u001b[1;32m--> 898\u001b[1;33m         args, arg_names, flat_shapes=arg_shapes)\n\u001b[0m\u001b[0;32m    899\u001b[0m     func_kwargs = _get_defun_inputs_from_kwargs(\n\u001b[0;32m    900\u001b[0m         kwargs, flat_shapes=kwarg_shapes)\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_get_defun_inputs_from_args\u001b[1;34m(args, names, flat_shapes)\u001b[0m\n\u001b[0;32m   1130\u001b[0m   \u001b[1;34m\"\"\"Maps Python function positional args to graph-construction inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1131\u001b[0m   return _get_defun_inputs(\n\u001b[1;32m-> 1132\u001b[1;33m       args, names, structure=args, flat_shapes=flat_shapes)\n\u001b[0m\u001b[0;32m   1133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_get_defun_inputs\u001b[1;34m(args, names, structure, flat_shapes)\u001b[0m\n\u001b[0;32m   1210\u001b[0m           placeholder = graph_placeholder(\n\u001b[0;32m   1211\u001b[0m               \u001b[0marg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mplaceholder_shape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1212\u001b[1;33m               name=requested_name)\n\u001b[0m\u001b[0;32m   1213\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1214\u001b[0m           \u001b[1;31m# Sometimes parameter names are not valid op names, so fall back to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\graph_only_ops.py\u001b[0m in \u001b[0;36mgraph_placeholder\u001b[1;34m(dtype, shape, name)\u001b[0m\n\u001b[0;32m     38\u001b[0m   op = g._create_op_internal(  # pylint: disable=protected-access\n\u001b[0;32m     39\u001b[0m       \u001b[1;34m\"Placeholder\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 40\u001b[1;33m       attrs=attrs, name=name)\n\u001b[0m\u001b[0;32m     41\u001b[0m   \u001b[0mresult\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     42\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mop_callbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_invoke_op_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m    593\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 595\u001b[1;33m         compute_device)\n\u001b[0m\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[1;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[0;32m   3325\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3326\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3327\u001b[1;33m           op_def=op_def)\n\u001b[0m\u001b[0;32m   3328\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3329\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[0;32m   1815\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mop\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1816\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[1;32m-> 1817\u001b[1;33m                                 control_input_ops, op_def)\n\u001b[0m\u001b[0;32m   1818\u001b[0m       \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1819\u001b[0m     \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[1;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[0;32m   1652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1653\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1654\u001b[1;33m     \u001b[0mc_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1655\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1656\u001b[0m     \u001b[1;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create and initialize the model\n",
    "dqn = DQN('CartPole-v0')\n",
    "dqn.initialize_network()\n",
    "\n",
    "print(\"\\nStarting training...\\n\")\n",
    "dqn.train()\n",
    "print(\"\\nFinished training...\\nCheck out some demonstrations\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1817: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: dqn_weights_main\\assets\n"
     ]
    }
   ],
   "source": [
    "dqn.save_model('dqn_weights_main')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Test steps =  200\n",
      "Mean steps =  200.0\n",
      "\n",
      "Finished.\n",
      "\n",
      "Ciao, and hasta la vista...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# average steps\n",
    "results = []\n",
    "for i in range(50):\n",
    "    episode_length = dqn.playPolicy()\n",
    "    print(\"Test steps = \", episode_length)\n",
    "    results.append(episode_length)\n",
    "print(\"Mean steps = \", sum(results) / len(results))\t\n",
    "dqn.env.close()\n",
    "print(\"\\nFinished.\")\n",
    "print(\"\\nCiao, and hasta la vista...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "m = 10\n",
    "n = len(dqn.episodic_rewards)//m\n",
    "ep_rwd = np.reshape(dqn.episodic_rewards[:n*m],(n,m))\n",
    "avg_eprwd = np.mean(ep_rwd,axis=1)\n",
    "x_plot = [(i+1)*m for i in range(n)]\n",
    "plt.plot(x_plot, avg_eprwd)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Average Reward for every '+str(m)+' Episodes')\n",
    "plt.title('DQN, Cart-pole')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to visualize it\n",
    "\n",
    "dqn_vis = DQN('CartPole-v0')\n",
    "dqn_vis.load_model('dqn_weights_main') # loading trained model from memory\n",
    "for i in range(10):\n",
    "    done = False\n",
    "    steps = 0\n",
    "    state = dqn_vis.env.reset()\n",
    "\n",
    "    while not done and steps < 200: \n",
    "        dqn_vis.env.render()\n",
    "        action = np.argmax(dqn_vis.model.predict(np.array([state]))[0])\n",
    "        state, _, done, _ = dqn_vis.env.step(action)\n",
    "        steps += 1\n",
    "        \n",
    "    print('Steps:'+str(steps))\n",
    "\n",
    "dqn_vis.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
