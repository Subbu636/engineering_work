{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import gym\n",
    "import random as rd\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Observations\n",
    "    1. On decreasing target update freq the varience of model increasing and on increasing convergence is taking longer\n",
    "    2. low discount factors unable to clearly differentiate the increase in steps after some treshlod\n",
    "    3. Increasing mini batch helping to achieve convergence faster\n",
    "    4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing DQN class\n",
    "\n",
    "class DQN:\n",
    "\n",
    "    REPLAY_MEMORY_SIZE = 8192 \t\t\t# number of tuples in experience replay  \n",
    "    EPSILON = 0.5 \t\t\t\t\t\t# epsilon of epsilon-greedy exploation\n",
    "    EPSILON_DECAY = 0.9999 \t\t\t\t# exponential decay multiplier for epsilon\n",
    "    HIDDEN1_SIZE = 32 \t\t\t\t\t# size of hidden layer 1 --> try 16*\n",
    "    HIDDEN2_SIZE = 16 \t\t\t\t\t# size of hidden layer 2\n",
    "    EPISODES_NUM = 2000 \t\t\t\t# number of episodes to train on. Ideally shouldn't take longer than 2000\n",
    "    MAX_STEPS = 200 \t\t\t\t\t# maximum number of steps in an episode \n",
    "    LEARNING_RATE = 0.001 \t\t\t\t# learning rate and other parameters for SGD/RMSProp/Adam --> try 0.001*, 0.003\n",
    "    MINIBATCH_SIZE = 64 \t\t\t\t# size of minibatch sampled from the experience replay --> try 16*, 8\n",
    "    DISCOUNT_FACTOR = 0.999 \t\t\t# MDP's gamma --> try 0.999*, 0.99\n",
    "    TARGET_UPDATE_FREQ = 100 \t\t\t# number of steps (not episodes) after which to update the target networks --> try 50, 20*     \n",
    "    LOG_DIR = './logs' \t\t\t\t\t# directory wherein logging takes place\n",
    "    EPSILON_MIN = 0.02                  # 0.05*\n",
    "\n",
    "\n",
    "    # Create and initialize the environment\n",
    "    def __init__(self, env):\n",
    "        self.env = gym.make(env)\n",
    "        assert len(self.env.observation_space.shape) == 1\n",
    "        self.input_size = self.env.observation_space.shape[0]\t\t# In case of cartpole, 4 state features\n",
    "        self.output_size = self.env.action_space.n\t\t\t\t\t# In case of cartpole, 2 actions (right/left)\n",
    "        self.eps = self.EPSILON\n",
    "        self.episodic_rewards = []\n",
    "        self.episodic_steps = []\n",
    "\n",
    "    # Create the Q-network\n",
    "    def initialize_network(self):\n",
    "        \n",
    "        ############################################################\n",
    "        # Design your q-network here.\n",
    "        # \n",
    "        # Add hidden layers and the output layer. For instance:\n",
    "        # \n",
    "        # with tf.name_scope('output'):\n",
    "        #\tW_n = tf.Variable(\n",
    "        # \t\t\t tf.truncated_normal([self.HIDDEN_n-1_SIZE, self.output_size], \n",
    "        # \t\t\t stddev=0.01), name='W_n')\n",
    "        # \tb_n = tf.Variable(tf.zeros(self.output_size), name='b_n')\n",
    "        # \tself.Q = tf.matmul(h_n-1, W_n) + b_n\n",
    "        #\n",
    "        #############################################################\n",
    "        \n",
    "        # Model designed using keras layers\n",
    "        self.model = keras.Sequential([\n",
    "                layers.InputLayer(input_shape=(self.input_size,)),\n",
    "                layers.Dense(self.HIDDEN1_SIZE, activation='relu', name='hidden1', kernel_initializer='RandomNormal'),\n",
    "                layers.Dense(self.HIDDEN2_SIZE, activation='relu', name='hidden2', kernel_initializer='RandomNormal'),\n",
    "                layers.Dense(self.output_size, activation='linear', name='output', kernel_initializer='RandomNormal')\n",
    "        ])\n",
    "\n",
    "        ############################################################\n",
    "        # Next, compute the loss.\n",
    "        #\n",
    "        # First, compute the q-values. Note that you need to calculate these\n",
    "        # for the actions in the (s,a,s',r) tuples from the experience replay's minibatch\n",
    "        #\n",
    "        # Next, compute the l2 loss between these estimated q-values and \n",
    "        # the target (which is computed using the frozen target network)\n",
    "        #\n",
    "        ############################################################\n",
    "        \n",
    "        ############################################################\n",
    "        # Finally, choose a gradient descent algorithm : SGD/RMSProp/Adam. \n",
    "        #\n",
    "        # For instance:\n",
    "        # optimizer = tf.train.GradientDescentOptimizer(self.LEARNING_RATE)\n",
    "        # global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        # self.train_op = optimizer.minimize(self.loss, global_step=global_step)\n",
    "        #\n",
    "        ############################################################\n",
    "\n",
    "        # Assigned descent algo. and loss function in one line\n",
    "        self.model.compile(loss=keras.losses.MeanSquaredError(),optimizer=keras.optimizers.Adam(lr=self.LEARNING_RATE))\n",
    "        self.model.summary()\n",
    "        \n",
    "        # create a target model a clone to our model i.e. target network\n",
    "        self.target_model = keras.models.clone_model(self.model)\n",
    "        self.target_model.build((None, self.input_size))\n",
    "        self.target_model.compile(loss=keras.losses.MeanSquaredError(),optimizer=keras.optimizers.Adam(lr=self.LEARNING_RATE))\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "        ############################################################\n",
    "\n",
    "    def train(self, episodes_num=EPISODES_NUM):\n",
    "\n",
    "        # Initialize summary for TensorBoard \n",
    "        summary_writer = tf.summary.create_file_writer(self.LOG_DIR)\n",
    "        summary = tf.summary\n",
    "        # Alternatively, you could use animated real-time plots from matplotlib \n",
    "        # (https://stackoverflow.com/a/24228275/3284912)\n",
    "\n",
    "        ############################################################\n",
    "        # Initialize other variables (like the replay memory)\n",
    "        ############################################################\n",
    "        \n",
    "        # Using deque\n",
    "        self.replay_buffer = deque(maxlen=self.REPLAY_MEMORY_SIZE)\n",
    "        total_steps = 0\n",
    "\n",
    "        ############################################################\n",
    "        # Main training loop\n",
    "        # \n",
    "        # In each episode, \n",
    "        #\tpick the action for the given state, \n",
    "        #\tperform a 'step' in the environment to get the reward and next state,\n",
    "        #\tupdate the replay buffer,\n",
    "        #\tsample a random minibatch from the replay buffer,\n",
    "        # \tperform Q-learning,\n",
    "        #\tupdate the target network, if required.\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        # You'll need to write code in various places in the following skeleton\n",
    "        #\n",
    "        ############################################################\n",
    "\n",
    "        for episode in range(episodes_num):\n",
    "\n",
    "            state = self.env.reset()\n",
    "\n",
    "            ############################################################\n",
    "            # Episode-specific initializations go here.\n",
    "            ############################################################\n",
    "            \n",
    "            episode_length = 0\n",
    "            score = 0\n",
    "            \n",
    "            ############################################################\n",
    "\n",
    "            while True:\n",
    "                ############################################################\n",
    "                # Pick the next action using epsilon greedy and execute it\n",
    "                ############################################################\n",
    "                episode_length += 1\n",
    "                total_steps += 1\n",
    "                if(rd.random() < self.eps):\n",
    "                    act = self.env.action_space.sample()\n",
    "                else:\n",
    "                    act = np.argmax(self.model.predict(np.array([state]))[0])\n",
    "\n",
    "                ############################################################\n",
    "                # Step in the environment. Something like: \n",
    "                # next_state, reward, done, _ = self.env.step(action)\n",
    "                ############################################################\n",
    "\n",
    "                next_state, reward, done, _ = self.env.step(act)\n",
    "                \n",
    "                ############################################################\n",
    "                # Update the (limited) replay buffer. \n",
    "                #\n",
    "                # Note : when the replay buffer is full, you'll need to \n",
    "                # remove an entry to accommodate a new one.\n",
    "                ############################################################\n",
    "\n",
    "                # The max length in deque removes oldest if buffer size exceeds it\n",
    "                x = 0\n",
    "                if done:\n",
    "                    x = 1\n",
    "                self.replay_buffer.append(((state),act,reward,(next_state),x))\n",
    "                score += reward\n",
    "                state = next_state\n",
    "\n",
    "                ############################################################\n",
    "                # Sample a random minibatch and perform Q-learning (fetch max Q at s') \n",
    "                #\n",
    "                # Remember, the target (r + gamma * max Q) is computed    \n",
    "                # with the help of the target network.\n",
    "                # Compute this target and pass it to the network for computing \n",
    "                # and minimizing the loss with the current estimates\n",
    "                #\n",
    "                ############################################################\n",
    "                \n",
    "                # not starting network update until it has a batch size elements\n",
    "                if len(self.replay_buffer) >= self.REPLAY_MEMORY_SIZE: # REPLAY_MEMORY_SIZE / MINI\n",
    "                    replay_batch = np.array(rd.sample(self.replay_buffer,self.MINIBATCH_SIZE))\n",
    "                    nst = []\n",
    "                    st = []\n",
    "                    for y in replay_batch:\n",
    "                        nst.append(y[3])\n",
    "                        st.append(y[0])\n",
    "                    max_Q = np.amax(self.target_model.predict(np.array(nst),workers=8, use_multiprocessing=True),1)\n",
    "                    batch_targets = self.target_model.predict(np.array(st),workers=8, use_multiprocessing=True)\n",
    "                    # for st, act, rwd, nst, d in replay_batch:\n",
    "                    #     if d:\n",
    "                    #         y = rwd\n",
    "                    #     else:\n",
    "                    #         y = (rwd + self.DISCOUNT_FACTOR * np.max(self.target_model.predict(nst)[0]))\n",
    "                    #     tgt = self.model.predict(st)[0]\n",
    "                    #     tgt[act] = y\n",
    "                    #     batch_states.append(st[0])\n",
    "                    #     batch_targets.append(tgt)\n",
    "                    # print(max_Q)\n",
    "                    # print(np.shape((1-replay_batch[:,4])))\n",
    "                    tgts = replay_batch[:,2] + self.DISCOUNT_FACTOR * max_Q * (1-replay_batch[:,4])\n",
    "                    for y in range(len(batch_targets)):\n",
    "                        batch_targets[y][replay_batch[y,1]] = tgts[y]\n",
    "                    self.model.fit(np.array(st), batch_targets, epochs=1, verbose = 0, workers=8, use_multiprocessing=True)\n",
    "                    \n",
    "                    if self.eps > self.EPSILON_MIN:\n",
    "                        self.eps *= self.EPSILON_DECAY\n",
    "                    elif self.eps < self.EPSILON_MIN:\n",
    "                        self.eps = self.EPSILON_MIN\n",
    "\n",
    "                ############################################################\n",
    "                # Update target weights. \n",
    "                #\n",
    "                # Something along the lines of:\n",
    "                # if total_steps % self.TARGET_UPDATE_FREQ == 0:\n",
    "                # \ttarget_weights = self.session.run(self.weights)\n",
    "                ############################################################\n",
    "\n",
    "                if total_steps%self.TARGET_UPDATE_FREQ == 0:\n",
    "                    self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "                ############################################################\n",
    "                # Break out of the loop if the episode ends\n",
    "                #\n",
    "                # Something like:\n",
    "                # if done or (episode_length == self.MAX_STEPS):\n",
    "                # \tbreak\n",
    "                #\n",
    "                ############################################################\n",
    "                \n",
    "                if done or episode_length == self.MAX_STEPS:\n",
    "                    self.episodic_rewards.append(score)\n",
    "                    self.episodic_steps.append(episode_length)\n",
    "                    break\n",
    "\n",
    "\n",
    "            ############################################################\n",
    "            # Logging. \n",
    "            #\n",
    "            # Very important. This is what gives an idea of how good the current\n",
    "            # experiment is, and if one should terminate and re-run with new parameters\n",
    "            # The earlier you learn how to read and visualize experiment logs quickly,\n",
    "            # the faster you'll be able to prototype and learn.\n",
    "            #\n",
    "            # Use any debugging information you think you need.\n",
    "            # For instance :\n",
    "\n",
    "            print(\"Training: Episode = %d, Length = %d, Global step = %d\" % (episode, episode_length, total_steps),end=', ')\n",
    "            print('Eps: '+str(self.eps))\n",
    "            with summary_writer.as_default():\n",
    "                summary.scalar(\"episode length\",episode ,step=episode_length)\n",
    "    \n",
    "    def save_model(self, name):\n",
    "        self.target_model.save(name)\n",
    "        \n",
    "    def load_model(self, name):\n",
    "        self.model = keras.models.load_model(name)\n",
    "        self.target_model = keras.models.load_model(name)\n",
    "\n",
    "    # Simple function to visually 'test' a policy\n",
    "    def playPolicy(self):\n",
    "\n",
    "        done = False\n",
    "        steps = 0\n",
    "        state = self.env.reset()\n",
    "\n",
    "        # we assume the CartPole task to be solved if the pole remains upright for 200 steps\n",
    "        while not done and steps < 200: \n",
    "            # self.env.render()\n",
    "            action = np.argmax(self.target_model.predict(np.array([state]))[0])\n",
    "            state, _, done, _ = self.env.step(action)\n",
    "            steps += 1\n",
    "\n",
    "        return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "hidden1 (Dense)              (None, 32)                160       \n",
      "_________________________________________________________________\n",
      "hidden2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 34        \n",
      "=================================================================\n",
      "Total params: 722\n",
      "Trainable params: 722\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "\n",
      "Starting training...\n",
      "\n",
      "Training: Episode = 0, Length = 10, Global step = 10, Eps: 0.5\n",
      "Training: Episode = 1, Length = 12, Global step = 22, Eps: 0.5\n",
      "Training: Episode = 2, Length = 15, Global step = 37, Eps: 0.5\n",
      "Training: Episode = 3, Length = 11, Global step = 48, Eps: 0.5\n",
      "Training: Episode = 4, Length = 17, Global step = 65, Eps: 0.5\n",
      "Training: Episode = 5, Length = 10, Global step = 75, Eps: 0.5\n",
      "Training: Episode = 6, Length = 12, Global step = 87, Eps: 0.5\n",
      "Training: Episode = 7, Length = 12, Global step = 99, Eps: 0.5\n",
      "Training: Episode = 8, Length = 11, Global step = 110, Eps: 0.5\n",
      "Training: Episode = 9, Length = 12, Global step = 122, Eps: 0.5\n",
      "Training: Episode = 10, Length = 12, Global step = 134, Eps: 0.5\n",
      "Training: Episode = 11, Length = 12, Global step = 146, Eps: 0.5\n",
      "Training: Episode = 12, Length = 9, Global step = 155, Eps: 0.5\n",
      "Training: Episode = 13, Length = 26, Global step = 181, Eps: 0.5\n",
      "Training: Episode = 14, Length = 12, Global step = 193, Eps: 0.5\n",
      "Training: Episode = 15, Length = 11, Global step = 204, Eps: 0.5\n",
      "Training: Episode = 16, Length = 9, Global step = 213, Eps: 0.5\n",
      "Training: Episode = 17, Length = 16, Global step = 229, Eps: 0.5\n",
      "Training: Episode = 18, Length = 11, Global step = 240, Eps: 0.5\n",
      "Training: Episode = 19, Length = 17, Global step = 257, Eps: 0.5\n",
      "Training: Episode = 20, Length = 12, Global step = 269, Eps: 0.5\n",
      "Training: Episode = 21, Length = 10, Global step = 279, Eps: 0.5\n",
      "Training: Episode = 22, Length = 10, Global step = 289, Eps: 0.5\n",
      "Training: Episode = 23, Length = 17, Global step = 306, Eps: 0.5\n",
      "Training: Episode = 24, Length = 20, Global step = 326, Eps: 0.5\n",
      "Training: Episode = 25, Length = 11, Global step = 337, Eps: 0.5\n",
      "Training: Episode = 26, Length = 12, Global step = 349, Eps: 0.5\n",
      "Training: Episode = 27, Length = 10, Global step = 359, Eps: 0.5\n",
      "Training: Episode = 28, Length = 10, Global step = 369, Eps: 0.5\n",
      "Training: Episode = 29, Length = 17, Global step = 386, Eps: 0.5\n",
      "Training: Episode = 30, Length = 9, Global step = 395, Eps: 0.5\n",
      "Training: Episode = 31, Length = 12, Global step = 407, Eps: 0.5\n",
      "Training: Episode = 32, Length = 16, Global step = 423, Eps: 0.5\n",
      "Training: Episode = 33, Length = 12, Global step = 435, Eps: 0.5\n",
      "Training: Episode = 34, Length = 13, Global step = 448, Eps: 0.5\n",
      "Training: Episode = 35, Length = 17, Global step = 465, Eps: 0.5\n",
      "Training: Episode = 36, Length = 11, Global step = 476, Eps: 0.5\n",
      "Training: Episode = 37, Length = 10, Global step = 486, Eps: 0.5\n",
      "Training: Episode = 38, Length = 11, Global step = 497, Eps: 0.5\n",
      "Training: Episode = 39, Length = 13, Global step = 510, Eps: 0.5\n",
      "Training: Episode = 40, Length = 20, Global step = 530, Eps: 0.5\n",
      "Training: Episode = 41, Length = 10, Global step = 540, Eps: 0.5\n",
      "Training: Episode = 42, Length = 9, Global step = 549, Eps: 0.5\n",
      "Training: Episode = 43, Length = 12, Global step = 561, Eps: 0.5\n",
      "Training: Episode = 44, Length = 38, Global step = 599, Eps: 0.5\n",
      "Training: Episode = 45, Length = 13, Global step = 612, Eps: 0.5\n",
      "Training: Episode = 46, Length = 22, Global step = 634, Eps: 0.5\n",
      "Training: Episode = 47, Length = 13, Global step = 647, Eps: 0.5\n",
      "Training: Episode = 48, Length = 16, Global step = 663, Eps: 0.5\n",
      "Training: Episode = 49, Length = 9, Global step = 672, Eps: 0.5\n",
      "Training: Episode = 50, Length = 20, Global step = 692, Eps: 0.5\n",
      "Training: Episode = 51, Length = 12, Global step = 704, Eps: 0.5\n",
      "Training: Episode = 52, Length = 13, Global step = 717, Eps: 0.5\n",
      "Training: Episode = 53, Length = 18, Global step = 735, Eps: 0.5\n",
      "Training: Episode = 54, Length = 9, Global step = 744, Eps: 0.5\n",
      "Training: Episode = 55, Length = 15, Global step = 759, Eps: 0.5\n",
      "Training: Episode = 56, Length = 11, Global step = 770, Eps: 0.5\n",
      "Training: Episode = 57, Length = 8, Global step = 778, Eps: 0.5\n",
      "Training: Episode = 58, Length = 11, Global step = 789, Eps: 0.5\n",
      "Training: Episode = 59, Length = 24, Global step = 813, Eps: 0.5\n",
      "Training: Episode = 60, Length = 11, Global step = 824, Eps: 0.5\n",
      "Training: Episode = 61, Length = 14, Global step = 838, Eps: 0.5\n",
      "Training: Episode = 62, Length = 9, Global step = 847, Eps: 0.5\n",
      "Training: Episode = 63, Length = 10, Global step = 857, Eps: 0.5\n",
      "Training: Episode = 64, Length = 10, Global step = 867, Eps: 0.5\n",
      "Training: Episode = 65, Length = 18, Global step = 885, Eps: 0.5\n",
      "Training: Episode = 66, Length = 11, Global step = 896, Eps: 0.5\n",
      "Training: Episode = 67, Length = 9, Global step = 905, Eps: 0.5\n",
      "Training: Episode = 68, Length = 14, Global step = 919, Eps: 0.5\n",
      "Training: Episode = 69, Length = 9, Global step = 928, Eps: 0.5\n",
      "Training: Episode = 70, Length = 11, Global step = 939, Eps: 0.5\n",
      "Training: Episode = 71, Length = 15, Global step = 954, Eps: 0.5\n",
      "Training: Episode = 72, Length = 11, Global step = 965, Eps: 0.5\n",
      "Training: Episode = 73, Length = 9, Global step = 974, Eps: 0.5\n",
      "Training: Episode = 74, Length = 31, Global step = 1005, Eps: 0.5\n",
      "Training: Episode = 75, Length = 11, Global step = 1016, Eps: 0.5\n",
      "Training: Episode = 76, Length = 12, Global step = 1028, Eps: 0.5\n",
      "Training: Episode = 77, Length = 10, Global step = 1038, Eps: 0.5\n",
      "Training: Episode = 78, Length = 22, Global step = 1060, Eps: 0.5\n",
      "Training: Episode = 79, Length = 10, Global step = 1070, Eps: 0.5\n",
      "Training: Episode = 80, Length = 12, Global step = 1082, Eps: 0.5\n",
      "Training: Episode = 81, Length = 24, Global step = 1106, Eps: 0.5\n",
      "Training: Episode = 82, Length = 12, Global step = 1118, Eps: 0.5\n",
      "Training: Episode = 83, Length = 12, Global step = 1130, Eps: 0.5\n",
      "Training: Episode = 84, Length = 13, Global step = 1143, Eps: 0.5\n",
      "Training: Episode = 85, Length = 12, Global step = 1155, Eps: 0.5\n",
      "Training: Episode = 86, Length = 16, Global step = 1171, Eps: 0.5\n",
      "Training: Episode = 87, Length = 14, Global step = 1185, Eps: 0.5\n",
      "Training: Episode = 88, Length = 10, Global step = 1195, Eps: 0.5\n",
      "Training: Episode = 89, Length = 11, Global step = 1206, Eps: 0.5\n",
      "Training: Episode = 90, Length = 21, Global step = 1227, Eps: 0.5\n",
      "Training: Episode = 91, Length = 28, Global step = 1255, Eps: 0.5\n",
      "Training: Episode = 92, Length = 11, Global step = 1266, Eps: 0.5\n",
      "Training: Episode = 93, Length = 12, Global step = 1278, Eps: 0.5\n",
      "Training: Episode = 94, Length = 12, Global step = 1290, Eps: 0.5\n",
      "Training: Episode = 95, Length = 10, Global step = 1300, Eps: 0.5\n",
      "Training: Episode = 96, Length = 11, Global step = 1311, Eps: 0.5\n",
      "Training: Episode = 97, Length = 14, Global step = 1325, Eps: 0.5\n",
      "Training: Episode = 98, Length = 18, Global step = 1343, Eps: 0.5\n",
      "Training: Episode = 99, Length = 17, Global step = 1360, Eps: 0.5\n",
      "Training: Episode = 100, Length = 15, Global step = 1375, Eps: 0.5\n",
      "Training: Episode = 101, Length = 10, Global step = 1385, Eps: 0.5\n",
      "Training: Episode = 102, Length = 17, Global step = 1402, Eps: 0.5\n",
      "Training: Episode = 103, Length = 10, Global step = 1412, Eps: 0.5\n",
      "Training: Episode = 104, Length = 11, Global step = 1423, Eps: 0.5\n",
      "Training: Episode = 105, Length = 9, Global step = 1432, Eps: 0.5\n",
      "Training: Episode = 106, Length = 10, Global step = 1442, Eps: 0.5\n",
      "Training: Episode = 107, Length = 13, Global step = 1455, Eps: 0.5\n",
      "Training: Episode = 108, Length = 13, Global step = 1468, Eps: 0.5\n",
      "Training: Episode = 109, Length = 11, Global step = 1479, Eps: 0.5\n",
      "Training: Episode = 110, Length = 15, Global step = 1494, Eps: 0.5\n",
      "Training: Episode = 111, Length = 9, Global step = 1503, Eps: 0.5\n",
      "Training: Episode = 112, Length = 9, Global step = 1512, Eps: 0.5\n",
      "Training: Episode = 113, Length = 10, Global step = 1522, Eps: 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Episode = 114, Length = 13, Global step = 1535, Eps: 0.5\n",
      "Training: Episode = 115, Length = 12, Global step = 1547, Eps: 0.5\n",
      "Training: Episode = 116, Length = 17, Global step = 1564, Eps: 0.5\n",
      "Training: Episode = 117, Length = 14, Global step = 1578, Eps: 0.5\n",
      "Training: Episode = 118, Length = 17, Global step = 1595, Eps: 0.5\n",
      "Training: Episode = 119, Length = 32, Global step = 1627, Eps: 0.5\n",
      "Training: Episode = 120, Length = 9, Global step = 1636, Eps: 0.5\n",
      "Training: Episode = 121, Length = 9, Global step = 1645, Eps: 0.5\n",
      "Training: Episode = 122, Length = 16, Global step = 1661, Eps: 0.5\n",
      "Training: Episode = 123, Length = 12, Global step = 1673, Eps: 0.5\n",
      "Training: Episode = 124, Length = 14, Global step = 1687, Eps: 0.5\n",
      "Training: Episode = 125, Length = 11, Global step = 1698, Eps: 0.5\n",
      "Training: Episode = 126, Length = 11, Global step = 1709, Eps: 0.5\n",
      "Training: Episode = 127, Length = 13, Global step = 1722, Eps: 0.5\n",
      "Training: Episode = 128, Length = 13, Global step = 1735, Eps: 0.5\n",
      "Training: Episode = 129, Length = 11, Global step = 1746, Eps: 0.5\n",
      "Training: Episode = 130, Length = 33, Global step = 1779, Eps: 0.5\n",
      "Training: Episode = 131, Length = 13, Global step = 1792, Eps: 0.5\n",
      "Training: Episode = 132, Length = 11, Global step = 1803, Eps: 0.5\n",
      "Training: Episode = 133, Length = 9, Global step = 1812, Eps: 0.5\n",
      "Training: Episode = 134, Length = 14, Global step = 1826, Eps: 0.5\n",
      "Training: Episode = 135, Length = 13, Global step = 1839, Eps: 0.5\n",
      "Training: Episode = 136, Length = 12, Global step = 1851, Eps: 0.5\n",
      "Training: Episode = 137, Length = 11, Global step = 1862, Eps: 0.5\n",
      "Training: Episode = 138, Length = 12, Global step = 1874, Eps: 0.5\n",
      "Training: Episode = 139, Length = 11, Global step = 1885, Eps: 0.5\n",
      "Training: Episode = 140, Length = 18, Global step = 1903, Eps: 0.5\n",
      "Training: Episode = 141, Length = 12, Global step = 1915, Eps: 0.5\n",
      "Training: Episode = 142, Length = 25, Global step = 1940, Eps: 0.5\n",
      "Training: Episode = 143, Length = 15, Global step = 1955, Eps: 0.5\n",
      "Training: Episode = 144, Length = 12, Global step = 1967, Eps: 0.5\n",
      "Training: Episode = 145, Length = 20, Global step = 1987, Eps: 0.5\n",
      "Training: Episode = 146, Length = 13, Global step = 2000, Eps: 0.5\n",
      "Training: Episode = 147, Length = 13, Global step = 2013, Eps: 0.5\n",
      "Training: Episode = 148, Length = 13, Global step = 2026, Eps: 0.5\n",
      "Training: Episode = 149, Length = 11, Global step = 2037, Eps: 0.5\n",
      "Training: Episode = 150, Length = 10, Global step = 2047, Eps: 0.5\n",
      "Training: Episode = 151, Length = 12, Global step = 2059, Eps: 0.5\n",
      "Training: Episode = 152, Length = 14, Global step = 2073, Eps: 0.5\n",
      "Training: Episode = 153, Length = 16, Global step = 2089, Eps: 0.5\n",
      "Training: Episode = 154, Length = 19, Global step = 2108, Eps: 0.5\n",
      "Training: Episode = 155, Length = 25, Global step = 2133, Eps: 0.5\n",
      "Training: Episode = 156, Length = 15, Global step = 2148, Eps: 0.5\n",
      "Training: Episode = 157, Length = 12, Global step = 2160, Eps: 0.5\n",
      "Training: Episode = 158, Length = 11, Global step = 2171, Eps: 0.5\n",
      "Training: Episode = 159, Length = 15, Global step = 2186, Eps: 0.5\n",
      "Training: Episode = 160, Length = 20, Global step = 2206, Eps: 0.5\n",
      "Training: Episode = 161, Length = 16, Global step = 2222, Eps: 0.5\n",
      "Training: Episode = 162, Length = 40, Global step = 2262, Eps: 0.5\n",
      "Training: Episode = 163, Length = 9, Global step = 2271, Eps: 0.5\n",
      "Training: Episode = 164, Length = 14, Global step = 2285, Eps: 0.5\n",
      "Training: Episode = 165, Length = 18, Global step = 2303, Eps: 0.5\n",
      "Training: Episode = 166, Length = 14, Global step = 2317, Eps: 0.5\n",
      "Training: Episode = 167, Length = 13, Global step = 2330, Eps: 0.5\n",
      "Training: Episode = 168, Length = 12, Global step = 2342, Eps: 0.5\n",
      "Training: Episode = 169, Length = 12, Global step = 2354, Eps: 0.5\n",
      "Training: Episode = 170, Length = 12, Global step = 2366, Eps: 0.5\n",
      "Training: Episode = 171, Length = 11, Global step = 2377, Eps: 0.5\n",
      "Training: Episode = 172, Length = 15, Global step = 2392, Eps: 0.5\n",
      "Training: Episode = 173, Length = 10, Global step = 2402, Eps: 0.5\n",
      "Training: Episode = 174, Length = 9, Global step = 2411, Eps: 0.5\n",
      "Training: Episode = 175, Length = 14, Global step = 2425, Eps: 0.5\n",
      "Training: Episode = 176, Length = 13, Global step = 2438, Eps: 0.5\n",
      "Training: Episode = 177, Length = 13, Global step = 2451, Eps: 0.5\n",
      "Training: Episode = 178, Length = 11, Global step = 2462, Eps: 0.5\n",
      "Training: Episode = 179, Length = 10, Global step = 2472, Eps: 0.5\n",
      "Training: Episode = 180, Length = 17, Global step = 2489, Eps: 0.5\n",
      "Training: Episode = 181, Length = 18, Global step = 2507, Eps: 0.5\n",
      "Training: Episode = 182, Length = 10, Global step = 2517, Eps: 0.5\n",
      "Training: Episode = 183, Length = 17, Global step = 2534, Eps: 0.5\n",
      "Training: Episode = 184, Length = 15, Global step = 2549, Eps: 0.5\n",
      "Training: Episode = 185, Length = 8, Global step = 2557, Eps: 0.5\n",
      "Training: Episode = 186, Length = 15, Global step = 2572, Eps: 0.5\n",
      "Training: Episode = 187, Length = 20, Global step = 2592, Eps: 0.5\n",
      "Training: Episode = 188, Length = 12, Global step = 2604, Eps: 0.5\n",
      "Training: Episode = 189, Length = 10, Global step = 2614, Eps: 0.5\n",
      "Training: Episode = 190, Length = 10, Global step = 2624, Eps: 0.5\n",
      "Training: Episode = 191, Length = 10, Global step = 2634, Eps: 0.5\n",
      "Training: Episode = 192, Length = 12, Global step = 2646, Eps: 0.5\n",
      "Training: Episode = 193, Length = 17, Global step = 2663, Eps: 0.5\n",
      "Training: Episode = 194, Length = 15, Global step = 2678, Eps: 0.5\n",
      "Training: Episode = 195, Length = 12, Global step = 2690, Eps: 0.5\n",
      "Training: Episode = 196, Length = 13, Global step = 2703, Eps: 0.5\n",
      "Training: Episode = 197, Length = 14, Global step = 2717, Eps: 0.5\n",
      "Training: Episode = 198, Length = 13, Global step = 2730, Eps: 0.5\n",
      "Training: Episode = 199, Length = 11, Global step = 2741, Eps: 0.5\n",
      "Training: Episode = 200, Length = 15, Global step = 2756, Eps: 0.5\n",
      "Training: Episode = 201, Length = 13, Global step = 2769, Eps: 0.5\n",
      "Training: Episode = 202, Length = 18, Global step = 2787, Eps: 0.5\n",
      "Training: Episode = 203, Length = 11, Global step = 2798, Eps: 0.5\n",
      "Training: Episode = 204, Length = 9, Global step = 2807, Eps: 0.5\n",
      "Training: Episode = 205, Length = 39, Global step = 2846, Eps: 0.5\n",
      "Training: Episode = 206, Length = 13, Global step = 2859, Eps: 0.5\n",
      "Training: Episode = 207, Length = 23, Global step = 2882, Eps: 0.5\n",
      "Training: Episode = 208, Length = 21, Global step = 2903, Eps: 0.5\n",
      "Training: Episode = 209, Length = 9, Global step = 2912, Eps: 0.5\n",
      "Training: Episode = 210, Length = 9, Global step = 2921, Eps: 0.5\n",
      "Training: Episode = 211, Length = 10, Global step = 2931, Eps: 0.5\n",
      "Training: Episode = 212, Length = 14, Global step = 2945, Eps: 0.5\n",
      "Training: Episode = 213, Length = 9, Global step = 2954, Eps: 0.5\n",
      "Training: Episode = 214, Length = 17, Global step = 2971, Eps: 0.5\n",
      "Training: Episode = 215, Length = 13, Global step = 2984, Eps: 0.5\n",
      "Training: Episode = 216, Length = 15, Global step = 2999, Eps: 0.5\n",
      "Training: Episode = 217, Length = 14, Global step = 3013, Eps: 0.5\n",
      "Training: Episode = 218, Length = 21, Global step = 3034, Eps: 0.5\n",
      "Training: Episode = 219, Length = 12, Global step = 3046, Eps: 0.5\n",
      "Training: Episode = 220, Length = 12, Global step = 3058, Eps: 0.5\n",
      "Training: Episode = 221, Length = 23, Global step = 3081, Eps: 0.5\n",
      "Training: Episode = 222, Length = 11, Global step = 3092, Eps: 0.5\n",
      "Training: Episode = 223, Length = 10, Global step = 3102, Eps: 0.5\n",
      "Training: Episode = 224, Length = 15, Global step = 3117, Eps: 0.5\n",
      "Training: Episode = 225, Length = 12, Global step = 3129, Eps: 0.5\n",
      "Training: Episode = 226, Length = 25, Global step = 3154, Eps: 0.5\n",
      "Training: Episode = 227, Length = 23, Global step = 3177, Eps: 0.5\n",
      "Training: Episode = 228, Length = 10, Global step = 3187, Eps: 0.5\n",
      "Training: Episode = 229, Length = 10, Global step = 3197, Eps: 0.5\n",
      "Training: Episode = 230, Length = 21, Global step = 3218, Eps: 0.5\n",
      "Training: Episode = 231, Length = 21, Global step = 3239, Eps: 0.5\n",
      "Training: Episode = 232, Length = 9, Global step = 3248, Eps: 0.5\n",
      "Training: Episode = 233, Length = 15, Global step = 3263, Eps: 0.5\n",
      "Training: Episode = 234, Length = 10, Global step = 3273, Eps: 0.5\n",
      "Training: Episode = 235, Length = 29, Global step = 3302, Eps: 0.5\n",
      "Training: Episode = 236, Length = 15, Global step = 3317, Eps: 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Episode = 237, Length = 16, Global step = 3333, Eps: 0.5\n",
      "Training: Episode = 238, Length = 16, Global step = 3349, Eps: 0.5\n",
      "Training: Episode = 239, Length = 18, Global step = 3367, Eps: 0.5\n",
      "Training: Episode = 240, Length = 12, Global step = 3379, Eps: 0.5\n",
      "Training: Episode = 241, Length = 14, Global step = 3393, Eps: 0.5\n",
      "Training: Episode = 242, Length = 16, Global step = 3409, Eps: 0.5\n",
      "Training: Episode = 243, Length = 10, Global step = 3419, Eps: 0.5\n",
      "Training: Episode = 244, Length = 14, Global step = 3433, Eps: 0.5\n",
      "Training: Episode = 245, Length = 12, Global step = 3445, Eps: 0.5\n",
      "Training: Episode = 246, Length = 18, Global step = 3463, Eps: 0.5\n",
      "Training: Episode = 247, Length = 10, Global step = 3473, Eps: 0.5\n",
      "Training: Episode = 248, Length = 12, Global step = 3485, Eps: 0.5\n",
      "Training: Episode = 249, Length = 10, Global step = 3495, Eps: 0.5\n",
      "Training: Episode = 250, Length = 13, Global step = 3508, Eps: 0.5\n",
      "Training: Episode = 251, Length = 11, Global step = 3519, Eps: 0.5\n",
      "Training: Episode = 252, Length = 15, Global step = 3534, Eps: 0.5\n",
      "Training: Episode = 253, Length = 10, Global step = 3544, Eps: 0.5\n",
      "Training: Episode = 254, Length = 16, Global step = 3560, Eps: 0.5\n",
      "Training: Episode = 255, Length = 10, Global step = 3570, Eps: 0.5\n",
      "Training: Episode = 256, Length = 10, Global step = 3580, Eps: 0.5\n",
      "Training: Episode = 257, Length = 27, Global step = 3607, Eps: 0.5\n",
      "Training: Episode = 258, Length = 12, Global step = 3619, Eps: 0.5\n",
      "Training: Episode = 259, Length = 16, Global step = 3635, Eps: 0.5\n",
      "Training: Episode = 260, Length = 14, Global step = 3649, Eps: 0.5\n",
      "Training: Episode = 261, Length = 11, Global step = 3660, Eps: 0.5\n",
      "Training: Episode = 262, Length = 10, Global step = 3670, Eps: 0.5\n",
      "Training: Episode = 263, Length = 15, Global step = 3685, Eps: 0.5\n",
      "Training: Episode = 264, Length = 19, Global step = 3704, Eps: 0.5\n",
      "Training: Episode = 265, Length = 12, Global step = 3716, Eps: 0.5\n",
      "Training: Episode = 266, Length = 17, Global step = 3733, Eps: 0.5\n",
      "Training: Episode = 267, Length = 10, Global step = 3743, Eps: 0.5\n",
      "Training: Episode = 268, Length = 11, Global step = 3754, Eps: 0.5\n",
      "Training: Episode = 269, Length = 12, Global step = 3766, Eps: 0.5\n",
      "Training: Episode = 270, Length = 13, Global step = 3779, Eps: 0.5\n",
      "Training: Episode = 271, Length = 31, Global step = 3810, Eps: 0.5\n",
      "Training: Episode = 272, Length = 11, Global step = 3821, Eps: 0.5\n",
      "Training: Episode = 273, Length = 11, Global step = 3832, Eps: 0.5\n",
      "Training: Episode = 274, Length = 11, Global step = 3843, Eps: 0.5\n",
      "Training: Episode = 275, Length = 11, Global step = 3854, Eps: 0.5\n",
      "Training: Episode = 276, Length = 15, Global step = 3869, Eps: 0.5\n",
      "Training: Episode = 277, Length = 10, Global step = 3879, Eps: 0.5\n",
      "Training: Episode = 278, Length = 11, Global step = 3890, Eps: 0.5\n",
      "Training: Episode = 279, Length = 12, Global step = 3902, Eps: 0.5\n",
      "Training: Episode = 280, Length = 11, Global step = 3913, Eps: 0.5\n",
      "Training: Episode = 281, Length = 13, Global step = 3926, Eps: 0.5\n",
      "Training: Episode = 282, Length = 15, Global step = 3941, Eps: 0.5\n",
      "Training: Episode = 283, Length = 14, Global step = 3955, Eps: 0.5\n",
      "Training: Episode = 284, Length = 13, Global step = 3968, Eps: 0.5\n",
      "Training: Episode = 285, Length = 13, Global step = 3981, Eps: 0.5\n",
      "Training: Episode = 286, Length = 10, Global step = 3991, Eps: 0.5\n",
      "Training: Episode = 287, Length = 41, Global step = 4032, Eps: 0.5\n",
      "Training: Episode = 288, Length = 10, Global step = 4042, Eps: 0.5\n",
      "Training: Episode = 289, Length = 15, Global step = 4057, Eps: 0.5\n",
      "Training: Episode = 290, Length = 26, Global step = 4083, Eps: 0.5\n",
      "Training: Episode = 291, Length = 13, Global step = 4096, Eps: 0.5\n",
      "Training: Episode = 292, Length = 13, Global step = 4109, Eps: 0.5\n",
      "Training: Episode = 293, Length = 10, Global step = 4119, Eps: 0.5\n",
      "Training: Episode = 294, Length = 15, Global step = 4134, Eps: 0.5\n",
      "Training: Episode = 295, Length = 10, Global step = 4144, Eps: 0.5\n",
      "Training: Episode = 296, Length = 11, Global step = 4155, Eps: 0.5\n",
      "Training: Episode = 297, Length = 10, Global step = 4165, Eps: 0.5\n",
      "Training: Episode = 298, Length = 12, Global step = 4177, Eps: 0.5\n",
      "Training: Episode = 299, Length = 10, Global step = 4187, Eps: 0.5\n",
      "Training: Episode = 300, Length = 13, Global step = 4200, Eps: 0.5\n",
      "Training: Episode = 301, Length = 12, Global step = 4212, Eps: 0.5\n",
      "Training: Episode = 302, Length = 12, Global step = 4224, Eps: 0.5\n",
      "Training: Episode = 303, Length = 18, Global step = 4242, Eps: 0.5\n",
      "Training: Episode = 304, Length = 15, Global step = 4257, Eps: 0.5\n",
      "Training: Episode = 305, Length = 12, Global step = 4269, Eps: 0.5\n",
      "Training: Episode = 306, Length = 17, Global step = 4286, Eps: 0.5\n",
      "Training: Episode = 307, Length = 11, Global step = 4297, Eps: 0.5\n",
      "Training: Episode = 308, Length = 11, Global step = 4308, Eps: 0.5\n",
      "Training: Episode = 309, Length = 18, Global step = 4326, Eps: 0.5\n",
      "Training: Episode = 310, Length = 31, Global step = 4357, Eps: 0.5\n",
      "Training: Episode = 311, Length = 14, Global step = 4371, Eps: 0.5\n",
      "Training: Episode = 312, Length = 12, Global step = 4383, Eps: 0.5\n",
      "Training: Episode = 313, Length = 18, Global step = 4401, Eps: 0.5\n",
      "Training: Episode = 314, Length = 10, Global step = 4411, Eps: 0.5\n",
      "Training: Episode = 315, Length = 19, Global step = 4430, Eps: 0.5\n",
      "Training: Episode = 316, Length = 13, Global step = 4443, Eps: 0.5\n",
      "Training: Episode = 317, Length = 16, Global step = 4459, Eps: 0.5\n",
      "Training: Episode = 318, Length = 10, Global step = 4469, Eps: 0.5\n",
      "Training: Episode = 319, Length = 10, Global step = 4479, Eps: 0.5\n",
      "Training: Episode = 320, Length = 11, Global step = 4490, Eps: 0.5\n",
      "Training: Episode = 321, Length = 10, Global step = 4500, Eps: 0.5\n",
      "Training: Episode = 322, Length = 10, Global step = 4510, Eps: 0.5\n",
      "Training: Episode = 323, Length = 10, Global step = 4520, Eps: 0.5\n",
      "Training: Episode = 324, Length = 12, Global step = 4532, Eps: 0.5\n",
      "Training: Episode = 325, Length = 13, Global step = 4545, Eps: 0.5\n",
      "Training: Episode = 326, Length = 15, Global step = 4560, Eps: 0.5\n",
      "Training: Episode = 327, Length = 10, Global step = 4570, Eps: 0.5\n",
      "Training: Episode = 328, Length = 12, Global step = 4582, Eps: 0.5\n",
      "Training: Episode = 329, Length = 13, Global step = 4595, Eps: 0.5\n",
      "Training: Episode = 330, Length = 12, Global step = 4607, Eps: 0.5\n",
      "Training: Episode = 331, Length = 22, Global step = 4629, Eps: 0.5\n",
      "Training: Episode = 332, Length = 8, Global step = 4637, Eps: 0.5\n",
      "Training: Episode = 333, Length = 14, Global step = 4651, Eps: 0.5\n",
      "Training: Episode = 334, Length = 13, Global step = 4664, Eps: 0.5\n",
      "Training: Episode = 335, Length = 10, Global step = 4674, Eps: 0.5\n",
      "Training: Episode = 336, Length = 24, Global step = 4698, Eps: 0.5\n",
      "Training: Episode = 337, Length = 9, Global step = 4707, Eps: 0.5\n",
      "Training: Episode = 338, Length = 11, Global step = 4718, Eps: 0.5\n",
      "Training: Episode = 339, Length = 14, Global step = 4732, Eps: 0.5\n",
      "Training: Episode = 340, Length = 29, Global step = 4761, Eps: 0.5\n",
      "Training: Episode = 341, Length = 12, Global step = 4773, Eps: 0.5\n",
      "Training: Episode = 342, Length = 9, Global step = 4782, Eps: 0.5\n",
      "Training: Episode = 343, Length = 10, Global step = 4792, Eps: 0.5\n",
      "Training: Episode = 344, Length = 13, Global step = 4805, Eps: 0.5\n",
      "Training: Episode = 345, Length = 11, Global step = 4816, Eps: 0.5\n",
      "Training: Episode = 346, Length = 11, Global step = 4827, Eps: 0.5\n",
      "Training: Episode = 347, Length = 18, Global step = 4845, Eps: 0.5\n",
      "Training: Episode = 348, Length = 9, Global step = 4854, Eps: 0.5\n",
      "Training: Episode = 349, Length = 11, Global step = 4865, Eps: 0.5\n",
      "Training: Episode = 350, Length = 9, Global step = 4874, Eps: 0.5\n",
      "Training: Episode = 351, Length = 12, Global step = 4886, Eps: 0.5\n",
      "Training: Episode = 352, Length = 17, Global step = 4903, Eps: 0.5\n",
      "Training: Episode = 353, Length = 13, Global step = 4916, Eps: 0.5\n",
      "Training: Episode = 354, Length = 28, Global step = 4944, Eps: 0.5\n",
      "Training: Episode = 355, Length = 9, Global step = 4953, Eps: 0.5\n",
      "Training: Episode = 356, Length = 17, Global step = 4970, Eps: 0.5\n",
      "Training: Episode = 357, Length = 11, Global step = 4981, Eps: 0.5\n",
      "Training: Episode = 358, Length = 14, Global step = 4995, Eps: 0.5\n",
      "Training: Episode = 359, Length = 14, Global step = 5009, Eps: 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Episode = 360, Length = 14, Global step = 5023, Eps: 0.5\n",
      "Training: Episode = 361, Length = 17, Global step = 5040, Eps: 0.5\n",
      "Training: Episode = 362, Length = 9, Global step = 5049, Eps: 0.5\n",
      "Training: Episode = 363, Length = 10, Global step = 5059, Eps: 0.5\n",
      "Training: Episode = 364, Length = 12, Global step = 5071, Eps: 0.5\n",
      "Training: Episode = 365, Length = 14, Global step = 5085, Eps: 0.5\n",
      "Training: Episode = 366, Length = 18, Global step = 5103, Eps: 0.5\n",
      "Training: Episode = 367, Length = 14, Global step = 5117, Eps: 0.5\n",
      "Training: Episode = 368, Length = 13, Global step = 5130, Eps: 0.5\n",
      "Training: Episode = 369, Length = 12, Global step = 5142, Eps: 0.5\n",
      "Training: Episode = 370, Length = 15, Global step = 5157, Eps: 0.5\n",
      "Training: Episode = 371, Length = 13, Global step = 5170, Eps: 0.5\n",
      "Training: Episode = 372, Length = 10, Global step = 5180, Eps: 0.5\n",
      "Training: Episode = 373, Length = 12, Global step = 5192, Eps: 0.5\n",
      "Training: Episode = 374, Length = 14, Global step = 5206, Eps: 0.5\n",
      "Training: Episode = 375, Length = 8, Global step = 5214, Eps: 0.5\n",
      "Training: Episode = 376, Length = 13, Global step = 5227, Eps: 0.5\n",
      "Training: Episode = 377, Length = 10, Global step = 5237, Eps: 0.5\n",
      "Training: Episode = 378, Length = 9, Global step = 5246, Eps: 0.5\n",
      "Training: Episode = 379, Length = 16, Global step = 5262, Eps: 0.5\n",
      "Training: Episode = 380, Length = 12, Global step = 5274, Eps: 0.5\n",
      "Training: Episode = 381, Length = 10, Global step = 5284, Eps: 0.5\n",
      "Training: Episode = 382, Length = 15, Global step = 5299, Eps: 0.5\n",
      "Training: Episode = 383, Length = 26, Global step = 5325, Eps: 0.5\n",
      "Training: Episode = 384, Length = 12, Global step = 5337, Eps: 0.5\n",
      "Training: Episode = 385, Length = 10, Global step = 5347, Eps: 0.5\n",
      "Training: Episode = 386, Length = 20, Global step = 5367, Eps: 0.5\n",
      "Training: Episode = 387, Length = 19, Global step = 5386, Eps: 0.5\n",
      "Training: Episode = 388, Length = 16, Global step = 5402, Eps: 0.5\n",
      "Training: Episode = 389, Length = 13, Global step = 5415, Eps: 0.5\n",
      "Training: Episode = 390, Length = 11, Global step = 5426, Eps: 0.5\n",
      "Training: Episode = 391, Length = 13, Global step = 5439, Eps: 0.5\n",
      "Training: Episode = 392, Length = 8, Global step = 5447, Eps: 0.5\n",
      "Training: Episode = 393, Length = 14, Global step = 5461, Eps: 0.5\n",
      "Training: Episode = 394, Length = 11, Global step = 5472, Eps: 0.5\n",
      "Training: Episode = 395, Length = 26, Global step = 5498, Eps: 0.5\n",
      "Training: Episode = 396, Length = 9, Global step = 5507, Eps: 0.5\n",
      "Training: Episode = 397, Length = 14, Global step = 5521, Eps: 0.5\n",
      "Training: Episode = 398, Length = 17, Global step = 5538, Eps: 0.5\n",
      "Training: Episode = 399, Length = 12, Global step = 5550, Eps: 0.5\n",
      "Training: Episode = 400, Length = 10, Global step = 5560, Eps: 0.5\n",
      "Training: Episode = 401, Length = 11, Global step = 5571, Eps: 0.5\n",
      "Training: Episode = 402, Length = 11, Global step = 5582, Eps: 0.5\n",
      "Training: Episode = 403, Length = 18, Global step = 5600, Eps: 0.5\n",
      "Training: Episode = 404, Length = 10, Global step = 5610, Eps: 0.5\n",
      "Training: Episode = 405, Length = 10, Global step = 5620, Eps: 0.5\n",
      "Training: Episode = 406, Length = 10, Global step = 5630, Eps: 0.5\n",
      "Training: Episode = 407, Length = 17, Global step = 5647, Eps: 0.5\n",
      "Training: Episode = 408, Length = 11, Global step = 5658, Eps: 0.5\n",
      "Training: Episode = 409, Length = 16, Global step = 5674, Eps: 0.5\n",
      "Training: Episode = 410, Length = 14, Global step = 5688, Eps: 0.5\n",
      "Training: Episode = 411, Length = 10, Global step = 5698, Eps: 0.5\n",
      "Training: Episode = 412, Length = 13, Global step = 5711, Eps: 0.5\n",
      "Training: Episode = 413, Length = 13, Global step = 5724, Eps: 0.5\n",
      "Training: Episode = 414, Length = 15, Global step = 5739, Eps: 0.5\n",
      "Training: Episode = 415, Length = 11, Global step = 5750, Eps: 0.5\n",
      "Training: Episode = 416, Length = 8, Global step = 5758, Eps: 0.5\n",
      "Training: Episode = 417, Length = 14, Global step = 5772, Eps: 0.5\n",
      "Training: Episode = 418, Length = 15, Global step = 5787, Eps: 0.5\n",
      "Training: Episode = 419, Length = 12, Global step = 5799, Eps: 0.5\n",
      "Training: Episode = 420, Length = 13, Global step = 5812, Eps: 0.5\n",
      "Training: Episode = 421, Length = 10, Global step = 5822, Eps: 0.5\n",
      "Training: Episode = 422, Length = 15, Global step = 5837, Eps: 0.5\n",
      "Training: Episode = 423, Length = 12, Global step = 5849, Eps: 0.5\n",
      "Training: Episode = 424, Length = 10, Global step = 5859, Eps: 0.5\n",
      "Training: Episode = 425, Length = 11, Global step = 5870, Eps: 0.5\n",
      "Training: Episode = 426, Length = 9, Global step = 5879, Eps: 0.5\n",
      "Training: Episode = 427, Length = 13, Global step = 5892, Eps: 0.5\n",
      "Training: Episode = 428, Length = 9, Global step = 5901, Eps: 0.5\n",
      "Training: Episode = 429, Length = 9, Global step = 5910, Eps: 0.5\n",
      "Training: Episode = 430, Length = 9, Global step = 5919, Eps: 0.5\n",
      "Training: Episode = 431, Length = 22, Global step = 5941, Eps: 0.5\n",
      "Training: Episode = 432, Length = 13, Global step = 5954, Eps: 0.5\n",
      "Training: Episode = 433, Length = 14, Global step = 5968, Eps: 0.5\n",
      "Training: Episode = 434, Length = 8, Global step = 5976, Eps: 0.5\n",
      "Training: Episode = 435, Length = 13, Global step = 5989, Eps: 0.5\n",
      "Training: Episode = 436, Length = 29, Global step = 6018, Eps: 0.5\n",
      "Training: Episode = 437, Length = 11, Global step = 6029, Eps: 0.5\n",
      "Training: Episode = 438, Length = 22, Global step = 6051, Eps: 0.5\n",
      "Training: Episode = 439, Length = 13, Global step = 6064, Eps: 0.5\n",
      "Training: Episode = 440, Length = 9, Global step = 6073, Eps: 0.5\n",
      "Training: Episode = 441, Length = 9, Global step = 6082, Eps: 0.5\n",
      "Training: Episode = 442, Length = 10, Global step = 6092, Eps: 0.5\n",
      "Training: Episode = 443, Length = 15, Global step = 6107, Eps: 0.5\n",
      "Training: Episode = 444, Length = 15, Global step = 6122, Eps: 0.5\n",
      "Training: Episode = 445, Length = 12, Global step = 6134, Eps: 0.5\n",
      "Training: Episode = 446, Length = 10, Global step = 6144, Eps: 0.5\n",
      "Training: Episode = 447, Length = 13, Global step = 6157, Eps: 0.5\n",
      "Training: Episode = 448, Length = 12, Global step = 6169, Eps: 0.5\n",
      "Training: Episode = 449, Length = 10, Global step = 6179, Eps: 0.5\n",
      "Training: Episode = 450, Length = 33, Global step = 6212, Eps: 0.5\n",
      "Training: Episode = 451, Length = 10, Global step = 6222, Eps: 0.5\n",
      "Training: Episode = 452, Length = 15, Global step = 6237, Eps: 0.5\n",
      "Training: Episode = 453, Length = 11, Global step = 6248, Eps: 0.5\n",
      "Training: Episode = 454, Length = 15, Global step = 6263, Eps: 0.5\n",
      "Training: Episode = 455, Length = 10, Global step = 6273, Eps: 0.5\n",
      "Training: Episode = 456, Length = 13, Global step = 6286, Eps: 0.5\n",
      "Training: Episode = 457, Length = 14, Global step = 6300, Eps: 0.5\n",
      "Training: Episode = 458, Length = 9, Global step = 6309, Eps: 0.5\n",
      "Training: Episode = 459, Length = 13, Global step = 6322, Eps: 0.5\n",
      "Training: Episode = 460, Length = 22, Global step = 6344, Eps: 0.5\n",
      "Training: Episode = 461, Length = 9, Global step = 6353, Eps: 0.5\n",
      "Training: Episode = 462, Length = 16, Global step = 6369, Eps: 0.5\n",
      "Training: Episode = 463, Length = 15, Global step = 6384, Eps: 0.5\n",
      "Training: Episode = 464, Length = 11, Global step = 6395, Eps: 0.5\n",
      "Training: Episode = 465, Length = 24, Global step = 6419, Eps: 0.5\n",
      "Training: Episode = 466, Length = 14, Global step = 6433, Eps: 0.5\n",
      "Training: Episode = 467, Length = 12, Global step = 6445, Eps: 0.5\n",
      "Training: Episode = 468, Length = 10, Global step = 6455, Eps: 0.5\n",
      "Training: Episode = 469, Length = 13, Global step = 6468, Eps: 0.5\n",
      "Training: Episode = 470, Length = 10, Global step = 6478, Eps: 0.5\n",
      "Training: Episode = 471, Length = 13, Global step = 6491, Eps: 0.5\n",
      "Training: Episode = 472, Length = 18, Global step = 6509, Eps: 0.5\n",
      "Training: Episode = 473, Length = 10, Global step = 6519, Eps: 0.5\n",
      "Training: Episode = 474, Length = 10, Global step = 6529, Eps: 0.5\n",
      "Training: Episode = 475, Length = 8, Global step = 6537, Eps: 0.5\n",
      "Training: Episode = 476, Length = 14, Global step = 6551, Eps: 0.5\n",
      "Training: Episode = 477, Length = 23, Global step = 6574, Eps: 0.5\n",
      "Training: Episode = 478, Length = 10, Global step = 6584, Eps: 0.5\n",
      "Training: Episode = 479, Length = 10, Global step = 6594, Eps: 0.5\n",
      "Training: Episode = 480, Length = 14, Global step = 6608, Eps: 0.5\n",
      "Training: Episode = 481, Length = 15, Global step = 6623, Eps: 0.5\n",
      "Training: Episode = 482, Length = 14, Global step = 6637, Eps: 0.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Episode = 483, Length = 26, Global step = 6663, Eps: 0.5\n",
      "Training: Episode = 484, Length = 10, Global step = 6673, Eps: 0.5\n",
      "Training: Episode = 485, Length = 12, Global step = 6685, Eps: 0.5\n",
      "Training: Episode = 486, Length = 29, Global step = 6714, Eps: 0.5\n",
      "Training: Episode = 487, Length = 18, Global step = 6732, Eps: 0.5\n",
      "Training: Episode = 488, Length = 13, Global step = 6745, Eps: 0.5\n",
      "Training: Episode = 489, Length = 11, Global step = 6756, Eps: 0.5\n",
      "Training: Episode = 490, Length = 15, Global step = 6771, Eps: 0.5\n",
      "Training: Episode = 491, Length = 11, Global step = 6782, Eps: 0.5\n",
      "Training: Episode = 492, Length = 8, Global step = 6790, Eps: 0.5\n",
      "Training: Episode = 493, Length = 15, Global step = 6805, Eps: 0.5\n",
      "Training: Episode = 494, Length = 13, Global step = 6818, Eps: 0.5\n",
      "Training: Episode = 495, Length = 13, Global step = 6831, Eps: 0.5\n",
      "Training: Episode = 496, Length = 11, Global step = 6842, Eps: 0.5\n",
      "Training: Episode = 497, Length = 10, Global step = 6852, Eps: 0.5\n",
      "Training: Episode = 498, Length = 13, Global step = 6865, Eps: 0.5\n",
      "Training: Episode = 499, Length = 11, Global step = 6876, Eps: 0.5\n",
      "Training: Episode = 500, Length = 8, Global step = 6884, Eps: 0.5\n",
      "Training: Episode = 501, Length = 10, Global step = 6894, Eps: 0.5\n",
      "Training: Episode = 502, Length = 11, Global step = 6905, Eps: 0.5\n",
      "Training: Episode = 503, Length = 10, Global step = 6915, Eps: 0.5\n",
      "Training: Episode = 504, Length = 13, Global step = 6928, Eps: 0.5\n",
      "Training: Episode = 505, Length = 30, Global step = 6958, Eps: 0.5\n",
      "Training: Episode = 506, Length = 10, Global step = 6968, Eps: 0.5\n",
      "Training: Episode = 507, Length = 18, Global step = 6986, Eps: 0.5\n",
      "Training: Episode = 508, Length = 12, Global step = 6998, Eps: 0.5\n",
      "Training: Episode = 509, Length = 13, Global step = 7011, Eps: 0.5\n",
      "Training: Episode = 510, Length = 11, Global step = 7022, Eps: 0.5\n",
      "Training: Episode = 511, Length = 11, Global step = 7033, Eps: 0.5\n",
      "Training: Episode = 512, Length = 14, Global step = 7047, Eps: 0.5\n",
      "Training: Episode = 513, Length = 14, Global step = 7061, Eps: 0.5\n",
      "Training: Episode = 514, Length = 17, Global step = 7078, Eps: 0.5\n",
      "Training: Episode = 515, Length = 11, Global step = 7089, Eps: 0.5\n",
      "Training: Episode = 516, Length = 31, Global step = 7120, Eps: 0.5\n",
      "Training: Episode = 517, Length = 15, Global step = 7135, Eps: 0.5\n",
      "Training: Episode = 518, Length = 9, Global step = 7144, Eps: 0.5\n",
      "Training: Episode = 519, Length = 10, Global step = 7154, Eps: 0.5\n",
      "Training: Episode = 520, Length = 11, Global step = 7165, Eps: 0.5\n",
      "Training: Episode = 521, Length = 22, Global step = 7187, Eps: 0.5\n",
      "Training: Episode = 522, Length = 14, Global step = 7201, Eps: 0.5\n",
      "Training: Episode = 523, Length = 12, Global step = 7213, Eps: 0.5\n",
      "Training: Episode = 524, Length = 12, Global step = 7225, Eps: 0.5\n",
      "Training: Episode = 525, Length = 20, Global step = 7245, Eps: 0.5\n",
      "Training: Episode = 526, Length = 18, Global step = 7263, Eps: 0.5\n",
      "Training: Episode = 527, Length = 11, Global step = 7274, Eps: 0.5\n",
      "Training: Episode = 528, Length = 14, Global step = 7288, Eps: 0.5\n",
      "Training: Episode = 529, Length = 17, Global step = 7305, Eps: 0.5\n",
      "Training: Episode = 530, Length = 14, Global step = 7319, Eps: 0.5\n",
      "Training: Episode = 531, Length = 10, Global step = 7329, Eps: 0.5\n",
      "Training: Episode = 532, Length = 19, Global step = 7348, Eps: 0.5\n",
      "Training: Episode = 533, Length = 13, Global step = 7361, Eps: 0.5\n",
      "Training: Episode = 534, Length = 15, Global step = 7376, Eps: 0.5\n",
      "Training: Episode = 535, Length = 16, Global step = 7392, Eps: 0.5\n",
      "Training: Episode = 536, Length = 17, Global step = 7409, Eps: 0.5\n",
      "Training: Episode = 537, Length = 12, Global step = 7421, Eps: 0.5\n",
      "Training: Episode = 538, Length = 25, Global step = 7446, Eps: 0.5\n",
      "Training: Episode = 539, Length = 10, Global step = 7456, Eps: 0.5\n",
      "Training: Episode = 540, Length = 12, Global step = 7468, Eps: 0.5\n",
      "Training: Episode = 541, Length = 10, Global step = 7478, Eps: 0.5\n",
      "Training: Episode = 542, Length = 13, Global step = 7491, Eps: 0.5\n",
      "Training: Episode = 543, Length = 10, Global step = 7501, Eps: 0.5\n",
      "Training: Episode = 544, Length = 11, Global step = 7512, Eps: 0.5\n",
      "Training: Episode = 545, Length = 13, Global step = 7525, Eps: 0.5\n",
      "Training: Episode = 546, Length = 11, Global step = 7536, Eps: 0.5\n",
      "Training: Episode = 547, Length = 14, Global step = 7550, Eps: 0.5\n",
      "Training: Episode = 548, Length = 11, Global step = 7561, Eps: 0.5\n",
      "Training: Episode = 549, Length = 20, Global step = 7581, Eps: 0.5\n",
      "Training: Episode = 550, Length = 15, Global step = 7596, Eps: 0.5\n",
      "Training: Episode = 551, Length = 17, Global step = 7613, Eps: 0.5\n",
      "Training: Episode = 552, Length = 14, Global step = 7627, Eps: 0.5\n",
      "Training: Episode = 553, Length = 9, Global step = 7636, Eps: 0.5\n",
      "Training: Episode = 554, Length = 13, Global step = 7649, Eps: 0.5\n",
      "Training: Episode = 555, Length = 15, Global step = 7664, Eps: 0.5\n",
      "Training: Episode = 556, Length = 8, Global step = 7672, Eps: 0.5\n",
      "Training: Episode = 557, Length = 9, Global step = 7681, Eps: 0.5\n",
      "Training: Episode = 558, Length = 10, Global step = 7691, Eps: 0.5\n",
      "Training: Episode = 559, Length = 9, Global step = 7700, Eps: 0.5\n",
      "Training: Episode = 560, Length = 26, Global step = 7726, Eps: 0.5\n",
      "Training: Episode = 561, Length = 12, Global step = 7738, Eps: 0.5\n",
      "Training: Episode = 562, Length = 11, Global step = 7749, Eps: 0.5\n",
      "Training: Episode = 563, Length = 9, Global step = 7758, Eps: 0.5\n",
      "Training: Episode = 564, Length = 40, Global step = 7798, Eps: 0.5\n",
      "Training: Episode = 565, Length = 33, Global step = 7831, Eps: 0.5\n",
      "Training: Episode = 566, Length = 17, Global step = 7848, Eps: 0.5\n",
      "Training: Episode = 567, Length = 21, Global step = 7869, Eps: 0.5\n",
      "Training: Episode = 568, Length = 28, Global step = 7897, Eps: 0.5\n",
      "Training: Episode = 569, Length = 11, Global step = 7908, Eps: 0.5\n",
      "Training: Episode = 570, Length = 24, Global step = 7932, Eps: 0.5\n",
      "Training: Episode = 571, Length = 16, Global step = 7948, Eps: 0.5\n",
      "Training: Episode = 572, Length = 12, Global step = 7960, Eps: 0.5\n",
      "Training: Episode = 573, Length = 12, Global step = 7972, Eps: 0.5\n",
      "Training: Episode = 574, Length = 15, Global step = 7987, Eps: 0.5\n",
      "Training: Episode = 575, Length = 8, Global step = 7995, Eps: 0.5\n",
      "Training: Episode = 576, Length = 8, Global step = 8003, Eps: 0.5\n",
      "Training: Episode = 577, Length = 12, Global step = 8015, Eps: 0.5\n",
      "Training: Episode = 578, Length = 9, Global step = 8024, Eps: 0.5\n",
      "Training: Episode = 579, Length = 12, Global step = 8036, Eps: 0.5\n",
      "Training: Episode = 580, Length = 18, Global step = 8054, Eps: 0.5\n",
      "Training: Episode = 581, Length = 11, Global step = 8065, Eps: 0.5\n",
      "Training: Episode = 582, Length = 10, Global step = 8075, Eps: 0.5\n",
      "Training: Episode = 583, Length = 15, Global step = 8090, Eps: 0.5\n",
      "Training: Episode = 584, Length = 11, Global step = 8101, Eps: 0.5\n",
      "Training: Episode = 585, Length = 20, Global step = 8121, Eps: 0.5\n",
      "Training: Episode = 586, Length = 16, Global step = 8137, Eps: 0.5\n",
      "Training: Episode = 587, Length = 9, Global step = 8146, Eps: 0.5\n",
      "Training: Episode = 588, Length = 12, Global step = 8158, Eps: 0.5\n",
      "Training: Episode = 589, Length = 18, Global step = 8176, Eps: 0.5\n",
      "Training: Episode = 590, Length = 18, Global step = 8194, Eps: 0.49985001499950005\n",
      "Training: Episode = 591, Length = 10, Global step = 8204, Eps: 0.4993503898570359\n",
      "Training: Episode = 592, Length = 27, Global step = 8231, Eps: 0.49800389506456644\n",
      "Training: Episode = 593, Length = 13, Global step = 8244, Eps: 0.4973568783016272\n",
      "Training: Episode = 594, Length = 18, Global step = 8262, Eps: 0.4964623964710172\n",
      "Training: Episode = 595, Length = 9, Global step = 8271, Eps: 0.4960157589989595\n",
      "Training: Episode = 596, Length = 12, Global step = 8283, Eps: 0.4954208673494629\n",
      "Training: Episode = 597, Length = 15, Global step = 8298, Eps: 0.49467825601500054\n",
      "Training: Episode = 598, Length = 17, Global step = 8315, Eps: 0.49383797540593977\n",
      "Training: Episode = 599, Length = 12, Global step = 8327, Eps: 0.4932456956598965\n",
      "Training: Episode = 600, Length = 15, Global step = 8342, Eps: 0.4925063448000278\n",
      "Training: Episode = 601, Length = 13, Global step = 8355, Eps: 0.4918664705659152\n",
      "Training: Episode = 602, Length = 28, Global step = 8383, Eps: 0.49049110209324154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Episode = 603, Length = 14, Global step = 8397, Eps: 0.4898048607187243\n",
      "Training: Episode = 604, Length = 14, Global step = 8411, Eps: 0.48911957945790147\n",
      "Training: Episode = 605, Length = 16, Global step = 8427, Eps: 0.4883375748004464\n",
      "Training: Episode = 606, Length = 10, Global step = 8437, Eps: 0.48784945691896436\n",
      "Training: Episode = 607, Length = 25, Global step = 8462, Eps: 0.4866312957036009\n",
      "Training: Episode = 608, Length = 15, Global step = 8477, Eps: 0.4859018595015552\n",
      "Training: Episode = 609, Length = 18, Global step = 8495, Eps: 0.48502797918795015\n",
      "Training: Episode = 610, Length = 12, Global step = 8507, Eps: 0.4844462656247088\n",
      "Training: Episode = 611, Length = 11, Global step = 8518, Eps: 0.4839136410980502\n",
      "Training: Episode = 612, Length = 14, Global step = 8532, Eps: 0.4832366021858303\n",
      "Training: Episode = 613, Length = 12, Global step = 8544, Eps: 0.48265703709307667\n",
      "Training: Episode = 614, Length = 13, Global step = 8557, Eps: 0.48202995927933917\n",
      "Training: Episode = 615, Length = 10, Global step = 8567, Eps: 0.48154814617570796\n",
      "Training: Episode = 616, Length = 17, Global step = 8584, Eps: 0.48073016890535014\n",
      "Training: Episode = 617, Length = 11, Global step = 8595, Eps: 0.48020163004184274\n",
      "Training: Episode = 618, Length = 11, Global step = 8606, Eps: 0.47967367228047586\n",
      "Training: Episode = 619, Length = 14, Global step = 8620, Eps: 0.4790025654677718\n",
      "Training: Episode = 620, Length = 14, Global step = 8634, Eps: 0.4783323975941426\n",
      "Training: Episode = 621, Length = 11, Global step = 8645, Eps: 0.4778064949606987\n",
      "Training: Episode = 622, Length = 10, Global step = 8655, Eps: 0.4773289034213341\n",
      "Training: Episode = 623, Length = 12, Global step = 8667, Eps: 0.47675642366931603\n",
      "Training: Episode = 624, Length = 16, Global step = 8683, Eps: 0.47599418523225684\n",
      "Training: Episode = 625, Length = 25, Global step = 8708, Eps: 0.47480562665754716\n",
      "Training: Episode = 626, Length = 11, Global step = 8719, Eps: 0.4742836015329913\n",
      "Training: Episode = 627, Length = 11, Global step = 8730, Eps: 0.47376215034904473\n",
      "Training: Episode = 628, Length = 28, Global step = 8758, Eps: 0.47243740559792047\n",
      "Training: Episode = 629, Length = 11, Global step = 8769, Eps: 0.47191798421439934\n",
      "Training: Episode = 630, Length = 9, Global step = 8778, Eps: 0.4714934278794455\n",
      "Training: Episode = 631, Length = 10, Global step = 8788, Eps: 0.4710221465670393\n",
      "Training: Episode = 632, Length = 10, Global step = 8798, Eps: 0.47055133632392554\n",
      "Training: Episode = 633, Length = 13, Global step = 8811, Eps: 0.4699399864822028\n",
      "Training: Episode = 634, Length = 18, Global step = 8829, Eps: 0.46909481313138707\n",
      "Training: Episode = 635, Length = 18, Global step = 8847, Eps: 0.46825115980017684\n",
      "Training: Episode = 636, Length = 15, Global step = 8862, Eps: 0.467549274511204\n",
      "Training: Episode = 637, Length = 11, Global step = 8873, Eps: 0.4670352273842125\n",
      "Training: Episode = 638, Length = 11, Global step = 8884, Eps: 0.46652174542641967\n",
      "Training: Episode = 639, Length = 10, Global step = 8894, Eps: 0.46605543355980594\n",
      "Training: Episode = 640, Length = 14, Global step = 8908, Eps: 0.46540337989366926\n",
      "Training: Episode = 641, Length = 8, Global step = 8916, Eps: 0.4650311874766414\n",
      "Training: Episode = 642, Length = 23, Global step = 8939, Eps: 0.463962791451191\n",
      "Training: Episode = 643, Length = 13, Global step = 8952, Eps: 0.4633600015806216\n",
      "Training: Episode = 644, Length = 28, Global step = 8980, Eps: 0.462064343559983\n",
      "Training: Episode = 645, Length = 9, Global step = 8989, Eps: 0.4616486519551352\n",
      "Training: Episode = 646, Length = 13, Global step = 9002, Eps: 0.46104886866154365\n",
      "Training: Episode = 647, Length = 11, Global step = 9013, Eps: 0.46054196840683587\n",
      "Training: Episode = 648, Length = 21, Global step = 9034, Eps: 0.45957579679907\n",
      "Training: Episode = 649, Length = 13, Global step = 9047, Eps: 0.458978706600947\n",
      "Training: Episode = 650, Length = 10, Global step = 9057, Eps: 0.45851993437969624\n",
      "Training: Episode = 651, Length = 10, Global step = 9067, Eps: 0.4580616207242743\n",
      "Training: Episode = 652, Length = 9, Global step = 9076, Eps: 0.45764953012933457\n",
      "Training: Episode = 653, Length = 12, Global step = 9088, Eps: 0.457100652641209\n",
      "Training: Episode = 654, Length = 11, Global step = 9099, Eps: 0.4565980932532561\n",
      "Training: Episode = 655, Length = 8, Global step = 9107, Eps: 0.4562329426005534\n",
      "Training: Episode = 656, Length = 12, Global step = 9119, Eps: 0.4556857640828263\n",
      "Training: Episode = 657, Length = 14, Global step = 9133, Eps: 0.4550482185213317\n",
      "Training: Episode = 658, Length = 14, Global step = 9147, Eps: 0.45441156494368873\n",
      "Training: Episode = 659, Length = 9, Global step = 9156, Eps: 0.45400275808523793\n",
      "Training: Episode = 660, Length = 18, Global step = 9174, Eps: 0.4531862473745772\n",
      "Training: Episode = 661, Length = 17, Global step = 9191, Eps: 0.4524164467792781\n",
      "Training: Episode = 662, Length = 8, Global step = 9199, Eps: 0.4520546402731277\n",
      "Training: Episode = 663, Length = 13, Global step = 9212, Eps: 0.4514673217141367\n",
      "Training: Episode = 664, Length = 9, Global step = 9221, Eps: 0.4510611636149123\n",
      "Training: Episode = 665, Length = 10, Global step = 9231, Eps: 0.45061030537470326\n",
      "Training: Episode = 666, Length = 18, Global step = 9249, Eps: 0.449799895891236\n",
      "Training: Episode = 667, Length = 12, Global step = 9261, Eps: 0.44926043278516414\n",
      "Training: Episode = 668, Length = 14, Global step = 9275, Eps: 0.448631876842773\n",
      "Training: Episode = 669, Length = 13, Global step = 9288, Eps: 0.4480490052074648\n",
      "Training: Episode = 670, Length = 10, Global step = 9298, Eps: 0.44760115777055326\n",
      "Training: Episode = 671, Length = 11, Global step = 9309, Eps: 0.4471090426038031\n",
      "Training: Episode = 672, Length = 16, Global step = 9325, Eps: 0.44639420441618854\n",
      "Training: Episode = 673, Length = 21, Global step = 9346, Eps: 0.4454577134213066\n",
      "Training: Episode = 674, Length = 16, Global step = 9362, Eps: 0.4447455153797134\n",
      "Training: Episode = 675, Length = 27, Global step = 9389, Eps: 0.4435462622448469\n",
      "Training: Episode = 676, Length = 20, Global step = 9409, Eps: 0.44266001195282756\n",
      "Training: Episode = 677, Length = 26, Global step = 9435, Eps: 0.4415105334165345\n",
      "Training: Episode = 678, Length = 13, Global step = 9448, Eps: 0.4409369139750687\n",
      "Training: Episode = 679, Length = 10, Global step = 9458, Eps: 0.4404961754298018\n",
      "Training: Episode = 680, Length = 12, Global step = 9470, Eps: 0.4399678706498745\n",
      "Training: Episode = 681, Length = 12, Global step = 9482, Eps: 0.43944019948711827\n",
      "Training: Episode = 682, Length = 34, Global step = 9516, Eps: 0.4379485654408079\n",
      "Training: Episode = 683, Length = 14, Global step = 9530, Eps: 0.437335835823016\n",
      "Training: Episode = 684, Length = 14, Global step = 9544, Eps: 0.43672396346932796\n",
      "Training: Episode = 685, Length = 22, Global step = 9566, Eps: 0.4357641789098155\n",
      "Training: Episode = 686, Length = 12, Global step = 9578, Eps: 0.4352415494036353\n",
      "Training: Episode = 687, Length = 22, Global step = 9600, Eps: 0.43428502273297287\n",
      "Training: Episode = 688, Length = 21, Global step = 9621, Eps: 0.4333739356064422\n",
      "Training: Episode = 689, Length = 13, Global step = 9634, Eps: 0.4328108873979097\n",
      "Training: Episode = 690, Length = 16, Global step = 9650, Eps: 0.43211890910884265\n",
      "Training: Episode = 691, Length = 19, Global step = 9669, Eps: 0.4312986216863146\n",
      "Training: Episode = 692, Length = 13, Global step = 9682, Eps: 0.4307382697677269\n",
      "Training: Episode = 693, Length = 11, Global step = 9693, Eps: 0.4302646945059732\n",
      "Training: Episode = 694, Length = 36, Global step = 9729, Eps: 0.42871844920377017\n",
      "Training: Episode = 695, Length = 13, Global step = 9742, Eps: 0.42816144949761287\n",
      "Training: Episode = 696, Length = 55, Global step = 9797, Eps: 0.42581290850467335\n",
      "Training: Episode = 697, Length = 15, Global step = 9812, Eps: 0.4251746360517837\n",
      "Training: Episode = 698, Length = 52, Global step = 9864, Eps: 0.42296935637512884\n",
      "Training: Episode = 699, Length = 14, Global step = 9878, Eps: 0.4223775840243994\n",
      "Training: Episode = 700, Length = 33, Global step = 9911, Eps: 0.42098596584799797\n",
      "Training: Episode = 701, Length = 22, Global step = 9933, Eps: 0.42006076855270313\n",
      "Training: Episode = 702, Length = 13, Global step = 9946, Eps: 0.41951501708087674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Episode = 703, Length = 41, Global step = 9987, Eps: 0.41779844106620057\n",
      "Training: Episode = 704, Length = 45, Global step = 10032, Eps: 0.41592247836362944\n",
      "Training: Episode = 705, Length = 21, Global step = 10053, Eps: 0.4150499140433424\n",
      "Training: Episode = 706, Length = 64, Global step = 10117, Eps: 0.4124019447334324\n",
      "Training: Episode = 707, Length = 38, Global step = 10155, Eps: 0.4108377130531363\n",
      "Training: Episode = 708, Length = 16, Global step = 10171, Eps: 0.4101808654875127\n",
      "Training: Episode = 709, Length = 40, Global step = 10211, Eps: 0.40854333738747256\n",
      "Training: Episode = 710, Length = 13, Global step = 10224, Eps: 0.4080125495958579\n",
      "Training: Episode = 711, Length = 38, Global step = 10262, Eps: 0.4064649667966334\n",
      "Training: Episode = 712, Length = 10, Global step = 10272, Eps: 0.4060586846903046\n",
      "Training: Episode = 713, Length = 17, Global step = 10289, Eps: 0.4053689368901189\n",
      "Training: Episode = 714, Length = 21, Global step = 10310, Eps: 0.4045185128585191\n",
      "Training: Episode = 715, Length = 34, Global step = 10344, Eps: 0.4031454168448934\n",
      "Training: Episode = 716, Length = 27, Global step = 10371, Eps: 0.40205833808133234\n",
      "Training: Episode = 717, Length = 16, Global step = 10387, Eps: 0.40141552698532845\n",
      "Training: Episode = 718, Length = 25, Global step = 10412, Eps: 0.400413191491698\n",
      "Training: Episode = 719, Length = 18, Global step = 10430, Eps: 0.3996930600525814\n",
      "Training: Episode = 720, Length = 27, Global step = 10457, Eps: 0.3986152905446792\n",
      "Training: Episode = 721, Length = 24, Global step = 10481, Eps: 0.3976597132192\n",
      "Training: Episode = 722, Length = 26, Global step = 10507, Eps: 0.39662708932557716\n",
      "Training: Episode = 723, Length = 36, Global step = 10543, Eps: 0.39520172772508533\n",
      "Training: Episode = 724, Length = 50, Global step = 10593, Eps: 0.3932305525707641\n",
      "Training: Episode = 725, Length = 11, Global step = 10604, Eps: 0.39279821517487024\n",
      "Training: Episode = 726, Length = 23, Global step = 10627, Eps: 0.3918957723641547\n",
      "Training: Episode = 727, Length = 58, Global step = 10685, Eps: 0.389629242845833\n",
      "Training: Episode = 728, Length = 32, Global step = 10717, Eps: 0.3883843598986102\n",
      "Training: Episode = 729, Length = 50, Global step = 10767, Eps: 0.38644718820412893\n",
      "Training: Episode = 730, Length = 105, Global step = 10872, Eps: 0.3824105204854301\n",
      "Training: Episode = 731, Length = 51, Global step = 10923, Eps: 0.38046509461093925\n",
      "Training: Episode = 732, Length = 53, Global step = 10976, Eps: 0.37845386351685983\n",
      "Training: Episode = 733, Length = 194, Global step = 11170, Eps: 0.3711822576271814\n",
      "Training: Episode = 734, Length = 74, Global step = 11244, Eps: 0.3684455105346496\n",
      "Training: Episode = 735, Length = 68, Global step = 11312, Eps: 0.36594845581669666\n",
      "Training: Episode = 736, Length = 83, Global step = 11395, Eps: 0.36292350330280115\n",
      "Training: Episode = 737, Length = 58, Global step = 11453, Eps: 0.36082453492616845\n",
      "Training: Episode = 738, Length = 62, Global step = 11515, Eps: 0.35859423237530297\n",
      "Training: Episode = 739, Length = 144, Global step = 11659, Eps: 0.35346722214682047\n",
      "Training: Episode = 740, Length = 74, Global step = 11733, Eps: 0.35086108898005913\n",
      "Training: Episode = 741, Length = 102, Global step = 11835, Eps: 0.34730031863311667\n",
      "Training: Episode = 742, Length = 200, Global step = 12035, Eps: 0.3404229711173575\n",
      "Training: Episode = 743, Length = 96, Global step = 12131, Eps: 0.33717038535535915\n",
      "Training: Episode = 744, Length = 47, Global step = 12178, Eps: 0.3355893238948459\n",
      "Training: Episode = 745, Length = 115, Global step = 12293, Eps: 0.3317519619230451\n",
      "Training: Episode = 746, Length = 36, Global step = 12329, Eps: 0.3305597425307262\n",
      "Training: Episode = 747, Length = 66, Global step = 12395, Eps: 0.3283851236338817\n",
      "Training: Episode = 748, Length = 48, Global step = 12443, Eps: 0.32681257355126875\n",
      "Training: Episode = 749, Length = 77, Global step = 12520, Eps: 0.324305655408649\n",
      "Training: Episode = 750, Length = 61, Global step = 12581, Eps: 0.3223333140492945\n",
      "Training: Episode = 751, Length = 76, Global step = 12657, Eps: 0.3198927447432337\n",
      "Training: Episode = 752, Length = 72, Global step = 12729, Eps: 0.3175976743941004\n",
      "Training: Episode = 753, Length = 75, Global step = 12804, Eps: 0.3152244837643738\n",
      "Training: Episode = 754, Length = 63, Global step = 12867, Eps: 0.31324471335170156\n",
      "Training: Episode = 755, Length = 52, Global step = 12919, Eps: 0.31161998755293596\n",
      "Training: Episode = 756, Length = 179, Global step = 13098, Eps: 0.30609134233955804\n",
      "Training: Episode = 757, Length = 98, Global step = 13196, Eps: 0.3031061492612244\n",
      "Training: Episode = 758, Length = 87, Global step = 13283, Eps: 0.3004804329033158\n",
      "Training: Episode = 759, Length = 51, Global step = 13334, Eps: 0.2989518075710254\n",
      "Training: Episode = 760, Length = 96, Global step = 13430, Eps: 0.29609545980566293\n",
      "Training: Episode = 761, Length = 77, Global step = 13507, Eps: 0.29382416689894186\n",
      "Training: Episode = 762, Length = 80, Global step = 13587, Eps: 0.2914828343132313\n",
      "Training: Episode = 763, Length = 107, Global step = 13694, Eps: 0.28838044027275705\n",
      "Training: Episode = 764, Length = 101, Global step = 13795, Eps: 0.2854823130971514\n",
      "Training: Episode = 765, Length = 165, Global step = 13960, Eps: 0.2808102716686287\n",
      "Training: Episode = 766, Length = 162, Global step = 14122, Eps: 0.2762975711998728\n",
      "Training: Episode = 767, Length = 190, Global step = 14312, Eps: 0.2710972171394786\n",
      "Training: Episode = 768, Length = 174, Global step = 14486, Eps: 0.266420695463796\n",
      "Training: Episode = 769, Length = 194, Global step = 14680, Eps: 0.26130169289829436\n",
      "Training: Episode = 770, Length = 169, Global step = 14849, Eps: 0.2569225830386644\n",
      "Training: Episode = 771, Length = 161, Global step = 15010, Eps: 0.2528190463854093\n",
      "Training: Episode = 772, Length = 174, Global step = 15184, Eps: 0.24845782953883966\n",
      "Training: Episode = 773, Length = 144, Global step = 15328, Eps: 0.24490549735280795\n",
      "Training: Episode = 774, Length = 200, Global step = 15528, Eps: 0.24005580351882558\n",
      "Training: Episode = 775, Length = 127, Global step = 15655, Eps: 0.2370262218978524\n",
      "Training: Episode = 776, Length = 200, Global step = 15855, Eps: 0.23233255589502613\n",
      "Training: Episode = 777, Length = 200, Global step = 16055, Eps: 0.2277318353071401\n",
      "Training: Episode = 778, Length = 200, Global step = 16255, Eps: 0.22322221960055783\n",
      "Training: Episode = 779, Length = 200, Global step = 16455, Eps: 0.21880190468845442\n",
      "Training: Episode = 780, Length = 200, Global step = 16655, Eps: 0.21446912220908634\n",
      "Training: Episode = 781, Length = 200, Global step = 16855, Eps: 0.21022213881835175\n",
      "Training: Episode = 782, Length = 200, Global step = 17055, Eps: 0.20605925549636053\n",
      "Training: Episode = 783, Length = 200, Global step = 17255, Eps: 0.20197880686773648\n",
      "Training: Episode = 784, Length = 200, Global step = 17455, Eps: 0.197979160535378\n",
      "Training: Episode = 785, Length = 200, Global step = 17655, Eps: 0.1940587164274114\n",
      "Training: Episode = 786, Length = 200, Global step = 17855, Eps: 0.19021590615707756\n",
      "Training: Episode = 787, Length = 200, Global step = 18055, Eps: 0.18644919239529334\n",
      "Training: Episode = 788, Length = 200, Global step = 18255, Eps: 0.1827570682556385\n",
      "Training: Episode = 789, Length = 200, Global step = 18455, Eps: 0.1791380566915196\n",
      "Training: Episode = 790, Length = 200, Global step = 18655, Eps: 0.17559070990527365\n",
      "Training: Episode = 791, Length = 200, Global step = 18855, Eps: 0.172113608768971\n",
      "Training: Episode = 792, Length = 200, Global step = 19055, Eps: 0.1687053622566893\n",
      "Training: Episode = 793, Length = 200, Global step = 19255, Eps: 0.16536460688802807\n",
      "Training: Episode = 794, Length = 200, Global step = 19455, Eps: 0.16209000618264455\n",
      "Training: Episode = 795, Length = 200, Global step = 19655, Eps: 0.15888025012558976\n",
      "Training: Episode = 796, Length = 200, Global step = 19855, Eps: 0.15573405464323317\n",
      "Training: Episode = 797, Length = 200, Global step = 20055, Eps: 0.15265016108956433\n",
      "Training: Episode = 798, Length = 200, Global step = 20255, Eps: 0.14962733574266732\n",
      "Training: Episode = 799, Length = 200, Global step = 20455, Eps: 0.14666436931116628\n",
      "Training: Episode = 800, Length = 200, Global step = 20655, Eps: 0.14376007645044436\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Episode = 801, Length = 200, Global step = 20855, Eps: 0.14091329528844276\n",
      "Training: Episode = 802, Length = 200, Global step = 21055, Eps: 0.1381228869608498\n",
      "Training: Episode = 803, Length = 200, Global step = 21255, Eps: 0.13538773515549488\n",
      "Training: Episode = 804, Length = 200, Global step = 21455, Eps: 0.13270674566576265\n",
      "Training: Episode = 805, Length = 200, Global step = 21655, Eps: 0.13007884595285435\n",
      "Training: Episode = 806, Length = 200, Global step = 21855, Eps: 0.12750298471671262\n",
      "Training: Episode = 807, Length = 200, Global step = 22055, Eps: 0.12497813147544692\n",
      "Training: Episode = 808, Length = 200, Global step = 22255, Eps: 0.12250327615308564\n",
      "Training: Episode = 809, Length = 200, Global step = 22455, Eps: 0.12007742867549145\n",
      "Training: Episode = 810, Length = 200, Global step = 22655, Eps: 0.11769961857427877\n",
      "Training: Episode = 811, Length = 200, Global step = 22855, Eps: 0.11536889459857541\n",
      "Training: Episode = 812, Length = 200, Global step = 23055, Eps: 0.11308432433447035\n",
      "Training: Episode = 813, Length = 200, Global step = 23255, Eps: 0.1108449938319995\n",
      "Training: Episode = 814, Length = 200, Global step = 23455, Eps: 0.10865000723951619\n",
      "Training: Episode = 815, Length = 200, Global step = 23655, Eps: 0.10649848644530326\n",
      "Training: Episode = 816, Length = 200, Global step = 23855, Eps: 0.10438957072628123\n",
      "Training: Episode = 817, Length = 200, Global step = 24055, Eps: 0.10232241640367316\n",
      "Training: Episode = 818, Length = 200, Global step = 24255, Eps: 0.10029619650548845\n",
      "Training: Episode = 819, Length = 200, Global step = 24455, Eps: 0.09831010043568962\n",
      "Training: Episode = 820, Length = 200, Global step = 24655, Eps: 0.09636333364991047\n",
      "Training: Episode = 821, Length = 200, Global step = 24855, Eps: 0.09445511733759654\n",
      "Training: Episode = 822, Length = 200, Global step = 25055, Eps: 0.09258468811043905\n",
      "Training: Episode = 823, Length = 200, Global step = 25255, Eps: 0.09075129769697869\n",
      "Training: Episode = 824, Length = 200, Global step = 25455, Eps: 0.08895421264325724\n",
      "Training: Episode = 825, Length = 200, Global step = 25655, Eps: 0.0871927140193969\n",
      "Training: Episode = 826, Length = 200, Global step = 25855, Eps: 0.08546609713199033\n",
      "Training: Episode = 827, Length = 200, Global step = 26055, Eps: 0.08377367124218496\n",
      "Training: Episode = 828, Length = 200, Global step = 26255, Eps: 0.08211475928935108\n",
      "Training: Episode = 829, Length = 200, Global step = 26455, Eps: 0.0804886976202215\n",
      "Training: Episode = 830, Length = 200, Global step = 26655, Eps: 0.07889483572339467\n",
      "Training: Episode = 831, Length = 200, Global step = 26855, Eps: 0.07733253596909549\n",
      "Training: Episode = 832, Length = 200, Global step = 27055, Eps: 0.07580117335408948\n",
      "Training: Episode = 833, Length = 200, Global step = 27255, Eps: 0.0743001352516478\n",
      "Training: Episode = 834, Length = 200, Global step = 27455, Eps: 0.07282882116646452\n",
      "Training: Episode = 835, Length = 200, Global step = 27655, Eps: 0.07138664249442606\n",
      "Training: Episode = 836, Length = 200, Global step = 27855, Eps: 0.06997302228713777\n",
      "Training: Episode = 837, Length = 200, Global step = 28055, Eps: 0.06858739502111447\n",
      "Training: Episode = 838, Length = 200, Global step = 28255, Eps: 0.06722920637154062\n",
      "Training: Episode = 839, Length = 200, Global step = 28455, Eps: 0.0658979129905107\n",
      "Training: Episode = 840, Length = 200, Global step = 28655, Eps: 0.06459298228966162\n",
      "Training: Episode = 841, Length = 200, Global step = 28855, Eps: 0.06331389222710822\n",
      "Training: Episode = 842, Length = 200, Global step = 29055, Eps: 0.06206013109859875\n",
      "Training: Episode = 843, Length = 200, Global step = 29255, Eps: 0.060831197332806446\n",
      "Training: Episode = 844, Length = 200, Global step = 29455, Eps: 0.05962659929067392\n",
      "Training: Episode = 845, Length = 200, Global step = 29655, Eps: 0.05844585506873124\n",
      "Training: Episode = 846, Length = 200, Global step = 29855, Eps: 0.057288492306308905\n",
      "Training: Episode = 847, Length = 200, Global step = 30055, Eps: 0.05615404799656845\n",
      "Training: Episode = 848, Length = 200, Global step = 30255, Eps: 0.05504206830127481\n",
      "Training: Episode = 849, Length = 200, Global step = 30455, Eps: 0.05395210836923708\n",
      "Training: Episode = 850, Length = 200, Global step = 30655, Eps: 0.05288373215834413\n",
      "Training: Episode = 851, Length = 200, Global step = 30855, Eps: 0.05183651226112465\n",
      "Training: Episode = 852, Length = 200, Global step = 31055, Eps: 0.05081002973376113\n",
      "Training: Episode = 853, Length = 200, Global step = 31255, Eps: 0.04980387392849024\n",
      "Training: Episode = 854, Length = 200, Global step = 31455, Eps: 0.048817642329321606\n",
      "Training: Episode = 855, Length = 200, Global step = 31655, Eps: 0.04785094039101026\n",
      "Training: Episode = 856, Length = 200, Global step = 31855, Eps: 0.04690338138121703\n",
      "Training: Episode = 857, Length = 200, Global step = 32055, Eps: 0.045974586225795366\n",
      "Training: Episode = 858, Length = 200, Global step = 32255, Eps: 0.045064183357141345\n",
      "Training: Episode = 859, Length = 200, Global step = 32455, Eps: 0.04417180856554676\n",
      "Training: Episode = 860, Length = 200, Global step = 32655, Eps: 0.04329710485349582\n",
      "Training: Episode = 861, Length = 200, Global step = 32855, Eps: 0.04243972229284705\n",
      "Training: Episode = 862, Length = 200, Global step = 33055, Eps: 0.04159931788484365\n",
      "Training: Episode = 863, Length = 200, Global step = 33255, Eps: 0.04077555542289544\n",
      "Training: Episode = 864, Length = 200, Global step = 33455, Eps: 0.03996810535807822\n",
      "Training: Episode = 865, Length = 200, Global step = 33655, Eps: 0.03917664466729672\n",
      "Training: Episode = 866, Length = 200, Global step = 33855, Eps: 0.03840085672405831\n",
      "Training: Episode = 867, Length = 200, Global step = 34055, Eps: 0.03764043117180527\n",
      "Training: Episode = 868, Length = 200, Global step = 34255, Eps: 0.03689506379975575\n",
      "Training: Episode = 869, Length = 200, Global step = 34455, Eps: 0.036164456421203084\n",
      "Training: Episode = 870, Length = 200, Global step = 34655, Eps: 0.035448316754225426\n",
      "Training: Episode = 871, Length = 200, Global step = 34855, Eps: 0.034746358304757176\n",
      "Training: Episode = 872, Length = 200, Global step = 35055, Eps: 0.0340583002519762\n",
      "Training: Episode = 873, Length = 200, Global step = 35255, Eps: 0.03338386733596043\n",
      "Training: Episode = 874, Length = 200, Global step = 35455, Eps: 0.032722789747569425\n",
      "Training: Episode = 875, Length = 200, Global step = 35655, Eps: 0.03207480302050593\n",
      "Training: Episode = 876, Length = 200, Global step = 35855, Eps: 0.031439647925515755\n",
      "Training: Episode = 877, Length = 200, Global step = 36055, Eps: 0.030817070366681694\n",
      "Training: Episode = 878, Length = 200, Global step = 36255, Eps: 0.030206821279772072\n",
      "Training: Episode = 879, Length = 200, Global step = 36455, Eps: 0.029608656532601526\n",
      "Training: Episode = 880, Length = 200, Global step = 36655, Eps: 0.029022336827365155\n",
      "Training: Episode = 881, Length = 200, Global step = 36855, Eps: 0.028447627604906715\n",
      "Training: Episode = 882, Length = 200, Global step = 37055, Eps: 0.02788429895088224\n",
      "Training: Episode = 883, Length = 200, Global step = 37255, Eps: 0.027332125503782313\n",
      "Training: Episode = 884, Length = 200, Global step = 37455, Eps: 0.026790886364775248\n",
      "Training: Episode = 885, Length = 200, Global step = 37655, Eps: 0.02626036500933583\n",
      "Training: Episode = 886, Length = 200, Global step = 37855, Eps: 0.02574034920062395\n",
      "Training: Episode = 887, Length = 200, Global step = 38055, Eps: 0.025230630904578544\n",
      "Training: Episode = 888, Length = 200, Global step = 38255, Eps: 0.024731006206692926\n",
      "Training: Episode = 889, Length = 200, Global step = 38455, Eps: 0.02424127523043804\n",
      "Training: Episode = 890, Length = 200, Global step = 38655, Eps: 0.02376124205730118\n",
      "Training: Episode = 891, Length = 200, Global step = 38855, Eps: 0.02329071464840822\n",
      "Training: Episode = 892, Length = 200, Global step = 39055, Eps: 0.022829504767697753\n",
      "Training: Episode = 893, Length = 200, Global step = 39255, Eps: 0.02237742790661661\n",
      "Training: Episode = 894, Length = 200, Global step = 39455, Eps: 0.021934303210306625\n",
      "Training: Episode = 895, Length = 200, Global step = 39655, Eps: 0.0214999534052531\n",
      "Training: Episode = 896, Length = 200, Global step = 39855, Eps: 0.02107420472836586\n",
      "Training: Episode = 897, Length = 200, Global step = 40055, Eps: 0.02065688685746481\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-b102fc773b03>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nStarting training...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nFinished training...\\nCheck out some demonstrations\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-1b33369a0810>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, episodes_num)\u001b[0m\n\u001b[1;32m    183\u001b[0m                         \u001b[0mnst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m                         \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                     \u001b[0mmax_Q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m                     \u001b[0mbatch_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m                     \u001b[0;31m# for st, act, rwd, nst, d in replay_batch:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1238\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1241\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflat_map\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslice_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"batch\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mslice_inputs\u001b[0;34m(self, indices_dataset, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m     dataset = dataset.map(\n\u001b[0m\u001b[1;32m    397\u001b[0m         grab_batch, num_parallel_calls=dataset_ops.AUTOTUNE)\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1621\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m       return ParallelMapDataset(\n\u001b[0m\u001b[1;32m   1624\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1625\u001b[0m           \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4014\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4015\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4016\u001b[0;31m     self._map_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m   4017\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4018\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3219\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3220\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2529\u001b[0m       \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputs\u001b[0m \u001b[0mto\u001b[0m \u001b[0mspecialize\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2530\u001b[0m     \"\"\"\n\u001b[0;32m-> 2531\u001b[0;31m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[1;32m   2532\u001b[0m         *args, **kwargs)\n\u001b[1;32m   2533\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2510\u001b[0m           \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2511\u001b[0m         \u001b[0mnum_positional\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2512\u001b[0;31m         \u001b[0muser_arg_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_user_specified_name\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2513\u001b[0m         \u001b[0mproposal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muser_arg_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2514\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mproposal\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseen_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   2325\u001b[0m     \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tensor\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"func\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2327\u001b[0;31m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2328\u001b[0m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2329\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.8/contextlib.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32mdel\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create and initialize the model\n",
    "dqn = DQN('CartPole-v0')\n",
    "dqn.initialize_network()\n",
    "\n",
    "print(\"\\nStarting training...\\n\")\n",
    "dqn.train()\n",
    "print(\"\\nFinished training...\\nCheck out some demonstrations\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_batch = np.array(rd.sample(dqn.replay_buffer,dqn.MINIBATCH_SIZE))\n",
    "nst = []\n",
    "st = []\n",
    "acts = []\n",
    "for y in replay_batch:\n",
    "    nst.append(y[3])\n",
    "    st.append(y[0])\n",
    "    acts.append(y[1])\n",
    "max_Q = np.amax(dqn.target_model.predict(np.array(nst),1))\n",
    "tgts = replay_batch[:,2] + dqn.DISCOUNT_FACTOR * max_Q * (1-replay_batch[:,4])\n",
    "batch_targets = dqn.target_model.predict(np.array(st))\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_targets[1],tgts[1])\n",
    "batch_targets[:,list(replay_batch[:,1])] = tgts\n",
    "for y in range(len(batch_targets)):\n",
    "    batch_targets[y][replay_batch[y,1]] = tgts[y]\n",
    "print(batch_targets[1],replay_batch[1,1])\n",
    "# x = [1,2,3]\n",
    "# batch_targets[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.model.fit(np.array(st), batch_targets,epochs=1, verbose = 0, workers=8, use_multiprocessing=True)\n",
    "batch_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# average steps\n",
    "results = []\n",
    "for i in range(50):\n",
    "    episode_length = dqn.playPolicy()\n",
    "    print(\"Test steps = \", episode_length)\n",
    "    results.append(episode_length)\n",
    "print(\"Mean steps = \", sum(results) / len(results))\t\n",
    "dqn.env.close()\n",
    "print(\"\\nFinished.\")\n",
    "print(\"\\nCiao, and hasta la vista...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100\n",
    "n = len(dqn.episodic_rewards)//m\n",
    "ep_rwd = np.reshape(dqn.episodic_rewards[:n*m],(n,m))\n",
    "avg_eprwd = np.mean(ep_rwd,axis=1)\n",
    "x_plot = [(i+1)*m for i in range(n)]\n",
    "plt.plot(x_plot, avg_eprwd)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Average Reward for every '+str(m)+' Episodes')\n",
    "plt.title('DQN, Cart-pole')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/subbu/.local/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: dqn_weights_final_copy/assets\n"
     ]
    }
   ],
   "source": [
    "dqn.save_model('dqn_weights_final_copy')\n",
    "np.save('dqn_ep_rwd_final_copy.npy',dqn.episodic_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps:200\n",
      "Steps:200\n",
      "Steps:200\n",
      "Steps:200\n",
      "Steps:200\n",
      "Steps:200\n",
      "Steps:200\n",
      "Steps:200\n",
      "Steps:200\n",
      "Steps:200\n"
     ]
    }
   ],
   "source": [
    "# to visualize it No need to train again\n",
    "\n",
    "dqn_vis = DQN('CartPole-v0')\n",
    "dqn_vis.load_model('dqn_weights_final_copy') # loading trained model from memory\n",
    "for i in range(10):\n",
    "    done = False\n",
    "    steps = 0\n",
    "    state = dqn_vis.env.reset()\n",
    "\n",
    "    while not done and steps < 200: \n",
    "        dqn_vis.env.render()\n",
    "        action = np.argmax(dqn_vis.model.predict(np.array([state]))[0])\n",
    "        state, _, done, _ = dqn_vis.env.step(action)\n",
    "        steps += 1\n",
    "        \n",
    "    print('Steps:'+str(steps))\n",
    "\n",
    "dqn_vis.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nOydeZhcZZW431NLr+lOp9OdEEJCAAFBhABBwAUHN1AHUEd0HHedYRx11J8bLuOMOuq4zDCMGxo3UJHFBUFEZJFFlC0QlrAmgexb70t113bv+f1x763crlRV367u6nSnz/s89dyq7y7fqe0795zzfeeIqmIYhmEYALH9LYBhGIYxczClYBiGYRQwpWAYhmEUMKVgGIZhFDClYBiGYRQwpWAYhmEUMKVgGHMAEdkkIq/Y33IYMx9TCsaswB/URkVkSET6ReSvIvI+EYkVHfdCEfmTf9yAiFwnIs8N7f8bEVER+W7ReXeJyLsmIM9ZInKn30+XiNwhIudO8v3ZoG3sd0wpGLOJc1S1BTgU+CpwIfCjYKeInA7cBFwLHAwcBjwC/EVEVoSukwLeXtQWGRF5I/BL4KfAIcBi4N+Bc6q4VqIaGQyjVphSMGYdqjqgqtcBbwbeKSLH+bu+DvxUVf9PVYdUtVdV/w24D/iP0CX6gUuL2iIhIgJcBPynqv7Ql8VV1TtU9Z/8Y47wrZUeEekWkctFpC10jU0icqGIPAKkROQKYDnwOxEZFpFPlun7dhH5LxG5T0QGReRaEWkP7T9XRB7zLanbReSYMteJicinRGSjL+PV4esYcxtTCsasRVXvA7YBLxGRJuCFeHfwxVwNvKqo7cvA34nI0RPs9mhgGfCrCscI8F941sox/vGfLzrmLcBrgTZVfQuwBc8SmqeqX69w7XcA7wGWAHngmwAichRwBfARoBO4AU/J1JW4xr8CrwNe6svYB3ynQp/GHMKUgjHb2QG0+48YsLPEMTvxBsoCqroL+B7wxQn2tzB0zZKo6gZVvVlVM6rahWdZvLTosG+q6lZVHZ1g/z9T1XWqmgI+B7xJROJ4VtPv/X5zwH8DjXiKspj3AZ9V1W2qmsFTWG80V5YBphSM2c9SoBfvbtfFu4MuZgnQXaL9a8BZInLCBPrrCV2zJCKyWESuFJHtIjII/BzoKDpsa6VOROR7vitpWEQ+U+a8zUDSv/bB/msAVNX1j11a4vKHAtf4bqZ+4AnAwYuNGHMcUwrGrEVETsEb9O7y75zvBs4vceibgNuLG1W1B7gY+M8JdPsU3mD7dxWO+QqgwPNVtRV4G55LaUz3lV6r6vt8V9I8Vf1KaNey0PPlQA5P4e3AG+yBQuxjGbC9hHxbgVeralvo0aCqpY415himFIxZh4i0isjfAlcCP1fVR/1dn8ILPH9IRFpEZIGIfAl4Cd5AXYqL8FwshaCsiKzwp62uKD5YvVzzHwU+JyLv9mWJiciLRWS1f1gLMAwMiMhS4BMR3tZu4PAIx71NRI71YyhfBH6lqg5e3OS1IvJyEUkCHwMywF9LXON7wJdF5FD//XaKyHkR+jbmAKYUjNnE70RkCO9O97N4A/q7g52qehdwFvAGPJ9/L/BO4OWquq7UBVV1EG/WUnj2zTI8V0zJO2dV/RWeD/89eHfou4Ev4U2FBfgCcBIwAPwe+E2E9/ZfwL/5Lp2PVzjuZ3gzp3YBDcCHfJmewrNIvoVnOZyDF7jOlrjG/wHXATf5n+c9wKkRZDTmAGJFdowDFRE5HrgN+AdV/eMEzvs3oEtVv18z4apARG7Hs4x+uL9lMQ5cbLaBccCiqo+IyOuAU0XkVlXNRzzvSzUWzTBmLKYUjAMaVf0z8Of9LYdhzBbMfWQYhmEUsECzYRiGUWBWu486Ojp0xYoV+1sMwzCMWcUDDzzQraqdpfbNaqWwYsUK1qxZs7/FMAzDmFWIyOZy+8x9ZBiGYRQwpWAYhmEUMKVgGIZhFDClYBiGYRQwpWAYhmEUqJlSEJFlInKbiDzulwj8sN/eLiI3i8h6f7vAbxcR+aaIbBCRR0TkpFrJZhiGYZSmlpZCHviYqh4LnAZ8QESOxUtvfKuqHgnc6r8GeDVwpP+4ALikhrIZhmEYJajZOgVV3YlfslBVh0TkCbyCKOcBf+Mfdhle8ZML/faf+vnq7xGRNhFZ4l/HMAxjznD55fC731U+5uyz4V3vmvq+p2Xxml+s5ETgXmBxaKDfxd4SgEsZW2pwm982RimIyAV4lgTLly+vmcyGYRw43NbXx5kLFkQ69t+eeYZTW1trLFF5bru6nv/9QMu4x3UuUt71ruKCfpNnXKUgIs3AqKq6InIU8FzgD35x8HERkXnAr4GPqOqgVyXQQ1VVRCaUkU9VVwOrAVatWmXZ/AzDGJdBx4l87I5slnM6iktq1x7XhR/9CC75mPf6iCPgSxWSuB911NQrBIhmKdwJvMQPCN8E3I9Xdeqt453olwX8NXC5qgbVp3YHbiERWQLs8du3M7b+7CGUqXxlGIYxEdwJZIN29kPm6L4+zx10333e6/e8B374Q5DajPsViRJoFlUdwStx+F1VPR943rgneSbBj4AnVPWi0K7r8Eok4m+vDbW/w5+FdBowYPEEwzCmAjficaoa+dip5MILPYWwcCF8+9v7TyFANEtBROR0PMvgvX5bPMJ5LwLeDjwqIg/5bZ8BvgpcLSLvxauD+yZ/3w3Aa4ANwAih2ruGYRiTIaqloHiKYTrJZuHqq73nf/oTHH/8tHa/D1GUwkeATwPXqOpjInI4Xt3bivhF1MvpupeXOF6BD0SQxzAMY0JEHeZd1cjHThV33AEDA3DccftfIUAE95Gq3qGq5wLf8l8/o6ofqrlkhmEYk+Cm3t7C8yiWwo09PbhEdzVNFddd523PO2+aOy7DuEpBRE4XkceBJ/3XJ4jId2sumWEYxiQYdfcO71EG+v58ftrdR6p7lcK5505btxWJEmi+GDgL6AFQ1YeBM2oplGEYxmQJWwdRhvm06067++jJJ2HLFli0CFatmsaOKxApzYWqbi1qij7p1zAMYz8QHtzHcx+pKhlfIUynUrjpJm/7yldCbIakJ40SaN4qIi8E1F938GHgidqKZRiGMTnGKIVxjr2+p4dRx5l2S+EPf/C2r3zlNHY6DlF00/vwZgUtxVtMthKbJWQYxgwnbB2MZykMOw5p10UjHDtVdHfDLbd4FsJrXjMtXUZiXEtBVbuJsHrZMAxjJqFlnpci7bpeTCHCsVPFF78IjgMvfSl0dk5TpxEoqxRE5FtU+HxsWqphGDOZicQUcqoMOw46je6j66/3th//+DR1GJFK7qM1wANAA3ASsN5/rATqai+aYRhG9YSnlo4XU8irMuQ4nqUwDe6jrVvh2WehpQVe/eqadzchyloKqnoZgIj8C/BiVc37r78H/Hl6xDMMw6iOsCIYz1JwAqUwTZbCLbd42zPPhHiUpEHTSJRA8wIgnFx8nt9mGIYxY5nI7CNHlVE/0DydSuEVr5iGziZIlCmpXwXWishteLmMzgA+X0uhDMMwJotOYPGaA2SnKdCsOsuVgqr+RET+AJyK93ldqKq7ai6ZYRjGJAhbB+PFCZxg4ZpqzaekrlsHe/bAwQfDc59b066qImo5zhcAL/GfKzBO9VDDMIz9izuBQLMACZFpsRTCVsL+qplQiSgJ8b6Kt4r5cf/xIRH5Sq0FMwzDmAyVpqSqKrlQwry6WIykyLQsXguUwsv3KSAwM4hiKbwGWKmqLoCIXAasxSuYYxiGMSOpFGjek8vx7Ogop82fD0BSxLMUaqwQcjmvfgLMXKUQNQVTW+j5/CgniMiPRWSPiKwLtV0lIg/5j01BRTYRWSEio6F934v+FgzDMPZlPEsh3FJQCtTWfbR2LaRScNRRsHRpDTuaBFEshf9i39lHn4pw3qXAt4GfBg2q+ubguYj8DzAQOn6jqq6McF3DMIxxqRRTKJ56WnAf1bhG81/+4m1f9KIadjJJosw+ukJEbgdO8ZsizT5S1TtFZEWpfSIieLWZXxZZUsMwjAkwXu6jspZCDV1If/2rt53JSiFKoPlFwKCqXoe3iO2TInLoJPt9CbBbVdeH2g4TkbUicoeIvKTciSJygYisEZE1XV1dkxTDMIwDlYruI8YO/nW+Uhj2U13URB7daym88IU16mQKiBJTuAQYEZETgI8CGwm5hKrkLcAVodc7geWqeqLfxy9EpLXUiaq6WlVXqeqqzpmUWtAwjBnFRNxH9bEYZ7e3c0NPT83keegh2LkTOjrg6KNr1s2kiaIU8uqp1POA76jqd4CWajsUkQTwBuCqoE1VM6oalPt8AE/xHFVtH4ZhGOPlPgq3CBAXIeWnuqgFQS3m88+fOVXWShFFtCER+TTwNuD3IhIDkpPo8xXAk6q6LWgQkU4RifvPDweOBJ6ZRB+GYcxxKqW5KJciO+XUptKwKlx5pff8zDNr0sWUEUUpvBnIAO/1A8yHAN8Y7yQRuQK4GzhaRLaJyHv9XX/PWNcReDOaHvGnqP4KeJ+q9kZ8D4ZhGPswkZhC8CzlONRikfFVV8GTT3oZUV82w6fXRJl9tAu4KPR6CxFiCqr6ljLt7yrR9mvg1+Nd0zAMIyoTmX0UvK6VUrj8cm/7ilfAwoU16GAKKWspiMhd/nZIRAaLt9MnomEYxsSZSKAZvLjCsOMQm+KERH19e1Nb/OQnU3rpmlCpyM6L/W3VQWXDMIz9xbjuo6LjG2IxunM55k1x1ZvVqyGd9tJaLFkypZeuCZGypIrIScCL8T7Hu1R1bU2lMgzDmCSVch+VSpHdHI/TlcvRkoiaPDoaN9/sbS+4YEovWzOiLF77d+AyYCHQAVwqIv9Wa8EMwzAmwxj3UYUpqa4qffk8zfE4Q1McU0in9y5Ym+mzjgKiqMS3AieoahoKqbQfAr5US8EMwzAmQ0VLIbQ/7brc1t/PC1tbiYtEzhIahb/+1VMMJ5wAs2WtbZT3vwNoCL2uB7bXRhzDMIypYczsowpTUoM9zfE4SZEpDTTfequ3nalpsksRxVIYAB4TkZvxPr9XAveJyDcBVPVDNZTPMAyjKsarvBbsVVXaE4mCUphK99FML6hTiihK4Rr/EXB7bUQxDMOYOiqtUwi7j1zg3I4OmuNx2hKJKVMKt98O990HiQScccYUXXQaKKsURKRVVQdV9bIS+5b7i9gMwzBmJJVyH4XTXCh7cx+d3d7Oo6nUlPT/85972+OOg3nzpuSS00KlmMLtwRMRubVo329rIo1hGMYUoeO5j/z9rmrBOpjKQPNdd3nb739/ii44TVR6/2Erqr3CPsMwjBlH1MVrCoXgctyvqzBZ9uyBp56CxkY48cRJX25aqaQUxnPJGYZhzFjC1kGlmELgPgJvQIxPgVL4re9LOeMMSE4mp/R+oFKgeZGIfBTv8wqe47+eJTNuDcOYq2iFxWtjAs2qhbvjqbIU/vQnb/v610/6UtNOJaXwA/YW0wk/B/hhzSQyDMOYAiotXoOx6xQk5D5KToFSuPtubzuTazGXo1JCvC9MpyCGYRhTSaVay6pa2D8m0AyTthR27YItW6ClBY45ZlKX2i/M4KJwhmEY1VO8innMPooCzf7zqXAf3Xeft121yiuqM9uomVIQkR+LyB4RWRdq+7yIbBeRh/zHa0L7Pi0iG0TkKRE5q1ZyGYYxNwivWC410JVzH0020BwohRe8YFKX2W/U0lK4FDi7RPv/qupK/3EDgIgci1em83n+Od8NajYbhmFUQ+AeCg/6hNrCgebwOoXJWgr33uttZ6tSqJjmwr9jfx2w1G/aDlyrqjeOd2FVvVNEVkSU4zzgSlXNAM+KyAbgBXg1ng3DMCZMccK7Mfso4z6CSQWaVWHNGu/5AacURORi4Ci8eszb/OZDgA+JyKtV9cNV9vlBEXkHsAb4mKr24Smde0LHbGOvIiqW6wLgAoDly5dXKYJhGAc6YfdRqWE+nPtIpmjx2saN0N8PBx0ES0uOYDOfSu6j16jqa1T1SlW9y39cCbwWeE2F8ypxCXAEsBLYCfzPRC+gqqtVdZWqruqcLQnKDcOYVopzG5XcH1gSU7hO4YEHvO2qVTDFpZ6njUpKIS0ip5RoPwVIV9OZqu5WVUdVXby1D4GBtR1YFjr0EKxmg2EYVVJuxfJ4+xOTDDQHrqOTT676EvudSjGFdwGXiEgLe91Hy/DqK7yrms5EZImq7vRfvh4IZiZdB/xCRC4CDgaOBO6rpg/DMAwYG1MoVTinlPsoMckiOw8+6G0PSKWgqg8Cp4rIQYQCzaq6K8qFReQK4G+ADhHZBvwH8DcishLv+9gE/LPf12MicjXwOJAHPqCqTlXvyDCMOU9x1bWKlkLIfZQUodppj6p7lcJJJ1V5kRnAeLOP5gMvJaQUROSPqto/3oVV9S0lmn9U4fgvA18e77qGYRjjEY4pPDU6WlophNcp+O3L6utZPzpaVZ+bNnlB5sWL4eCDq7rEjKBsTMGfIfQg3t1+k/84E3jA32cYhjFjCZTCEyWK5oxJc8Fe99Gq1taqYwphK2G2BpmhsqXwWeDkYqtARBYA9+JNVTUMw5hxhN1DDqULwITdR2FFUO2K3gPBdQTjF9kpNZvLxYrsGIYxS8irll7RHFReY+yAVm2g+UBRCpUshS8DD4rITcBWv2058ErgP2stmGEYRrWEB31nvEAzY9NgVBNoVt27RmG2K4WyloKqXgasAu4AMv7jdmCVql46HcIZhmFUwxj30TgrmosT5lUTU9i+Hbq6YMECOPTQCZ8+o6g4+8hPQXHlNMliGIYx5YxnKUyF++hACTJDlTEVEXl0qgUxDMOYKsJTUkvGFMJpLhirCKoZFA+UeAJUToj3hnK7gINqI45hGMbkCc+QKbcKtlTqbJi8pTDbqeQ+ugq4nNIzkBpqI45hGMbUko8SaA7tqybQHCiFE0+s4uQZRiWl8Ajw36q6rniHiLyidiIZhmFMjvBAXy6mIKHnYetgooHmPXu8QPO8eXDkkdXJO5Oo5D77CDBYZt/rayCLYRjGlBFWCsUuobBSmKz7aO1ab7tyJcQOgKr3lRLi/bnCvjW1EccwDGPyhNcelJuSGuwvdh9NdFwPlMKB4DqC2tZoNgzD2C8EM4ugdJqL8P59Zh9VaSmYUjAMw5jBhN1HxVRyH0000HwgzTyCCEpBRKpNL24YhrFfCA/6+RJKAcYGmscohQlYCoODsGED1NXBscdWIegMJIqlsF5EviEiE3rLIvJjEdkjIutCbd8QkSdF5BERuUZE2vz2FSIyKiIP+Y/vTfB9GIZhFBizTqHM7KMAtygQPRH30cMPe9vjjoNkcsJizkiiKIUTgKeBH4rIPSJygYi0RjjvUuDsorabgeNU9Xj/mp8O7duoqiv9x/siXN8wDGNcxpt9VGwpHNvUFPnaQTzhQHEdQQSloKpDqvoDVX0hcCFeWc2dInKZiDynwnl3Ar1FbTepat5/eQ9wSPWiG4ZhlCYcPC5XTyE8+yisNI6cgFI4kBatBUSKKYjIuSJyDXAx8D/A4cDvgBsm0fd7gD+EXh8mImtF5A4ReUkFeS4QkTUisqarq2sS3RuGMRcouaI5FGcoDjRPhCBd9sknV3mBGUjFLKk+64HbgG+o6l9D7b8SkTOq6VREPgvk8dJoAOwElqtqj4icDPxWRJ6nqvssnlPV1cBqgFWrVpWOIBmGMacZMyW1TJGdcu6jqKRS8PjjkEjA8cdXK+nMo6JS8GceXaqqXyy1X1U/NNEOReRdwN8CL1f/m1PVoF4DqvqAiGwEjgJskZxhGBOmeMppxf1UlwTv4YfBdeH5z4fGxioFnYFUdB+pqoM3gE8JInI28EngXFUdCbV3BlNfReRw4Ejgmanq1zCMuUd4SmqlIV+rdB+t8W9ZDyTXEURzH/1FRL6NlzU1FTSq6oOVThKRK4C/ATpEZBtegPrTQD1ws2/O3ePPNDoD+KKI5PAU9/tUtbfkhQ3DMMaheJ3CeAnxqlEKQTxh1aoqTp7BRFEKK/1t2IWkwMsqnaSqbynR/KMyx/4a+HUEWQzDMMaluJ5CqUBzEGeo1n00Zy0FVT1zOgQxDMOYSsYkxKsw6FfjPhoehiefPPCCzBBtSupiEfmRiPzBf32siLy39qIZhmFUR3igj1RPYYLXf+ghL8h83HHQcICVHIvyWVwK/BE42H/9NF6tBcMwjBnPeDEFFypaEqW47z5ve6DFEyCaUuhQ1avxPjv8Fcnlyp4ahmHsd4pzH5WiYClU4T665x5ve/rpE5Vs5hNFKaREZCH+5ywipwEDNZXKMAxjEowpx4kXSL69r2/M/gCXic8+CpTCaadVLeKMJcrso48B1wFHiMhfgE7gjTWVyjAMY5IUxxT68/nCvvDsI2Fi7qNdu2DrVmhpgec+d+rknSlEmX30gIi8FDga7/N7SlVzNZfMMAyjSkqlzi72eUuJY6Nw//3e9uSTD4yazMVEmX30CN4q5LSqrjOFYBjGTCdsCQQxBbeoBGe1BOsTTjllEheZwUTRc+fgJa+7WkTuF5GPi8jyGstlGIYxKcIxBWFswLnaVcyw11I4EGceQbR6CptV9euqejLwD8DxwLM1l8wwDKNKxqxD8K0Gt8z+CV1XD3xLIUqgGRE5FHiz/3Dw3EmGYRgzGlUtKIBS2VInytat0NUF7e2wYsWkLzcjGVcpiMi9QBL4JXC+qlr2UsMwZjQFReC/Dj+HsTGHiRBYCatWQRWnzwqiWArvUNWnai6JYRjGFBHYBEGxnUoxhet7eji3oyPSdcNK4UAlSqC533IfGYYxmwiUQaAGimMKYbpz0SdUHojlN4ux3EeGYRxw3NDbi4jsVQqUtxTKpcEoJhxknuuWguU+MgxjVpF2XYS9g39xoLk4IV4UNm2C3l7o7IRly6ZQ2BlGTXMficiPRWSPiKwLtbWLyM0ist7fLvDbRUS+KSIbROQRETmpivdjGIZRyIwaBJRLrmgOpbmIQth1dKAGmSGaUvgoY3Mf/RT414jXvxQ4u6jtU8CtqnokcKv/GuDVeLWZjwQuAC6J2IdhGMYY8qGYQmGdQthSCD1vjccjXXMuuI4gWu6jB6vNfaSqd4rIiqLm8/BqNwNcBtwOXOi3/1S9b+seEWkTkSWqujNKX4ZhGAFBviPFcw/F8dIyBITdR69euDDSNU0phPDjCI9NUZ+LQwP9LmCx/3wpsDV03Da/bYxSEJEL8CwJli+3bBuGYexLXpWYH2h2VUmIMOLujR6ElUIUS0F1bsw8golXoZtSfKtgQssMVXW1qq5S1VWdnZ01kswwjNlMOKbgAPEi99FEeeYZ6O+HxYth6dIpE3NGUlEp+MHfqY6z7xaRJf71lwB7/PbtQLivQ/w2wzCMCRGOKbiqnlII7Q9cS1GZCyuZAyoqBf9O/oYp7vM64J3+83cC14ba3+ErotOAAYsnGIZRDWOUAvtaCoH7KO9Gm5A6V1xHEM199KCIVJUPUESuAO4GjhaRbf5K6K8CrxSR9cAr/NfgKZ9ngA3AD4D3V9OnYRhGPhxoViVO6cVV1/f0RLreXFIKUQLNpwJvFZHNQAoCV50eP96JqvqWMrteXuJYBT4QQR7DMIyKFCwF1YKlEF65HHiAMqo0jeMPUoWHHvKenzQHVk9FUQpn1VwKwzCMKSSYkuoSiimUcB9lXZemcWpqbtvmrWRubz/wg8wQscgO0IZXge0coM1vMwzDmJHk/QVriqcgEiIl3UeZCDGFwEpYufLADzJDtBrNHwYuBxb5j5+LSNQVzYZhGNNOUIIznObCLeM+Go+wUpgLRHEfvRc4VVVTACLyNbzg8bdqKZhhGEY1qCo53wJQoM6/vS+2CQL30Xg8/LC3nStKIcrso+JcUoESNgzDmHEE01CD2UfJEpZCwETdR3OBKJbCT4B7ReQa//XrgB/VTiTDMIzqcVULCkCBpB9ILlU3YTz30eAgbNwIdXXw3OdOuagzkrJKQUQOU9VnVfUiEbkdeLG/692qunZapDMMw5ggytiYQjn3kTK+++iRR7zt854HyeQUCzpDqWQp/Ao4WURuVdWXAw9Ok0yGYRhVE0xDhb3uo2AWUoDi+c7Hcx/NtXgCVFYKMRH5DHCUiHy0eKeqXlQ7sQzDMKojWLAWTEmt891HpYb/8dxHcy2eAJUDzX+PZ4UlgJYSD8MwjBlHYCmEA81AyRXN47mP5qJSKGspqOpTwNdE5BFV/cM0ymQYhlE1rm8pAPTn89TFYiVrNIOnKGJlVqTl8/Doo97z48dN6nPgEGVFsykEwzBmDUH8QIBb+/oKlkIpmyDvJ8srxVNPQSYDK1ZAW1ttZJ2J7NciO4ZhGFNN2H2UcpxCoDlsDwTPHSBRxlKYi0FmMKVgGMYBhobcRIFS2OcYf5v3k+WVYi7GE6DyOoU3VDpRVX8z9eIYhmFMjsBNJCKkXLcw+6gU/fk8HWUWIJhS2Jdz/O0i4IXAn/zXZwJ/BUwpGIYx41A8hQCepdAa3zdqELYNltXX73uNUA2FE06ogZAzmEqzj94NICI3AccGpTH9usqXVtuhiBwNXBVqOhz4d7z03P8EdPntn1HVqS4FahjGAU4QTwAYdV06kslCTKErm6Wzrq5w7MF1dcxP7DsM7toFXV0wfz4ceui0iD1jiBJTWFZUK3k3sLzaDlX1KVVdqaorgZOBESDIq/S/wT5TCIZhVIOLN7Dl/WypSb/Ajohw58AAe7LZQkzh9R0dBasizFyroRAmSkK8W0Xkj8AV/us3A7dMUf8vBzaq6uZSX4xhGMZECWooZF2XvCp1sVhBUaRdl990ddEcj7MgkaDceua5Gk+AaOsUPgh8DzjBf6xW1akqsvP37FU2AB8UkUdE5McisqDUCSJygYisEZE1XV1dpQ4xDGMOEwSac6oo0OYP/gKMOg639PXx1MgIMZGSaxdg7sYTYBylICJxEXlSVa9R1f/nP66pdE5URKQOOBf4pd90CXAEsBLYCfxPqfNUdbWqrlLVVZ2dnVMhimEYBxBBsrucKkkRXrFgQcF6SLsuT4yMkHZdYpSusQBmKZRFVR3gKRGpOoZQgVcDD6rqbr+v3arqqKoL/AB4QQ36NAzjACcINLDlFHAAACAASURBVGddl6Sf4iJQFKOuy0ktLaRdl7hIyRoLqRSsXw+JBBx77DQLPwOIElNYADwmIvcBqaBRVc+dZN9vIeQ6EpEloYD264F1k7y+YRhzkGCYr4vFSPhV1wSI+ZbC+Z2dXN/TQ0xkTEnJgEcf9aakHnsslJitesATRSl8bqo7FZFm4JXAP4eavy4iK/G+001F+wzDMCIRzDSaH4+z21cKMX+bdt2C5RCndDW2uew6gghKQVXvmOpOVTUFLCxqe/tU92MYxtwjqM/clkh4loIIMb9t1HULlkTMn6pazFwOMkOE2UcicpqI3C8iwyKSFRFHRAanQzjDMIyJEsQPltTX0+THFAJLIa9Kzo85lMt5NFcT4QVEWbz2bTz//3qgEfhH4Du1FMowDKNaAvfRynnzWJBMekoBL/VF3Lca8NuKayk4zt66zGYpVEBVNwBxf3bQT4CzayuWYRhGdQQOIcFbyBbzXUhD+Twpx6EuFvNiCiEFEfD00zAyAoccAgsXMieJEmge8dcUPCQiX8dbQ2Aptw3DmJG4qoUYQrBoLQbszuVQf+1C0FZsKdx7r7d9wRyeEB9lcH+7f9wH8aakLgP+rpZCGYZhlCPnumzPZMruDwLNEFIKIoU6C3W+IoiVsBTuucfbnnbaVEo8u4hiKTwH2KOqg8AXaiyPYRhGRUZcl6dGRlhaZhHBGPcRey0FF89lNMZ9VMZSmMtKIYql8A7gYRG5R0S+ISLnlMtLZBiGUWtc1ZLrC8L7xY8juH5MIRYqyVkXdh+FzkulvCBzPA4nn1zb9zCTibJO4Z0AInIw8Ea8mUcHRznXMAxjqnHxppaWI1yPeSCfZ0EigeApi6Z4nPZkkhj7Wgpr1oDrwkknQVNTDd/ADGfcgV1E3ga8BHg+0I03RfXPNZbLMAyjJK5qRaUQDjS3JBI0xuMF91F7MsnhjY00xGL7WAoWT/CIcrd/MbARL332baq6qaYSGYZhVMAZx30ULse5xK+yFqxezvnnNcRi+1gKphQ8otRT6ADeAzQAXxaR+0TkZzWXzDAMowTjuY+eHBkBPEvhxHnzAG+gU7yZS4BnPYRmH6maUgiIkuaiFa/85qHACmA+lK1NYRiGUVPGcx89kkoVMqOePn8+QCHoHFgQDbEYcfauU9i61avL3N4Oz3lOjd/ADCeK++iu0OPbqrqttiIZhmGUZzxLISigEyaIKSRCSiFsKQRWwqmnzr2azMVEmX10PICINKnqSO1FMgzDGMsTqRTHNDcD/pTUCsdmfBdRuO57MCW1KeapgcYg0OwfY66jvURxH50uIo8DT/qvTxCR79ZcMsMwDJ8gTgDjWwoZ1/XWKYTaYnj1E5rjcSAUaPb3m1LYS5TFaxcDZwE9AKr6MHDGZDsWkU0i8qiIPCQia/y2dhG5WUTW+1tbJGcYRmHWEIwfU0i7Lo5qwVUEFBawhZVC0JbJwIMPesfN5ZxHAVGzpG4taqpkvU2EM1V1paqu8l9/CrhVVY8EbvVfG4Yxx8mrsm54GPAshUpTUtOuS3siQWtir3c8qJ8QuI+Oamz0As149RMyGTjmGGhrq917mC1EUQpbReSFgIpIUkQ+DjxRI3nOAy7zn18GvK5G/RiGMYvIq/L06CgwvqWQcV1eXZT3OoaX3qLBVworW1poisc5qK7O8h0VEUUpvA/4ALAU2A6sBN4/BX0rcJOIPCAiF/hti1V1p/98F7C4+CQRuUBE1ojImq6urikQwzCMmU4+pAhcKFlGE+ChoSGyqrygpWVMe0yEZEgpADTF4zynqcniCUVEmX3UDbw1eO37+d8PfHmSfb9YVbeLyCLgZhF5sqhfFZF9vnlVXQ2sBli1alX52wXDMA4YcqHVyEGSu1I8PjJC2nVJFu2PAclYbIxSCDClMJayloKILBOR1SJyvYi8V0SaReS/gaeARZPtWFW3+9s9wDXAC4DdIrLE738JsGey/RiGMfvJqxZWI7uUHrhUlZTjeEqhaPAPLIVjijLd7dkDzzwDzc3wvOfVSPhZRiX30U+BHcC3gOOANXgupONV9cOT6dRXMC3Bc+BVwDrgOuCd/mHvBK6dTD+GYRwY5CNYCoE1kXFd4kX7O5JJOpNJjvPTXgSEK635E5PmPJXcR+2q+nn/+R9F5Hzgrao6FSkuFgPX+ItLEsAvVPVGEbkfuFpE3gtsBt40BX0ZhjHLKY4plLqbzbouuTJB6EV1dRzkJ8cLc8cd3vbUU6dQ2FlOxZiCHz8IVG4PMF/8kVxVe6vtVFWfAU4o0d4DvLza6xqGcWASthTuGRwcswYhIOu7mMpNVy0+Z3QULr3Ue37OOVMq7qymklKYDzwAYxYG+ks8UODwWgllGIYRJue6hUH9/qEhXtTaus8xgaVQLghdrBR+8Qvo6YFVq+D006de5tlKWaWgqiumUQ7DMIyy5FRJ+hbAtkxmn5gBQMZ3HZULlIaVgipcfLH3/MMftiR4YSKtaDYMw9if5EOuoT3ZbElrILAUSikMGKsUrrwS1q2DxYvh/PNrJvasxJSCsd94IpViKJ/f32IYs4AgpjCQz9Psl9csJutbCnUl1iIAhbULrgtf+ILX9vnPQ319bWSerZhSOAC5d3Bwf4sQie5cjlHX6jVNN+uGhxmcZco4mH2U9y2BnCprh4bGHBNMRW0uoxQCS+Guu+Cpp2DZMvjHf6y56LOOSEpBRF4sIu/2n3eKyGG1FcuYDNsymarOG3UcHir6o9WS8WrtGrWhO5ejb5YphWANQhAzyKmyO5sdc0zWD0Y3l1lwECiFu+/2Xp97LiSilBmbY0Spp/AfwIXAp/2mJPDzWgo107l7YGB/i1CRTJV33xnXpSuXm2JpyuNQOdulURscYNiZqkTH00NelawfUxC81ct3Ff0Ps6pjaiYUkxChrw++9S3v9YteVFuZZytRLIXXA+cCKQBV3QG0VDzjAGd7lXfi00W1SmG6B2lnnApaRm1wVGddLMf1LQXHr7PsApuL/odRLIUvfAG2b/emoFqAuTRRlEJWVRVvbUKQlmJOk5nhd7fZKuWb7kHaNffRfsFRZWgWWQo7Mxk2pdNkXBcHb+GUq8pI0XvI+IV1msrEFObvauE73/Gmn15yibmOyhFFKVwtIt8H2kTkn4BbgB/UVqyZTbV34tNF1ZbCOHnqpxqH8imQjdrhAiMz/DccZthxGHIc8oGlgHeHWvwegt9SKUvBceDrn2wgn4d3vxtO2CefghEQJXX2f4vIK4FB4Gjg31X15ppLNoOZ6UohOwmlYO6jAx/XH1hnKk+mUrQnkyzycxU5ql61Nf950ncfjToOrh9bOMMvmeZASUvhs5+FG2/0sqH+539O21uZlUQyoHwlMKcVQZj9oRTu7O8v/PDHo2r3EfshpnAAWwp/7u/nJVbfccIMOM6Yugd5VVSV7lyOtcPDNMRiuKqkXZe067IlnS4c66ruYyk8+ih87Wve8yuugIMPnpa3MWuJMvtoSEQGix5bReQaEZmT+Y+mI6awdmiIgVAwcGfR9LtKzBr30QGuFHZN4DubbmaypZAv+h06eO6ilOOwJ5ulMR4nr0rGjysEM6kEzzX2wvnzx1zv4x/3tm98oyW+i0KUmMLFwCfwaikcAnwc+AVwJfDj2ok2c4k66N7R3191H735/Jh+0hMY6CejFGo1SN/W17dvf1S2TG4vcc5sYiLf2USY7Z/LeIQzogavgxKcKdelIRbD8esmjLhuIWiueL+nQ0NLlPv64KabvKDyRRdN8xuZpURRCueq6vdVdUhVB/1ymGep6lXAghrLNyOJOugWL66ZCDnXHXO3NDqB2SIzcfZRqbtmd5z+dszgO+0oTJVSuHdwkFTo+5/JFshUsI+loIrrK4Zhx6ExFsPB+x+O+i6k8LHhvEhr13rbk0/2VjAb4xNFKYyIyJtEJOY/3gQETrwD1/avQFSlMJkUDtmiP8a0WAoQ2X106wTvVkt9FuNZJlGnTd43OLjf592X+jwmqhTKfaZ9udyYyQOpGT7RYbIUK4XAUnBUC0oh57pk/fKb4VxHLoxJiHetX7vR6i9HJ4pSeCvwdrx6ybv9528TkUbggxPt0K/9fJuIPC4ij4nIh/32z4vIdhF5yH+8ZqLXni6ixhTKDQo3945fnyhbbClMYCDITcZSiHjuRO9WSyoFKk9Jjbrqtj+f3+eznqjSmiylrMKJKucdZRZFZovcKcXz86slyu8w4JYIx5b6zLuyWR4eHp6QXMXuI8cPNAeWQoNvKagfU6j3lUCwfiEIMw8NwerV3vN3vhMjIuMqBVV9RlXPUdUOVe30n29Q1VFVvauKPvPAx1T1WOA04AMicqy/739VdaX/uKGKa08LUad8lnP5RMlNNBlLoVomspgsVWFgKjXYlBrIBCq6j6Iqhax/1xhmMq67aih+f27RwBaFwTLvt7jE5FStMdgyzu8w/D3uzGbRcd5Pqc98xHUjW3E39vQApS0FxftMs67ruY/8lc2jrkt9LMbNvb2M+mkwAvfRLbdAOu2V2jzxxEgiGESbfdQgIh8Qke+KyI+DR7UdqupOVX3Qfz4EPIEXxN6vPDI8zM4pTl9R7u6+P8KfpNhSmIhSqHZmiQNlq1YVU0kp7CmRP6nUZxED1gwNsafMAB5VKeT8XPthot5N31SkwIpfR6XYpVM8sEWRo9zgWRxfmoylEAz0CvSOk+cqPMinK5S5DCj1myj+HVdiUzrNjT09JS0F8Gszi9Dop85OiDDiK4WuXI6tmQwOnvsonYYLL/TO/7u/i9S94RPFffQz4CDgLOAOvBlIU5JKU0RWACcC9/pNHxSRR3zFUzKILSIXiMgaEVnT1dU1FWIA3gA01as8yw3kAxGUQq7orr14UP2Df1dV6MtxJu0ycUKmdyl+tWdP4XklpVBqMC+pFETozeXKXmvEcca9O4V93SsQ3e9ePNW3nIIaj+KBeqJKYVc2WzaGkit6f5VciYP5fMWEjYHCLg7QliL8PWZVyaoW7uaLubGnp+T/p9R3U47uXI5N6fQ+U6PzqjTGYgjeDU9jLEZChDoRRhyHOhFu7O0tuD9jwFe+AuvXwzHHeJXVjOhEUQrPUdXPASlVvQx4LXDqZDsWkXnAr4GPqOogcAlwBLAS2An8T6nzVHW1qq5S1VWdnZ2TFaNAzjdNo1DqJ17qzxL8ebek0zyWShXaByLc6RUPKsX+6eLBbMBx6PP/8NVG/x0tX7UK4O5QnYZKCrTUnWwpV1pChJTjlJ0tJYwfH7mxp6dQcWs8GUpRXFeg2iBusWIrpxRuKDOoDvmpHEqxj/uownsLz9svRbBv2HF4YGiobBwDxn4WWdcl67plY0k7stmSchVbOZXYlskw4DgkRPZZp9CSSJAQGaMUWuLxwn9s2HF4++LFuKoMD0phsdrq1eAvjDYiEkUpBDZmv4gcB8wHFk2mUxFJ4imEy1X1NwCqultVHVV18XIrvWAyfUyUYDZDFEoNm6VcJsGdWMpxxgwale6yA4r/GMWSFVsbA/n8pAvWOKpc291Nvug6wUA2FPE9pErc4ZeSLS5CynXLBmSTsdi4irorlyt5NxrV6iv240f5bkpR3F8wY6aY4kH19/5nO+w4Ze/ci91jlX6nGf+OvhypkFJw2Fcpljo2kCGjWvaGpj+fL/mZ/7a7O7Kl0OevzUmIjHm/ripNsRhJEc99FIsRF6ElkWDEz4k05DgcVF+PAzyyVshm4ZRT4MUvjtS1ESKKUljtu3L+DbgOeBz4WrUdiogAPwKeUNWLQu1LQoe9HlhXbR/VMBFLIa+6j/um1J8r7bpsGBnhoeHhwh8+ijsE9lUKxecO5PNjXg/m81WvTwhw8BbNbRgdHdO+O5sdY0WoakXXQ6ZEwLqUZHG8gaecUqjzK2yV4saensIURbdETCHq4F6sXCeqFK7v7i6c9/vQbyKvOqYmcHBccX+BkqgUjC1ndfzOv2aY4I6+HMH7G8rnqfOVcjmGi5RC1nXLuj778/mSn93WTCayUmiOx2mIxYgBD6dSfOaZZwo3KA2+UkiIUB+yFPL+bzGwUtKOyzcv8j73U06J1K1RREWlICIxYFBV+1T1TlU9XFUXqer3J9Hni/Cmtb6saPrp10XkURF5BDgT+H+T6GPC5FQjTyEccd19KleVM/1T/rHBtbOq1EUI5hYrhYSfBCx83fCfbcBxmFcmj3xUHFUWJZNsCuWSuba7mwFf/noRPvfss+zOZscMeMWUsrpKDQsxf/ZIWUuhglLoz+fJui7DjkNSZJ/+orqPir+3icaVdudyqCqjrjsmcOsUKYXd/r7iQTWYdFBpTUayzA1CqdQnmXEs3mCg78/naYzFxrX4AhL+ZzxRpdCdy5FXLanAwvypr4+8Kq3xOIr3Oe3MZtno/xbrYzHq/LjCGW1t1MdizIvHcfC+syB53qab5nHDDUJbG3ziExW7NMpQUSn4rpxPTmWHqnqXqoqqHh+efqqqb1fV5/vt56rqzqnsdzxyRWb31aGgasBQPs+tfX2MOA6jrsu1oR96uT91xr+7Cga+EccpWwQkTPFAUGxSqypXhGQc8Rf1/Lqra9w7s8dSKZ4aGdmn3VGlKR4fc37g5826LnX+3dqgPxCXw2XvtN1KlpHgWQPlBrG6WIycP0e9mLQ/+A05Dkn/uDBRbSZXlW9u21Z4PVFLIeU4hRuKsIssXxS0D+I9xTPP+kKB33IkipRj8NvoyeX42a5dhXb1XTxhS+G3XV1jrLZAKWRUaSihFLak09znx47CfdaJkPGVcCkyrlvSXdaVy5EUGXd1+p5slsMbGljsD+4pxyEekrchFitkP12YTFLvvw4s2NZtLZx5JtzyYW8i47/8C6xYUbFLowxRsqTeIiIfB67Cr74GoKrVzd2boQhj1x+sS6V4U9Exg47DkO+mGXEcdvkDlogU3EfBa/B85iOOw0A+X/iDjbguTb5SCB9bTFxkzJ+5WEk0xuOsLxrYBa8gSTBrp/jaQVtvLkdjifTCjuo+1saebJZBxyGjSn0sRn0s5t2dx2KF6wWDdtBfXeiu8p7BQc5qby87TbY+FtvHUgium/QV4TXd3byhaFJBYGEElkIupIRKfaaVPutN6TRD+TwticQYt1ilcwKyvusi7MIACgXmAwJlMFIkZ5RayaWUQs5XCiOuS18ux6jrZQsNVv4G9OXzDOTztCeTwN6B/uC6Op71Z/qE3++w47DLdxdqSM56P74TbgsTVsLBDCARocdXCt1FMbfwb0d8N1bgIgqS39XFYtwzOMhgPu8phXi8oBiSKgw/2cQtf23hid/PY9vjycK1zzsPPve5cT9WowxRYgpvBj4A3Ak84D/W1FKo6SJ8Bxr88dR/BL7e4JjgDzPqusTxfvg9uRy/8a2F4G73mpD1kBApFAgJXAkjjlP4Yf9s9252ZjL73Amr73oIK4F4aGDYkk7z6PAwWzKZMX/q4G+aEBljRQT8uquLzek0g45DynUL7xW8uMGf+vtpC5WjUlW6cjlGfL9/QyxGg68UEiJc6t+lPj06yrrQ7KrgDr87lxt3TUa8hGvkij17Cp/BlXv2sLXEDJlR33eeCpRC6PPX0IAWPH5R4vMIWFZfP6aP4DP5jX+tSmRUGfGnd6aLLIWw+6ivKAb0a386da7E91dMUqRguapqIQA/5Dgs9t19Q45TcFPWhxT+SJFbK+AQP2lc+N39uquLEcehO5fj/U8/TXcux+39/ajv8gwC+r/0ZS/+bAL5V+/YwVp/FXPw++wpkuF/fess+BzaEokx6bKDdBWPp1IFV1djLEaTJvj0p+HDxy/mqtcv5+ZvLGDb40nmtSjnngtvvnwb11wDjY1lPkxjXKKsaD6sxOOASJl9S19fwXwP5kA/kkrxxMhI4QceDAxX7tnDkJ9OIeEvoOnJ5dgc8r/D2PrNCf8OKPjjq3q5WgL30fxEgrsHB8e4oQK5unK5MQNGWEkM+nL05/P7mPOL6uqIi/BoaJAO2JrJ8K1t2wqD6cbRUe7057T3+AN4qy+bozrGFRXEFOp9RZcQ4d7BQVSVvlyuIEcwgGRcl55cjstC7o1igs+8mIeHh7m6q4u6WIyN6TS7SqymDdx9ytg76Z3ZLA8ND/P0yAhXd3Xx1MgIa4eHWZdK7Rv89l8vra8fs8r857t3A953+cuuroqKIeFbg44/WAfkVce42IJ5/kHbpnTau0sOXashFis5dTcpwrP+7+zPAwPsymYLNyGtiQQPDA1xa18f/fk8X968eUwuoKQIX92yZcz1BDi3o2OfYjSbMxlGXbcgY7CG5Me7dpH0LbqUrzQAflW0TiiG545bUldXmOra4t9kFLupnhgZQVULyjgpQkdy791+vW+Jpl2XQcch15XkqUsX8o3jD+WrX4Xh3hj1LS5HvTzFJ37az549Xp6jI0/PEXH9pVGGcd1HItIEfBRYrqoXiMiRwNGqen3Npasxffk8Q47DAv/HqHh3OW9ZtKiQR2VHJsPPd+9m4+goS+rqqPenw13T1cWyhga06E4/bGEkRQomN8APd+7k2Obmwp8xBvSH/iwF904+z7ZMhmdGRzl+3jwObWgY4z4achxcvD/3sOMwP5FA/dcNsRivbFvAbV2D9PRANqssXizEYjAvHuf+oSFOaW0loUpPPs+mdJqX4imF4byD051kd0+Mh/c43L9d6c/VEU8qa7tg3cPNzG8RHh1McOvD81g40sTrDh5icWuSRFx5ZKHyRGyAVH0Tn6nr4R/OaGQglyeVdhnYlOSZJNTXK83NQjyhPLMuztN3t3K9NNC/1GtvaoLHu5M0nZImvbmBhzZnSAr84JhB3n7SfBobxyoe/PcdWAa7s1nvvTgOz46O0pZI0OjPaOnJ5ehIJomJkHYcbvBX9zbGYmPu8h8aHuZt/rVyqvxo507eu2RJ4Tci7HWVNcVi3kDqW1FBnp68eukWwq6Wr2zeXLiL35bJkPatr6DgfFsiQW8+z8Gx2Bj3TEKkkJJiczrNqD/FOenPwPnz8DBJER7x3SxhZdSeSLDdV6riz/NXIN2TYOftrdyaraenWVm6VLi/T5i/XIkviJPqjtO/vpl7N8a58zGHph3z2DiQQZ2D2ZpvYM0C2NVZR+/h0NAAT26dT643wQ+OVTbF64kloeEgGLrpIK6KN/JUup2rT/eOTaVgW1crd3S57FyyN9bwtws7uHV3PzufjbNrSyPZTQ0MjSjdjzWw/tq9NRLa2+HiSxx2nLKdIc3zieXLaUzs/T6MyRElpvATPJfRC/3X24FfArNaKbiqfGv7dp7X3Dym/dFUilfn8zTG46Rdl93ZLFszGW92hevSHI+jqTg9zyTJDDeQGEnwyUV9bBlq5pZtypMDMTbFlZvd3aR2Jng2F2fXrkYekCRb3DwbG/P0b2pmOAlPZBrYOZAnUa+kO7zB6PktzTyeauTZ7fV0ZXOMLIZFCr9d08kT8+O01StPdzWwses5uG1ZLnqBcESH8tetjex8Ns6ebTEevyeJ6xzETwAQ4nGlvR2SbYsYdNr5oMZJaIzDn5cnNdzA5fXKwyNxBh87iiv6wj+JxYVnVwHQFOGT3Vtp7CqAeDvzHAEO52pfHgpbb9H6HcDqMddYHvpxeUti7gb+GU+pLDrMoWHBIq6sj9PXdhAb6+uRGFw/X3kgs4DHW+ro6lvOz506bmuso7lO6Hc7eCTn0r40xarOZkZc5Z6+BM9u6aS/rYFDjnZwD1I2rG8hm4rx7U7l/qEm6pqUxmVZlh03TON8lzt6B2gZreetSxfT1AT1Gqd3xMHpSuIk4vyhvoesq7QNN3Ltg2m2L9rJh56zhNxwjAdG0yxzm9neCD1dwqZGh8EnG/n407voHWnEzTTwUaeHY9obeNXBrSxblGD+fNjyRILupxu4x4G1zyZ55rGFfH+B8NC2hTw72MTax5ogG2M0JTS3KhdKgi+6kM3CkNvOvI75nFSX4bDWeh7sP5jfPNlE9/ax36/HIf73DODFcB4Zs9/7r2wA7vG/6z8U9h0EhfZWAL7iX3Ojf+6bLw5fawk3Ap3PP5iRM5RtTjP//NsEu3Z1+Pv3TWhw+Ak5nvuSDJf++zw6O+N8d3uckax3UxTQNMkZeAbIeD5TEVmjqqtEZK2qnui3Payq+7309apVq3TNmurCG7syGV60di2XH3MMp82fz6+2dDM6LHz60a38oxzGbXc7vLSzlVtTPaQzoP11HN5Uz5pb69j8eKQqpvuVeJ3S3Ayjo5BLR7enG5pd5rUpbsJF6x0aNcFQ2sVBOfpYhbzwBEO855RWYgty3LZhlJE0PK++GTJxbn1ilIO0gd07hJGde5eSNrTn6WyJ0z/iopkY6YzSOA8WHj/CUcvj7Ox3OELm0dPvsuZhZbQvTutCF3dZilgMmvua2L05zhRnIpkQIopq5c+yrkHJTuDz3l80NcEhKzMsXqL05nK0DzazoS9LTy8kBurIZmDeoVla58O8ZVk6VuRY3lSPNufpmB9j96DDo48r9dkkB1HPjmwWtznPc91WtvTnGOqN4Yoy0jbKiYcl2TCU5jmD7eTzsC47SCyVZMu9DeTzYz+rWFxpbFaOPBqkM0NTi9KVz/KmNwoXvrGZG3t7eeMi70bhJzt30p3L8Ynlywvnr96xgwus3ua4iMgDqrqq1L4oo1vWT5Ot/sWOAKY2c9x+YGsmwyktLWwbzvHnJ/Ocf1pwh7KQL/jP7gTCd1NrQ+e3LXRxl47SvlDJD8VJjwotLcrggJDtS5Dq8e5Y2hY70Jxn3kIXcYV0Bo4+TDh6cR2bh7P0xzM0ugkaiPHwUIoXtc7nvoEhzjuknbucbroHXQ5PNuF2pjmoQ2jUBB1twmhG2b1LGOwVEiNJjlhQB8tHkJjy/DOzHL5c6Mrl6MvleXpHnsOSjSRTSe4cGKA5GeP4RAvbNsTprU+zoC6OZuM86Qzxi39Ywp+H+/nejh1844gj2DA6T1xD6wAAFGBJREFUzO96esi4Lme3tzMvHufNjz/OR085hd6cQ2v3IPcNDfHegw/mezt2cFgmw7sPOoiBvMMhNLA1n+a4+nlsYoRzOjq4qbeXwxsbObOtjY9s2MDy+nqWNTSwdmiI/zvySN739Hre3drKAztGec2yNn7b18Xpra10JDP87cIOLn+mmwefyPPArjS79igN/Q2c1NTKvDaXxwZGacwnaHfraaoXrhnYw6eXL2dtX4qExtgwnKalv4n1I6PMjycYcVwOOUiQ3jp2b4uxPZ8h3ujQ0RbjmOYmNvRn6O8TetbX4QzHSQ0IsaSSmOfQKHFGRiCfgVgCJOnijMYKCkHiyryDc6TVJZFOkB+JIQmleZ7iOJDLCXFHaFnsUJ8U4kmldT5sHk3TnE/ipuIMDwi5wQSJRhcOStOaiDMvESfemWXBfGjoyNPRASNLhnGSDh89agm37h5kXr0wFM/zWHaYwZ4Y57R0cltPP2fN6+Da7b2ctKSBL72ljcu7exl0HAbzed66OMHPd+/mup4ePrR0Kf35PEvr67mpt5eTWlo4v7OTvnyePw8Mk3Icbtm+nSNf28R5CxeS0SEaYzHuGxzkcyuauG9wCAXuHxriuOZmLtu1mTMaGvj2kQtwgU9u3ENjLMZoT5yH7ovTtKmV1nicfzq7mcHn9ZBV5Y2LOrlqzxCvbW/n089u58LDDmNeIsHZ7e2F/+Cr29v5bVE8ztxHkyeKUvg8cCOwTEQux1t89q4ayjQtbB3O8uj7j+CqOxv22bdgiUPn8jyxQ9IMjrqcvqSZ5II8uSzk4i7HHhHj/e+J8avuXloTCXpyObZnMhzV1MSmdJptmQzL6+rJOsqdQ/2c2trKp5Yvpz2R4KMbN3JKSwsjrss5DQ2sHx1lcV0dLfE4fxkY4MXz4QPxOGcugAue6uGchQsZdFIM5fM8ODzM6zs6uHjbNn5z3HGAFwy9pnsPFy5fztohZcPoKAJ0JBs5qqmJi7dtI9vmcvTCeYy4eU4Z9YK3h7c3cfjxDi9ra2djOk13LsfwnhHaGhIw7AVsF9fVcUh9PYP5PHER5icSZFyXwxsaSIhw/Lx5DDoOJ7e08M3t2wE4trmZhAhvP2gxV+7Zw3uXHcT3d+zghfPn80QqRVaVX+zezXkdHRza0EBHMklDLEZLIsE3tmzhtNZW3rxoERl3F/Pr4/zr0qVsLky1dGmZD8NHDvDLVx3Gh9avJ+UO84YlSYYch3U7d/Kqjg5WNLie3FtH+H/Hxvjy5l7+YdEiOpPz+cmuXSwZHmbYcWhJJHhtezsjbpqcKlfs3k2rP/AkZZT+fJ7uXI6WeJyjm5q4pbufT61Yxhe3bOa17e3c3t/PS9va2JbJsDWT4cRkK7jQHc9wXVcPpy9o5e7BQY5ubCQuwpK6Ol40fz4fWL+eN3R0sKKhARdYkEiwK5vllJYW/tjXx5Z0mrPa2/ldTw+XHHkkN/T28mw6zbDj8KbOTh4YGmJ7NsurFiygM5nk+p5hdmQdXrYiwanOfN742GMsratjOJ3m/FWdvGoBbNg2zBkHtxIbcNid7SOZbGNePM5Z7e3cOzjI17du5ZimJo5sbKQrl+PIxkaa43Fc4K2LFxeeJ/3A+uqjj+YLmzbRkkiwpq+PNy9axD3/v717D46rug84/v3t3fdKWj0tyZJtGT/rOISHS3F5ORCe4dEhDmCSQtskTDJkDEzTBJoMgU47bTOdEgiPMcUEmvJoC9Q4DgMujyZhKGCTEPOyQQYaW5Ity5YlLMnyPn794x4tK1myhJC8tvb3mbmjvefevffcs0f723vvued0d9Ofzfr3bLJZtvf3c3oySVqVhkiEzb29PNnRwexolJ2pFJsjXXxjeS1x7wACLKtO8GTHx/1kXVhVRcLz+Ew8Tom7RFSSd6moLBg8qAl1zC4ffWqjBgVVXS8ir+GPfSDAdap66McTjwLv/ibI2y4gzJyl9EVSfOmv9nHZxQE2HdjHqckkL3fvY93u3TywaBG/60mxvb+f93p7uaqujrJgkKpQyG+q53mcmkwi+BX61e5uTk8maU+luDpRR0iEmVF/XzWhEFfW1vLAjh0cW1LC3nSap3bv5tzKSr47cyb3trbyZ3V1uXyeXVHBvkyGuOfxm+ZmvlBRwR+VleVaMM2NxXJNDo8rKWF+PM76PXuoCoWYGY3yt7Nnc31zM0tKS3mkvZ3prvnlwA3wkmCQxYkEqWyWte5Xl+I3EUwEAkQ9j6XJJL/au5dpgQBd6TQL4nFCru16VTBIZTBIYyTCimnTeO2jj+jKZJgbi5FSpTYcpjwY5PPl5Wzt6+N3PT2sXrAAgKZolGggwLRQiPV79rDxwAH+bvZs4p7H8poaSjyPrkyGXakUv9y7l5b+fhoiERYnElQGgyyIx9nc20tQhG39/fxNUxNPdHSwN52mKRrlGndz+MP9+5kVjfo3foH6SIQ3e3r4w3icU5JJnu3s5Ms1NbzU1cX5lZXMicVY1drKaeXl1IRCzI7F/M9WMtRFwhxfUsJPWlpyzTq70mm+WlvLVtc9SCLtcU51BSWex7XTp7Olrw9V5bTyck4sKWFhPM7MaJQP9u9nTixG1HXbsDAeZ148zg3Nzcx1bSpXtbURcgHltGSSaeEwDZEI39m6lTnTpxP3PK6src21BEp4HosTCd7s6eHHc+cyJxajL5ulxPPoTKeZ4b6cAS6oqiLueQRFeLazk3MrKvjc9Ok839nJwnicHQcOUBkM5upamecRFuFbDQ1ERLi4upozy8t5pbubk8rKSAaDvNzdzZxYjIZwmLtbWggHApxZXs6lNTU8s2cPHakUS0pLSff00J5KkfA8MqrUu7KMBgLMLinJHQvAVXn/D/kG+j/Kd37emYQZn7G0Pvo58DCwVlUPbud4lNrypH8z7KJLlLVrhAfadjM9EqExGmZxcBrlwSBN0SgB/C/OpWVl9Gez/H1PD9PDYUSEqHuYa1cqRVM0yrrdu1nZ2MjGjz7ipLIyNnR3c/WQCv39WbOIex5/XleX+/JbVl7Ow+3tVAaDbOntzT3VmVUl6nlE3T/H4kSCUCBAZd4pckCEH7pHN0WEhOfh5TXvS3gedeEwNeEwX6+vR/DPLpaVl+eeQPVE8DyPRe6m++v79nGG60oAYE4sRn04jOA3Te3PZqlzeRy4UX/XvHlEAgFOLy9nXyZDQISbZs4kFgiwsrGRuOdxXGkp8+Px3M3Ay9wDaQERlpSWkuXj0/9qt/1wIMAfl5WxMB4npUpVMOjnV4SaUIgTamtZEI/zUnc3S8vK2NTTQ59rmVPjyqA+HM6NE/H1+nrubmlhbizGt9yX6p9UVxPzPBoiEZLBINWhED+aM4d9mYz/tKzLb0UwiIjwp7W1LCkt5d7WVnqzWWKeR2MkQnNfHylVvuyOS/FbmJV4HjtTKaqCQYKBAKvmzycowjXvvsu3GxqIBQIo5D7n6lCIRYkE1zc2sqajgxsaG/3eQd3yuOdRFQrlyjHuebl9Atza1ERfNkuVO/5IIMC8WIzVbW2cVVHBYveZDby/N5tlUTzOhVVVZIHmvj7mxGLMiER4L68frFAgwBerqnL5+Iu6OmKexy1NTUQCAT6bSHBvayuXVlcTDAS4takJT4QZ0SjzYjHu6uuj1PNyASceCDAzGmW+C4wAZySTg5r25udzqLAI51RUjGld8wnkP+Az3AScAdwN/B/wGLAciI72vsMxnXjiiTpeCxaoguqLL/rzfem09mcyms5mB63Xl04Pmu/Nm+9Lp7UvndbH29t1R39/bllXKqXpbHbQuqMZWLdt//5c2o7+/hH3fSiHyrOq6kM7doyah6HbONT2C+XRnTu1L53WbF5Z96bT2ptOayqT0VQmk0vL92Bb27Bl+WBbm+7PZDQ7pA4MWN3amnudyWZ1Z3+/tu3frz9ra9NsNqv70mntTqUOel9/JqN96fRBdevO7duH3c/9bj/9mYzevm3bsOt8krql6n9mN7//vva6Opvvjm3b9OWurkHrDvd6LPLz9V5Pj27o6sptozed1lUtLZrJZrUnndbVra0jlrWZXMBGHeF7ddTWRwNExAPOBL4BnKeqZZMRpD6J8bY+UoWSEujthb17IZkc/T2H0p/NEhYZtUuEI8XQp16PVuM9jpHeN9r29mcyuV/zE5GPsWxvpHXGY6Rt7UmlKPM8ghNcJwaGd83/5Z+fh6lSD49Gn7b1Ea710UX4XV6cADw4cdk7/Do7/YBQWvrpAwJw1FXsoy2/IxnvcYz0vtG2N9KX83jzMZbtTVRAONS2KvOeJJ5IAZGDhnfNz8NUqYdTzVjuKfwH/oA3TwN3Ar9Uv/fUo9bA0/m1Q5/dMcaYIjeWM4XVwApVzQCIyKkiskJVr53crE2egVElJ+IswRhjppKxNEl9RkSOF5EVwGXAB8ATk56zSTQwrrkFBWOMGWzEoCAi84EVburA78pGVPXzk5khETkPuB1/tMb7VPUfJnofA0GhrOC3yo0x5shyqDOFzcCvgQtVtRlARCZ1iEzXwuku4GxgO7BBRNaq6tsTuR+7fGSMMcM71O3/S4E24AUR+RcROYuRxwGZKCcBzar6vqoeAB4FLpnondjlI2OMGd6IQUFV16jqFcBC4AXgemCaiNwjIudMUn4agG1589tdWo6IXCMiG0Vk464hg3yMVSAANTVQVTX+jBpjzFQ0lpHXelT1YVW9CGjE7yz0e5Oes5Hzc6+qLlHVJTVDxu0dq5Urob0dbr55gjNnjDFHuU/09Iiqdrov5bMmKT8twIy8+UaXZowx5jA40h4p3ADME5HZIhIGrgDWFjhPxhhTNI6oIcRUNS0i3waewW+Ser+qvlXgbBljTNE4ooICgKo+BTxV6HwYY0wxOtIuHxljjCkgCwrGGGNyLCgYY4zJsaBgjDEmZ8wjrx2JRGQX/jCh41WN39mfsbIYyspjMCuPwY728pilqsM+/XtUB4VPS0Q2jjQkXbGxshjMymMwK4/BpnJ52OUjY4wxORYUjDHG5BR7ULi30Bk4glhZDGblMZiVx2BTtjyK+p6CMcaYwYr9TMEYY0weCwrGGGNyijIoiMh5IrJFRJpF5MZC5+dwEJEZIvKCiLwtIm+JyHUuvVJE/ltE3nN/K1y6iMgdrow2icgJhT2CiScinoj8VkTWufnZIvKKO+Z/d923IyIRN9/sljcVMt+TQUTKReQxEdksIu+IyNIirxs3uP+TN0XkERGJFkv9KLqgICIecBdwPrAIWCEiiwqbq8MiDfylqi4CTgaudcd9I/Ccqs4DnnPz4JfPPDddA9xz+LM86a4D3smb/0fgNlWdC3QCX3PpXwM6Xfptbr2p5nbgaVVdCHwOv1yKsm6ISAOwEliiqovxu/G/gmKpH6paVBOwFHgmb/4m4KZC56sA5fAkcDawBah3afXAFvd6FbAib/3celNhwh/V7zngTGAdIPhPqAaH1hP88T2WutdBt54U+hgmsCySwAdDj6mI68bAWPGV7vNeB5xbLPWj6M4U+PgDH7DdpRUNd3p7PPAKUKuqbW7RDqDWvZ7q5fRj4LtA1s1XAXtVNe3m8483VxZueZdbf6qYDewCfuoup90nIgmKtG6oagvwT8DvgTb8z/s1iqR+FGNQKGoiUgI8Dlyvqt35y9T/qTPl2yiLyIVAu6q+Vui8HCGCwAnAPap6PNDDx5eKgOKpGwDu3skl+MFyOpAAzitopg6jYgwKLcCMvPlGlzbliUgIPyA8pKpPuOSdIlLvltcD7S59KpfTKcDFIvIh8Cj+JaTbgXIRGRiNMP94c2XhlieB3Yczw5NsO7BdVV9x84/hB4lirBsAXwA+UNVdqpoCnsCvM0VRP4oxKGwA5rmWBGH8G0hrC5ynSSciAqwG3lHVf85btBa42r2+Gv9ew0D6Va6lyclAV96lhKOaqt6kqo2q2oT/+T+vql8BXgCWu9WGlsVAGS1360+ZX82qugPYJiILXNJZwNsUYd1wfg+cLCJx938zUB7FUT8KfVOjEBNwAfAusBX4fqHzc5iO+VT80/9NwOtuugD/2udzwHvAs0ClW1/wW2ltBd7Ab4lR8OOYhHJZBqxzr48BXgWagf8EIi496uab3fJjCp3vSSiH44CNrn6sASqKuW4AtwKbgTeBnwGRYqkf1s2FMcaYnGK8fGSMMWYEFhSMMcbkWFAwxhiTY0HBGGNMjgUFY4wxORYUjAFEJCMir+dNh+w9V0S+KSJXTcB+PxSR6k+7HWMmijVJNQYQkX2qWlKA/X6I386/43Dv25jh2JmCMYfgfsn/SETeEJFXRWSuS79FRL7jXq9041RsEpFHXVqliKxxaS+LyLEuvUpE1ru++u/DfxBsYF9fdft4XURWufEePBF5wPXr/4aI3FCAYjBFxIKCMb7YkMtHl+ct61LVzwJ34veuOtSNwPGqeizwTZd2K/Bbl/bXwL+69B8CL6rqZ4D/AmYCiMgfAJcDp6jqcUAG+Ar+k8YNqrrY5eGnE3jMxhwkOPoqxhSFPvdlPJxH8v7eNszyTcBDIrIGv4sI8LsV+RKAqj7vzhDKgNOBS136L0Sk061/FnAisMHvbocYfgd0PweOEZGfAL8A1o//EI0ZnZ0pGDM6HeH1gC/i9wV0Av6X+nh+bAnwoKoe56YFqnqLqnbij4T2P/hnIfeNY9vGjJkFBWNGd3ne3//NXyAiAWCGqr4AfA+/2+QS4Nf4l38QkWVAh/rjV/wKuNKln4/f8Rz4Hc8tF5FpblmliMxyLZMCqvo48AP8wGPMpLHLR8b4YiLyet7806o60Cy1QkQ2Af3AiiHv84B/E5Ek/q/9O1R1r4jcAtzv3tfLx10r3wo8IiJvAS/hd9OMqr4tIj8A1rtAkwKuBfrwR0Qb+AF308QdsjEHsyapxhyCNRk1xcYuHxljjMmxMwVjjDE5dqZgjDEmx4KCMcaYHAsKxhhjciwoGGOMybGgYIwxJuf/AVsZkUHOG8M8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to visualize it No need to train again\n",
    "\n",
    "ep_rwd = np.load('dqn_ep_rwd_final_copy.npy') # loading training data from memory\n",
    "avg_eprwd = []\n",
    "tot = 0\n",
    "for i in range(1,100):\n",
    "    avg_eprwd.append(tot/i)\n",
    "    tot += ep_rwd[i]\n",
    "for i in range(100,len(ep_rwd)):\n",
    "    tot += ep_rwd[i]\n",
    "    tot -= ep_rwd[i-100]\n",
    "    avg_eprwd.append(tot/100)\n",
    "plt.plot(ep_rwd,'c',linewidth=0.3)\n",
    "plt.plot(avg_eprwd,'b',linewidth=2)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Average Reward for every '+str(100)+' Episodes')\n",
    "plt.title('DQN, Cart-pole')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
