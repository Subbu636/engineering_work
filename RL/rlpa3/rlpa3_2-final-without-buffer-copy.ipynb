{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import gym\n",
    "import random as rd\n",
    "from collections import deque\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    Observations\n",
    "    1. On decreasing target update freq the varience of model increasing and on increasing convergence is taking longer\n",
    "    2. low discount factors unable to clearly differentiate the increase in steps after some treshlod\n",
    "    3. Increasing mini batch helping to achieve convergence faster\n",
    "    4. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing DQN class\n",
    "\n",
    "class DQN:\n",
    "\n",
    "    REPLAY_MEMORY_SIZE = 1 \t\t\t# number of tuples in experience replay  \n",
    "    EPSILON = 0.5 \t\t\t\t\t\t# epsilon of epsilon-greedy exploation\n",
    "    EPSILON_DECAY = 0.9999 \t\t\t\t# exponential decay multiplier for epsilon\n",
    "    HIDDEN1_SIZE = 32 \t\t\t\t\t# size of hidden layer 1 --> try 16*\n",
    "    HIDDEN2_SIZE = 16 \t\t\t\t\t# size of hidden layer 2\n",
    "    EPISODES_NUM = 2000 \t\t\t\t# number of episodes to train on. Ideally shouldn't take longer than 2000\n",
    "    MAX_STEPS = 200 \t\t\t\t\t# maximum number of steps in an episode \n",
    "    LEARNING_RATE = 0.001 \t\t\t\t# learning rate and other parameters for SGD/RMSProp/Adam --> try 0.001*, 0.003\n",
    "    MINIBATCH_SIZE = 1 \t\t\t\t# size of minibatch sampled from the experience replay --> try 16*, 8\n",
    "    DISCOUNT_FACTOR = 0.999 \t\t\t# MDP's gamma --> try 0.999*, 0.99\n",
    "    TARGET_UPDATE_FREQ = 100 \t\t\t# number of steps (not episodes) after which to update the target networks --> try 50, 20*     \n",
    "    LOG_DIR = './logs' \t\t\t\t\t# directory wherein logging takes place\n",
    "    EPSILON_MIN = 0.02                  # 0.05*\n",
    "\n",
    "\n",
    "    # Create and initialize the environment\n",
    "    def __init__(self, env):\n",
    "        self.env = gym.make(env)\n",
    "        assert len(self.env.observation_space.shape) == 1\n",
    "        self.input_size = self.env.observation_space.shape[0]\t\t# In case of cartpole, 4 state features\n",
    "        self.output_size = self.env.action_space.n\t\t\t\t\t# In case of cartpole, 2 actions (right/left)\n",
    "        self.eps = self.EPSILON\n",
    "        self.episodic_rewards = []\n",
    "        self.episodic_steps = []\n",
    "\n",
    "    # Create the Q-network\n",
    "    def initialize_network(self):\n",
    "        \n",
    "        ############################################################\n",
    "        # Design your q-network here.\n",
    "        # \n",
    "        # Add hidden layers and the output layer. For instance:\n",
    "        # \n",
    "        # with tf.name_scope('output'):\n",
    "        #\tW_n = tf.Variable(\n",
    "        # \t\t\t tf.truncated_normal([self.HIDDEN_n-1_SIZE, self.output_size], \n",
    "        # \t\t\t stddev=0.01), name='W_n')\n",
    "        # \tb_n = tf.Variable(tf.zeros(self.output_size), name='b_n')\n",
    "        # \tself.Q = tf.matmul(h_n-1, W_n) + b_n\n",
    "        #\n",
    "        #############################################################\n",
    "        \n",
    "        # Model designed using keras layers\n",
    "        self.model = keras.Sequential([\n",
    "                layers.InputLayer(input_shape=(self.input_size,)),\n",
    "                layers.Dense(self.HIDDEN1_SIZE, activation='relu', name='hidden1', kernel_initializer='RandomNormal'),\n",
    "                layers.Dense(self.HIDDEN2_SIZE, activation='relu', name='hidden2', kernel_initializer='RandomNormal'),\n",
    "                layers.Dense(self.output_size, activation='linear', name='output', kernel_initializer='RandomNormal')\n",
    "        ])\n",
    "\n",
    "        ############################################################\n",
    "        # Next, compute the loss.\n",
    "        #\n",
    "        # First, compute the q-values. Note that you need to calculate these\n",
    "        # for the actions in the (s,a,s',r) tuples from the experience replay's minibatch\n",
    "        #\n",
    "        # Next, compute the l2 loss between these estimated q-values and \n",
    "        # the target (which is computed using the frozen target network)\n",
    "        #\n",
    "        ############################################################\n",
    "        \n",
    "        ############################################################\n",
    "        # Finally, choose a gradient descent algorithm : SGD/RMSProp/Adam. \n",
    "        #\n",
    "        # For instance:\n",
    "        # optimizer = tf.train.GradientDescentOptimizer(self.LEARNING_RATE)\n",
    "        # global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "        # self.train_op = optimizer.minimize(self.loss, global_step=global_step)\n",
    "        #\n",
    "        ############################################################\n",
    "\n",
    "        # Assigned descent algo. and loss function in one line\n",
    "        self.model.compile(loss=keras.losses.MeanSquaredError(),optimizer=keras.optimizers.Adam(lr=self.LEARNING_RATE))\n",
    "        self.model.summary()\n",
    "        \n",
    "        # create a target model a clone to our model i.e. target network\n",
    "        self.target_model = keras.models.clone_model(self.model)\n",
    "        self.target_model.build((None, self.input_size))\n",
    "        self.target_model.compile(loss=keras.losses.MeanSquaredError(),optimizer=keras.optimizers.Adam(lr=self.LEARNING_RATE))\n",
    "        self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "        ############################################################\n",
    "\n",
    "    def train(self, episodes_num=EPISODES_NUM):\n",
    "\n",
    "        # Initialize summary for TensorBoard \n",
    "        summary_writer = tf.summary.create_file_writer(self.LOG_DIR)\n",
    "        summary = tf.summary\n",
    "        # Alternatively, you could use animated real-time plots from matplotlib \n",
    "        # (https://stackoverflow.com/a/24228275/3284912)\n",
    "\n",
    "        ############################################################\n",
    "        # Initialize other variables (like the replay memory)\n",
    "        ############################################################\n",
    "        \n",
    "        # Using deque\n",
    "        self.replay_buffer = deque(maxlen=self.REPLAY_MEMORY_SIZE)\n",
    "        total_steps = 0\n",
    "\n",
    "        ############################################################\n",
    "        # Main training loop\n",
    "        # \n",
    "        # In each episode, \n",
    "        #\tpick the action for the given state, \n",
    "        #\tperform a 'step' in the environment to get the reward and next state,\n",
    "        #\tupdate the replay buffer,\n",
    "        #\tsample a random minibatch from the replay buffer,\n",
    "        # \tperform Q-learning,\n",
    "        #\tupdate the target network, if required.\n",
    "        #\n",
    "        #\n",
    "        #\n",
    "        # You'll need to write code in various places in the following skeleton\n",
    "        #\n",
    "        ############################################################\n",
    "\n",
    "        for episode in range(episodes_num):\n",
    "\n",
    "            state = self.env.reset()\n",
    "\n",
    "            ############################################################\n",
    "            # Episode-specific initializations go here.\n",
    "            ############################################################\n",
    "            \n",
    "            episode_length = 0\n",
    "            score = 0\n",
    "            \n",
    "            ############################################################\n",
    "\n",
    "            while True:\n",
    "                ############################################################\n",
    "                # Pick the next action using epsilon greedy and execute it\n",
    "                ############################################################\n",
    "                episode_length += 1\n",
    "                total_steps += 1\n",
    "                if(rd.random() < self.eps):\n",
    "                    act = self.env.action_space.sample()\n",
    "                else:\n",
    "                    act = np.argmax(self.model.predict(np.array([state]))[0])\n",
    "\n",
    "                ############################################################\n",
    "                # Step in the environment. Something like: \n",
    "                # next_state, reward, done, _ = self.env.step(action)\n",
    "                ############################################################\n",
    "\n",
    "                next_state, reward, done, _ = self.env.step(act)\n",
    "                \n",
    "                ############################################################\n",
    "                # Update the (limited) replay buffer. \n",
    "                #\n",
    "                # Note : when the replay buffer is full, you'll need to \n",
    "                # remove an entry to accommodate a new one.\n",
    "                ############################################################\n",
    "\n",
    "                # The max length in deque removes oldest if buffer size exceeds it\n",
    "                x = 0\n",
    "                if done:\n",
    "                    x = 1\n",
    "                self.replay_buffer.append(((state),act,reward,(next_state),x))\n",
    "                score += reward\n",
    "                state = next_state\n",
    "\n",
    "                ############################################################\n",
    "                # Sample a random minibatch and perform Q-learning (fetch max Q at s') \n",
    "                #\n",
    "                # Remember, the target (r + gamma * max Q) is computed    \n",
    "                # with the help of the target network.\n",
    "                # Compute this target and pass it to the network for computing \n",
    "                # and minimizing the loss with the current estimates\n",
    "                #\n",
    "                ############################################################\n",
    "                \n",
    "                # not starting network update until it has a batch size elements\n",
    "                if len(self.replay_buffer) >= self.REPLAY_MEMORY_SIZE: # REPLAY_MEMORY_SIZE / MINI\n",
    "                    replay_batch = np.array(rd.sample(self.replay_buffer,self.MINIBATCH_SIZE))\n",
    "                    nst = []\n",
    "                    st = []\n",
    "                    for y in replay_batch:\n",
    "                        nst.append(y[3])\n",
    "                        st.append(y[0])\n",
    "                    max_Q = np.amax(self.target_model.predict(np.array(nst),workers=8, use_multiprocessing=True),1)\n",
    "                    batch_targets = self.target_model.predict(np.array(st),workers=8, use_multiprocessing=True)\n",
    "                    # for st, act, rwd, nst, d in replay_batch:\n",
    "                    #     if d:\n",
    "                    #         y = rwd\n",
    "                    #     else:\n",
    "                    #         y = (rwd + self.DISCOUNT_FACTOR * np.max(self.target_model.predict(nst)[0]))\n",
    "                    #     tgt = self.model.predict(st)[0]\n",
    "                    #     tgt[act] = y\n",
    "                    #     batch_states.append(st[0])\n",
    "                    #     batch_targets.append(tgt)\n",
    "                    # print(max_Q)\n",
    "                    # print(np.shape((1-replay_batch[:,4])))\n",
    "                    tgts = replay_batch[:,2] + self.DISCOUNT_FACTOR * max_Q * (1-replay_batch[:,4])\n",
    "                    for y in range(len(batch_targets)):\n",
    "                        batch_targets[y][replay_batch[y,1]] = tgts[y]\n",
    "                    self.model.fit(np.array(st), batch_targets, epochs=1, verbose = 0, workers=8, use_multiprocessing=True)\n",
    "                    \n",
    "                    if self.eps > self.EPSILON_MIN:\n",
    "                        self.eps *= self.EPSILON_DECAY\n",
    "                    elif self.eps < self.EPSILON_MIN:\n",
    "                        self.eps = self.EPSILON_MIN\n",
    "\n",
    "                ############################################################\n",
    "                # Update target weights. \n",
    "                #\n",
    "                # Something along the lines of:\n",
    "                # if total_steps % self.TARGET_UPDATE_FREQ == 0:\n",
    "                # \ttarget_weights = self.session.run(self.weights)\n",
    "                ############################################################\n",
    "\n",
    "                if total_steps%self.TARGET_UPDATE_FREQ == 0:\n",
    "                    self.target_model.set_weights(self.model.get_weights())\n",
    "\n",
    "                ############################################################\n",
    "                # Break out of the loop if the episode ends\n",
    "                #\n",
    "                # Something like:\n",
    "                # if done or (episode_length == self.MAX_STEPS):\n",
    "                # \tbreak\n",
    "                #\n",
    "                ############################################################\n",
    "                \n",
    "                if done or episode_length == self.MAX_STEPS:\n",
    "                    self.episodic_rewards.append(score)\n",
    "                    self.episodic_steps.append(episode_length)\n",
    "                    break\n",
    "\n",
    "\n",
    "            ############################################################\n",
    "            # Logging. \n",
    "            #\n",
    "            # Very important. This is what gives an idea of how good the current\n",
    "            # experiment is, and if one should terminate and re-run with new parameters\n",
    "            # The earlier you learn how to read and visualize experiment logs quickly,\n",
    "            # the faster you'll be able to prototype and learn.\n",
    "            #\n",
    "            # Use any debugging information you think you need.\n",
    "            # For instance :\n",
    "\n",
    "            print(\"Training: Episode = %d, Length = %d, Global step = %d\" % (episode, episode_length, total_steps),end=', ')\n",
    "            print('Eps: '+str(self.eps))\n",
    "            with summary_writer.as_default():\n",
    "                summary.scalar(\"episode length\",episode ,step=episode_length)\n",
    "    \n",
    "    def save_model(self, name):\n",
    "        self.target_model.save(name)\n",
    "        \n",
    "    def load_model(self, name):\n",
    "        self.model = keras.models.load_model(name)\n",
    "        self.target_model = keras.models.load_model(name)\n",
    "\n",
    "    # Simple function to visually 'test' a policy\n",
    "    def playPolicy(self):\n",
    "\n",
    "        done = False\n",
    "        steps = 0\n",
    "        state = self.env.reset()\n",
    "\n",
    "        # we assume the CartPole task to be solved if the pole remains upright for 200 steps\n",
    "        while not done and steps < 200: \n",
    "            # self.env.render()\n",
    "            action = np.argmax(self.target_model.predict(np.array([state]))[0])\n",
    "            state, _, done, _ = self.env.step(action)\n",
    "            steps += 1\n",
    "\n",
    "        return steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Starting training...\n",
      "\n",
      "Training: Episode = 0, Length = 15, Global step = 15, Eps: 0.02\n",
      "Training: Episode = 1, Length = 22, Global step = 37, Eps: 0.02\n",
      "Training: Episode = 2, Length = 23, Global step = 60, Eps: 0.02\n",
      "Training: Episode = 3, Length = 40, Global step = 100, Eps: 0.02\n",
      "Training: Episode = 4, Length = 43, Global step = 143, Eps: 0.02\n",
      "Training: Episode = 5, Length = 58, Global step = 201, Eps: 0.02\n",
      "Training: Episode = 6, Length = 76, Global step = 277, Eps: 0.02\n",
      "Training: Episode = 7, Length = 200, Global step = 477, Eps: 0.02\n",
      "Training: Episode = 8, Length = 86, Global step = 563, Eps: 0.02\n",
      "Training: Episode = 9, Length = 165, Global step = 728, Eps: 0.02\n",
      "Training: Episode = 10, Length = 59, Global step = 787, Eps: 0.02\n",
      "Training: Episode = 11, Length = 159, Global step = 946, Eps: 0.02\n",
      "Training: Episode = 12, Length = 49, Global step = 995, Eps: 0.02\n",
      "Training: Episode = 13, Length = 138, Global step = 1133, Eps: 0.02\n",
      "Training: Episode = 14, Length = 102, Global step = 1235, Eps: 0.02\n",
      "Training: Episode = 15, Length = 183, Global step = 1418, Eps: 0.02\n",
      "Training: Episode = 16, Length = 17, Global step = 1435, Eps: 0.02\n",
      "Training: Episode = 17, Length = 51, Global step = 1486, Eps: 0.02\n",
      "Training: Episode = 18, Length = 52, Global step = 1538, Eps: 0.02\n",
      "Training: Episode = 19, Length = 67, Global step = 1605, Eps: 0.02\n",
      "Training: Episode = 20, Length = 154, Global step = 1759, Eps: 0.02\n",
      "Training: Episode = 21, Length = 101, Global step = 1860, Eps: 0.02\n",
      "Training: Episode = 22, Length = 46, Global step = 1906, Eps: 0.02\n",
      "Training: Episode = 23, Length = 97, Global step = 2003, Eps: 0.02\n",
      "Training: Episode = 24, Length = 91, Global step = 2094, Eps: 0.02\n",
      "Training: Episode = 25, Length = 62, Global step = 2156, Eps: 0.02\n",
      "Training: Episode = 26, Length = 105, Global step = 2261, Eps: 0.02\n",
      "Training: Episode = 27, Length = 41, Global step = 2302, Eps: 0.02\n",
      "Training: Episode = 28, Length = 77, Global step = 2379, Eps: 0.02\n",
      "Training: Episode = 29, Length = 80, Global step = 2459, Eps: 0.02\n",
      "Training: Episode = 30, Length = 72, Global step = 2531, Eps: 0.02\n",
      "Training: Episode = 31, Length = 104, Global step = 2635, Eps: 0.02\n",
      "Training: Episode = 32, Length = 123, Global step = 2758, Eps: 0.02\n",
      "Training: Episode = 33, Length = 99, Global step = 2857, Eps: 0.02\n",
      "Training: Episode = 34, Length = 139, Global step = 2996, Eps: 0.02\n",
      "Training: Episode = 35, Length = 108, Global step = 3104, Eps: 0.02\n",
      "Training: Episode = 36, Length = 15, Global step = 3119, Eps: 0.02\n",
      "Training: Episode = 37, Length = 10, Global step = 3129, Eps: 0.02\n",
      "Training: Episode = 38, Length = 9, Global step = 3138, Eps: 0.02\n",
      "Training: Episode = 39, Length = 11, Global step = 3149, Eps: 0.02\n",
      "Training: Episode = 40, Length = 11, Global step = 3160, Eps: 0.02\n",
      "Training: Episode = 41, Length = 9, Global step = 3169, Eps: 0.02\n",
      "Training: Episode = 42, Length = 9, Global step = 3178, Eps: 0.02\n",
      "Training: Episode = 43, Length = 10, Global step = 3188, Eps: 0.02\n",
      "Training: Episode = 44, Length = 9, Global step = 3197, Eps: 0.02\n",
      "Training: Episode = 45, Length = 14, Global step = 3211, Eps: 0.02\n",
      "Training: Episode = 46, Length = 17, Global step = 3228, Eps: 0.02\n",
      "Training: Episode = 47, Length = 15, Global step = 3243, Eps: 0.02\n",
      "Training: Episode = 48, Length = 27, Global step = 3270, Eps: 0.02\n",
      "Training: Episode = 49, Length = 20, Global step = 3290, Eps: 0.02\n",
      "Training: Episode = 50, Length = 16, Global step = 3306, Eps: 0.02\n",
      "Training: Episode = 51, Length = 18, Global step = 3324, Eps: 0.02\n",
      "Training: Episode = 52, Length = 15, Global step = 3339, Eps: 0.02\n",
      "Training: Episode = 53, Length = 11, Global step = 3350, Eps: 0.02\n",
      "Training: Episode = 54, Length = 14, Global step = 3364, Eps: 0.02\n",
      "Training: Episode = 55, Length = 12, Global step = 3376, Eps: 0.02\n",
      "Training: Episode = 56, Length = 11, Global step = 3387, Eps: 0.02\n",
      "Training: Episode = 57, Length = 11, Global step = 3398, Eps: 0.02\n",
      "Training: Episode = 58, Length = 11, Global step = 3409, Eps: 0.02\n",
      "Training: Episode = 59, Length = 11, Global step = 3420, Eps: 0.02\n",
      "Training: Episode = 60, Length = 11, Global step = 3431, Eps: 0.02\n",
      "Training: Episode = 61, Length = 9, Global step = 3440, Eps: 0.02\n",
      "Training: Episode = 62, Length = 10, Global step = 3450, Eps: 0.02\n",
      "Training: Episode = 63, Length = 12, Global step = 3462, Eps: 0.02\n",
      "Training: Episode = 64, Length = 9, Global step = 3471, Eps: 0.02\n",
      "Training: Episode = 65, Length = 10, Global step = 3481, Eps: 0.02\n",
      "Training: Episode = 66, Length = 10, Global step = 3491, Eps: 0.02\n",
      "Training: Episode = 67, Length = 11, Global step = 3502, Eps: 0.02\n",
      "Training: Episode = 68, Length = 11, Global step = 3513, Eps: 0.02\n",
      "Training: Episode = 69, Length = 10, Global step = 3523, Eps: 0.02\n",
      "Training: Episode = 70, Length = 10, Global step = 3533, Eps: 0.02\n",
      "Training: Episode = 71, Length = 10, Global step = 3543, Eps: 0.02\n",
      "Training: Episode = 72, Length = 12, Global step = 3555, Eps: 0.02\n",
      "Training: Episode = 73, Length = 10, Global step = 3565, Eps: 0.02\n",
      "Training: Episode = 74, Length = 9, Global step = 3574, Eps: 0.02\n",
      "Training: Episode = 75, Length = 10, Global step = 3584, Eps: 0.02\n",
      "Training: Episode = 76, Length = 9, Global step = 3593, Eps: 0.02\n",
      "Training: Episode = 77, Length = 11, Global step = 3604, Eps: 0.02\n",
      "Training: Episode = 78, Length = 11, Global step = 3615, Eps: 0.02\n",
      "Training: Episode = 79, Length = 10, Global step = 3625, Eps: 0.02\n",
      "Training: Episode = 80, Length = 10, Global step = 3635, Eps: 0.02\n",
      "Training: Episode = 81, Length = 11, Global step = 3646, Eps: 0.02\n",
      "Training: Episode = 82, Length = 9, Global step = 3655, Eps: 0.02\n",
      "Training: Episode = 83, Length = 12, Global step = 3667, Eps: 0.02\n",
      "Training: Episode = 84, Length = 14, Global step = 3681, Eps: 0.02\n",
      "Training: Episode = 85, Length = 12, Global step = 3693, Eps: 0.02\n",
      "Training: Episode = 86, Length = 10, Global step = 3703, Eps: 0.02\n",
      "Training: Episode = 87, Length = 11, Global step = 3714, Eps: 0.02\n",
      "Training: Episode = 88, Length = 13, Global step = 3727, Eps: 0.02\n",
      "Training: Episode = 89, Length = 12, Global step = 3739, Eps: 0.02\n",
      "Training: Episode = 90, Length = 13, Global step = 3752, Eps: 0.02\n",
      "Training: Episode = 91, Length = 16, Global step = 3768, Eps: 0.02\n",
      "Training: Episode = 92, Length = 16, Global step = 3784, Eps: 0.02\n",
      "Training: Episode = 93, Length = 17, Global step = 3801, Eps: 0.02\n",
      "Training: Episode = 94, Length = 22, Global step = 3823, Eps: 0.02\n",
      "Training: Episode = 95, Length = 57, Global step = 3880, Eps: 0.02\n",
      "Training: Episode = 96, Length = 12, Global step = 3892, Eps: 0.02\n",
      "Training: Episode = 97, Length = 11, Global step = 3903, Eps: 0.02\n",
      "Training: Episode = 98, Length = 9, Global step = 3912, Eps: 0.02\n",
      "Training: Episode = 99, Length = 11, Global step = 3923, Eps: 0.02\n",
      "Training: Episode = 100, Length = 12, Global step = 3935, Eps: 0.02\n",
      "Training: Episode = 101, Length = 24, Global step = 3959, Eps: 0.02\n",
      "Training: Episode = 102, Length = 12, Global step = 3971, Eps: 0.02\n",
      "Training: Episode = 103, Length = 15, Global step = 3986, Eps: 0.02\n",
      "Training: Episode = 104, Length = 20, Global step = 4006, Eps: 0.02\n",
      "Training: Episode = 105, Length = 25, Global step = 4031, Eps: 0.02\n",
      "Training: Episode = 106, Length = 33, Global step = 4064, Eps: 0.02\n",
      "Training: Episode = 107, Length = 60, Global step = 4124, Eps: 0.02\n",
      "Training: Episode = 108, Length = 13, Global step = 4137, Eps: 0.02\n",
      "Training: Episode = 109, Length = 19, Global step = 4156, Eps: 0.02\n",
      "Training: Episode = 110, Length = 16, Global step = 4172, Eps: 0.02\n",
      "Training: Episode = 111, Length = 16, Global step = 4188, Eps: 0.02\n",
      "Training: Episode = 112, Length = 19, Global step = 4207, Eps: 0.02\n",
      "Training: Episode = 113, Length = 17, Global step = 4224, Eps: 0.02\n",
      "Training: Episode = 114, Length = 19, Global step = 4243, Eps: 0.02\n",
      "Training: Episode = 115, Length = 26, Global step = 4269, Eps: 0.02\n",
      "Training: Episode = 116, Length = 59, Global step = 4328, Eps: 0.02\n",
      "Training: Episode = 117, Length = 60, Global step = 4388, Eps: 0.02\n",
      "Training: Episode = 118, Length = 14, Global step = 4402, Eps: 0.02\n",
      "Training: Episode = 119, Length = 16, Global step = 4418, Eps: 0.02\n",
      "Training: Episode = 120, Length = 16, Global step = 4434, Eps: 0.02\n",
      "Training: Episode = 121, Length = 24, Global step = 4458, Eps: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Episode = 122, Length = 27, Global step = 4485, Eps: 0.02\n",
      "Training: Episode = 123, Length = 56, Global step = 4541, Eps: 0.02\n",
      "Training: Episode = 124, Length = 24, Global step = 4565, Eps: 0.02\n",
      "Training: Episode = 125, Length = 91, Global step = 4656, Eps: 0.02\n",
      "Training: Episode = 126, Length = 13, Global step = 4669, Eps: 0.02\n",
      "Training: Episode = 127, Length = 18, Global step = 4687, Eps: 0.02\n",
      "Training: Episode = 128, Length = 23, Global step = 4710, Eps: 0.02\n",
      "Training: Episode = 129, Length = 25, Global step = 4735, Eps: 0.02\n",
      "Training: Episode = 130, Length = 89, Global step = 4824, Eps: 0.02\n",
      "Training: Episode = 131, Length = 61, Global step = 4885, Eps: 0.02\n",
      "Training: Episode = 132, Length = 17, Global step = 4902, Eps: 0.02\n",
      "Training: Episode = 133, Length = 21, Global step = 4923, Eps: 0.02\n",
      "Training: Episode = 134, Length = 59, Global step = 4982, Eps: 0.02\n",
      "Training: Episode = 135, Length = 25, Global step = 5007, Eps: 0.02\n",
      "Training: Episode = 136, Length = 107, Global step = 5114, Eps: 0.02\n",
      "Training: Episode = 137, Length = 18, Global step = 5132, Eps: 0.02\n",
      "Training: Episode = 138, Length = 11, Global step = 5143, Eps: 0.02\n",
      "Training: Episode = 139, Length = 11, Global step = 5154, Eps: 0.02\n",
      "Training: Episode = 140, Length = 57, Global step = 5211, Eps: 0.02\n",
      "Training: Episode = 141, Length = 86, Global step = 5297, Eps: 0.02\n",
      "Training: Episode = 142, Length = 16, Global step = 5313, Eps: 0.02\n",
      "Training: Episode = 143, Length = 22, Global step = 5335, Eps: 0.02\n",
      "Training: Episode = 144, Length = 77, Global step = 5412, Eps: 0.02\n",
      "Training: Episode = 145, Length = 20, Global step = 5432, Eps: 0.02\n",
      "Training: Episode = 146, Length = 49, Global step = 5481, Eps: 0.02\n",
      "Training: Episode = 147, Length = 12, Global step = 5493, Eps: 0.02\n",
      "Training: Episode = 148, Length = 11, Global step = 5504, Eps: 0.02\n",
      "Training: Episode = 149, Length = 28, Global step = 5532, Eps: 0.02\n",
      "Training: Episode = 150, Length = 27, Global step = 5559, Eps: 0.02\n",
      "Training: Episode = 151, Length = 143, Global step = 5702, Eps: 0.02\n",
      "Training: Episode = 152, Length = 23, Global step = 5725, Eps: 0.02\n",
      "Training: Episode = 153, Length = 50, Global step = 5775, Eps: 0.02\n",
      "Training: Episode = 154, Length = 57, Global step = 5832, Eps: 0.02\n",
      "Training: Episode = 155, Length = 29, Global step = 5861, Eps: 0.02\n",
      "Training: Episode = 156, Length = 103, Global step = 5964, Eps: 0.02\n",
      "Training: Episode = 157, Length = 47, Global step = 6011, Eps: 0.02\n",
      "Training: Episode = 158, Length = 57, Global step = 6068, Eps: 0.02\n",
      "Training: Episode = 159, Length = 43, Global step = 6111, Eps: 0.02\n",
      "Training: Episode = 160, Length = 73, Global step = 6184, Eps: 0.02\n",
      "Training: Episode = 161, Length = 64, Global step = 6248, Eps: 0.02\n",
      "Training: Episode = 162, Length = 17, Global step = 6265, Eps: 0.02\n",
      "Training: Episode = 163, Length = 14, Global step = 6279, Eps: 0.02\n",
      "Training: Episode = 164, Length = 12, Global step = 6291, Eps: 0.02\n",
      "Training: Episode = 165, Length = 18, Global step = 6309, Eps: 0.02\n",
      "Training: Episode = 166, Length = 23, Global step = 6332, Eps: 0.02\n",
      "Training: Episode = 167, Length = 27, Global step = 6359, Eps: 0.02\n",
      "Training: Episode = 168, Length = 32, Global step = 6391, Eps: 0.02\n",
      "Training: Episode = 169, Length = 54, Global step = 6445, Eps: 0.02\n",
      "Training: Episode = 170, Length = 104, Global step = 6549, Eps: 0.02\n",
      "Training: Episode = 171, Length = 87, Global step = 6636, Eps: 0.02\n",
      "Training: Episode = 172, Length = 24, Global step = 6660, Eps: 0.02\n",
      "Training: Episode = 173, Length = 21, Global step = 6681, Eps: 0.02\n",
      "Training: Episode = 174, Length = 31, Global step = 6712, Eps: 0.02\n",
      "Training: Episode = 175, Length = 53, Global step = 6765, Eps: 0.02\n",
      "Training: Episode = 176, Length = 77, Global step = 6842, Eps: 0.02\n",
      "Training: Episode = 177, Length = 18, Global step = 6860, Eps: 0.02\n",
      "Training: Episode = 178, Length = 12, Global step = 6872, Eps: 0.02\n",
      "Training: Episode = 179, Length = 11, Global step = 6883, Eps: 0.02\n",
      "Training: Episode = 180, Length = 13, Global step = 6896, Eps: 0.02\n",
      "Training: Episode = 181, Length = 8, Global step = 6904, Eps: 0.02\n",
      "Training: Episode = 182, Length = 8, Global step = 6912, Eps: 0.02\n",
      "Training: Episode = 183, Length = 9, Global step = 6921, Eps: 0.02\n",
      "Training: Episode = 184, Length = 9, Global step = 6930, Eps: 0.02\n",
      "Training: Episode = 185, Length = 12, Global step = 6942, Eps: 0.02\n",
      "Training: Episode = 186, Length = 12, Global step = 6954, Eps: 0.02\n",
      "Training: Episode = 187, Length = 14, Global step = 6968, Eps: 0.02\n",
      "Training: Episode = 188, Length = 48, Global step = 7016, Eps: 0.02\n",
      "Training: Episode = 189, Length = 40, Global step = 7056, Eps: 0.02\n",
      "Training: Episode = 190, Length = 58, Global step = 7114, Eps: 0.02\n",
      "Training: Episode = 191, Length = 136, Global step = 7250, Eps: 0.02\n",
      "Training: Episode = 192, Length = 153, Global step = 7403, Eps: 0.02\n",
      "Training: Episode = 193, Length = 154, Global step = 7557, Eps: 0.02\n",
      "Training: Episode = 194, Length = 64, Global step = 7621, Eps: 0.02\n",
      "Training: Episode = 195, Length = 97, Global step = 7718, Eps: 0.02\n",
      "Training: Episode = 196, Length = 33, Global step = 7751, Eps: 0.02\n",
      "Training: Episode = 197, Length = 27, Global step = 7778, Eps: 0.02\n",
      "Training: Episode = 198, Length = 29, Global step = 7807, Eps: 0.02\n",
      "Training: Episode = 199, Length = 33, Global step = 7840, Eps: 0.02\n",
      "Training: Episode = 200, Length = 33, Global step = 7873, Eps: 0.02\n",
      "Training: Episode = 201, Length = 40, Global step = 7913, Eps: 0.02\n",
      "Training: Episode = 202, Length = 47, Global step = 7960, Eps: 0.02\n",
      "Training: Episode = 203, Length = 115, Global step = 8075, Eps: 0.02\n",
      "Training: Episode = 204, Length = 38, Global step = 8113, Eps: 0.02\n",
      "Training: Episode = 205, Length = 46, Global step = 8159, Eps: 0.02\n",
      "Training: Episode = 206, Length = 127, Global step = 8286, Eps: 0.02\n",
      "Training: Episode = 207, Length = 69, Global step = 8355, Eps: 0.02\n",
      "Training: Episode = 208, Length = 200, Global step = 8555, Eps: 0.02\n",
      "Training: Episode = 209, Length = 124, Global step = 8679, Eps: 0.02\n",
      "Training: Episode = 210, Length = 82, Global step = 8761, Eps: 0.02\n",
      "Training: Episode = 211, Length = 36, Global step = 8797, Eps: 0.02\n",
      "Training: Episode = 212, Length = 38, Global step = 8835, Eps: 0.02\n",
      "Training: Episode = 213, Length = 99, Global step = 8934, Eps: 0.02\n",
      "Training: Episode = 214, Length = 200, Global step = 9134, Eps: 0.02\n",
      "Training: Episode = 215, Length = 65, Global step = 9199, Eps: 0.02\n",
      "Training: Episode = 216, Length = 17, Global step = 9216, Eps: 0.02\n",
      "Training: Episode = 217, Length = 12, Global step = 9228, Eps: 0.02\n",
      "Training: Episode = 218, Length = 10, Global step = 9238, Eps: 0.02\n",
      "Training: Episode = 219, Length = 9, Global step = 9247, Eps: 0.02\n",
      "Training: Episode = 220, Length = 10, Global step = 9257, Eps: 0.02\n",
      "Training: Episode = 221, Length = 110, Global step = 9367, Eps: 0.02\n",
      "Training: Episode = 222, Length = 66, Global step = 9433, Eps: 0.02\n",
      "Training: Episode = 223, Length = 26, Global step = 9459, Eps: 0.02\n",
      "Training: Episode = 224, Length = 14, Global step = 9473, Eps: 0.02\n",
      "Training: Episode = 225, Length = 60, Global step = 9533, Eps: 0.02\n",
      "Training: Episode = 226, Length = 105, Global step = 9638, Eps: 0.02\n",
      "Training: Episode = 227, Length = 75, Global step = 9713, Eps: 0.02\n",
      "Training: Episode = 228, Length = 107, Global step = 9820, Eps: 0.02\n",
      "Training: Episode = 229, Length = 90, Global step = 9910, Eps: 0.02\n",
      "Training: Episode = 230, Length = 77, Global step = 9987, Eps: 0.02\n",
      "Training: Episode = 231, Length = 87, Global step = 10074, Eps: 0.02\n",
      "Training: Episode = 232, Length = 81, Global step = 10155, Eps: 0.02\n",
      "Training: Episode = 233, Length = 172, Global step = 10327, Eps: 0.02\n",
      "Training: Episode = 234, Length = 62, Global step = 10389, Eps: 0.02\n",
      "Training: Episode = 235, Length = 153, Global step = 10542, Eps: 0.02\n",
      "Training: Episode = 236, Length = 40, Global step = 10582, Eps: 0.02\n",
      "Training: Episode = 237, Length = 149, Global step = 10731, Eps: 0.02\n",
      "Training: Episode = 238, Length = 89, Global step = 10820, Eps: 0.02\n",
      "Training: Episode = 239, Length = 151, Global step = 10971, Eps: 0.02\n",
      "Training: Episode = 240, Length = 50, Global step = 11021, Eps: 0.02\n",
      "Training: Episode = 241, Length = 72, Global step = 11093, Eps: 0.02\n",
      "Training: Episode = 242, Length = 78, Global step = 11171, Eps: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Episode = 243, Length = 116, Global step = 11287, Eps: 0.02\n",
      "Training: Episode = 244, Length = 56, Global step = 11343, Eps: 0.02\n",
      "Training: Episode = 245, Length = 65, Global step = 11408, Eps: 0.02\n",
      "Training: Episode = 246, Length = 65, Global step = 11473, Eps: 0.02\n",
      "Training: Episode = 247, Length = 85, Global step = 11558, Eps: 0.02\n",
      "Training: Episode = 248, Length = 100, Global step = 11658, Eps: 0.02\n",
      "Training: Episode = 249, Length = 96, Global step = 11754, Eps: 0.02\n",
      "Training: Episode = 250, Length = 111, Global step = 11865, Eps: 0.02\n",
      "Training: Episode = 251, Length = 38, Global step = 11903, Eps: 0.02\n",
      "Training: Episode = 252, Length = 77, Global step = 11980, Eps: 0.02\n",
      "Training: Episode = 253, Length = 30, Global step = 12010, Eps: 0.02\n",
      "Training: Episode = 254, Length = 54, Global step = 12064, Eps: 0.02\n",
      "Training: Episode = 255, Length = 135, Global step = 12199, Eps: 0.02\n",
      "Training: Episode = 256, Length = 113, Global step = 12312, Eps: 0.02\n",
      "Training: Episode = 257, Length = 80, Global step = 12392, Eps: 0.02\n",
      "Training: Episode = 258, Length = 32, Global step = 12424, Eps: 0.02\n",
      "Training: Episode = 259, Length = 12, Global step = 12436, Eps: 0.02\n",
      "Training: Episode = 260, Length = 8, Global step = 12444, Eps: 0.02\n",
      "Training: Episode = 261, Length = 13, Global step = 12457, Eps: 0.02\n",
      "Training: Episode = 262, Length = 10, Global step = 12467, Eps: 0.02\n",
      "Training: Episode = 263, Length = 12, Global step = 12479, Eps: 0.02\n",
      "Training: Episode = 264, Length = 38, Global step = 12517, Eps: 0.02\n",
      "Training: Episode = 265, Length = 50, Global step = 12567, Eps: 0.02\n",
      "Training: Episode = 266, Length = 134, Global step = 12701, Eps: 0.02\n",
      "Training: Episode = 267, Length = 117, Global step = 12818, Eps: 0.02\n",
      "Training: Episode = 268, Length = 120, Global step = 12938, Eps: 0.02\n",
      "Training: Episode = 269, Length = 103, Global step = 13041, Eps: 0.02\n",
      "Training: Episode = 270, Length = 103, Global step = 13144, Eps: 0.02\n",
      "Training: Episode = 271, Length = 113, Global step = 13257, Eps: 0.02\n",
      "Training: Episode = 272, Length = 113, Global step = 13370, Eps: 0.02\n",
      "Training: Episode = 273, Length = 106, Global step = 13476, Eps: 0.02\n",
      "Training: Episode = 274, Length = 148, Global step = 13624, Eps: 0.02\n",
      "Training: Episode = 275, Length = 160, Global step = 13784, Eps: 0.02\n",
      "Training: Episode = 276, Length = 200, Global step = 13984, Eps: 0.02\n",
      "Training: Episode = 277, Length = 15, Global step = 13999, Eps: 0.02\n",
      "Training: Episode = 278, Length = 23, Global step = 14022, Eps: 0.02\n",
      "Training: Episode = 279, Length = 42, Global step = 14064, Eps: 0.02\n",
      "Training: Episode = 280, Length = 200, Global step = 14264, Eps: 0.02\n",
      "Training: Episode = 281, Length = 11, Global step = 14275, Eps: 0.02\n",
      "Training: Episode = 282, Length = 8, Global step = 14283, Eps: 0.02\n",
      "Training: Episode = 283, Length = 10, Global step = 14293, Eps: 0.02\n",
      "Training: Episode = 284, Length = 68, Global step = 14361, Eps: 0.02\n",
      "Training: Episode = 285, Length = 72, Global step = 14433, Eps: 0.02\n",
      "Training: Episode = 286, Length = 200, Global step = 14633, Eps: 0.02\n",
      "Training: Episode = 287, Length = 107, Global step = 14740, Eps: 0.02\n",
      "Training: Episode = 288, Length = 52, Global step = 14792, Eps: 0.02\n",
      "Training: Episode = 289, Length = 155, Global step = 14947, Eps: 0.02\n",
      "Training: Episode = 290, Length = 94, Global step = 15041, Eps: 0.02\n",
      "Training: Episode = 291, Length = 86, Global step = 15127, Eps: 0.02\n",
      "Training: Episode = 292, Length = 43, Global step = 15170, Eps: 0.02\n",
      "Training: Episode = 293, Length = 138, Global step = 15308, Eps: 0.02\n",
      "Training: Episode = 294, Length = 58, Global step = 15366, Eps: 0.02\n",
      "Training: Episode = 295, Length = 103, Global step = 15469, Eps: 0.02\n",
      "Training: Episode = 296, Length = 67, Global step = 15536, Eps: 0.02\n",
      "Training: Episode = 297, Length = 168, Global step = 15704, Eps: 0.02\n",
      "Training: Episode = 298, Length = 128, Global step = 15832, Eps: 0.02\n",
      "Training: Episode = 299, Length = 200, Global step = 16032, Eps: 0.02\n",
      "Training: Episode = 300, Length = 10, Global step = 16042, Eps: 0.02\n",
      "Training: Episode = 301, Length = 9, Global step = 16051, Eps: 0.02\n",
      "Training: Episode = 302, Length = 9, Global step = 16060, Eps: 0.02\n",
      "Training: Episode = 303, Length = 9, Global step = 16069, Eps: 0.02\n",
      "Training: Episode = 304, Length = 9, Global step = 16078, Eps: 0.02\n",
      "Training: Episode = 305, Length = 8, Global step = 16086, Eps: 0.02\n",
      "Training: Episode = 306, Length = 8, Global step = 16094, Eps: 0.02\n",
      "Training: Episode = 307, Length = 9, Global step = 16103, Eps: 0.02\n",
      "Training: Episode = 308, Length = 10, Global step = 16113, Eps: 0.02\n",
      "Training: Episode = 309, Length = 14, Global step = 16127, Eps: 0.02\n",
      "Training: Episode = 310, Length = 13, Global step = 16140, Eps: 0.02\n",
      "Training: Episode = 311, Length = 9, Global step = 16149, Eps: 0.02\n",
      "Training: Episode = 312, Length = 103, Global step = 16252, Eps: 0.02\n",
      "Training: Episode = 313, Length = 14, Global step = 16266, Eps: 0.02\n",
      "Training: Episode = 314, Length = 10, Global step = 16276, Eps: 0.02\n",
      "Training: Episode = 315, Length = 11, Global step = 16287, Eps: 0.02\n",
      "Training: Episode = 316, Length = 9, Global step = 16296, Eps: 0.02\n",
      "Training: Episode = 317, Length = 11, Global step = 16307, Eps: 0.02\n",
      "Training: Episode = 318, Length = 9, Global step = 16316, Eps: 0.02\n",
      "Training: Episode = 319, Length = 8, Global step = 16324, Eps: 0.02\n",
      "Training: Episode = 320, Length = 10, Global step = 16334, Eps: 0.02\n",
      "Training: Episode = 321, Length = 9, Global step = 16343, Eps: 0.02\n",
      "Training: Episode = 322, Length = 10, Global step = 16353, Eps: 0.02\n",
      "Training: Episode = 323, Length = 9, Global step = 16362, Eps: 0.02\n",
      "Training: Episode = 324, Length = 9, Global step = 16371, Eps: 0.02\n",
      "Training: Episode = 325, Length = 12, Global step = 16383, Eps: 0.02\n",
      "Training: Episode = 326, Length = 10, Global step = 16393, Eps: 0.02\n",
      "Training: Episode = 327, Length = 9, Global step = 16402, Eps: 0.02\n",
      "Training: Episode = 328, Length = 8, Global step = 16410, Eps: 0.02\n",
      "Training: Episode = 329, Length = 9, Global step = 16419, Eps: 0.02\n",
      "Training: Episode = 330, Length = 11, Global step = 16430, Eps: 0.02\n",
      "Training: Episode = 331, Length = 8, Global step = 16438, Eps: 0.02\n",
      "Training: Episode = 332, Length = 10, Global step = 16448, Eps: 0.02\n",
      "Training: Episode = 333, Length = 10, Global step = 16458, Eps: 0.02\n",
      "Training: Episode = 334, Length = 9, Global step = 16467, Eps: 0.02\n",
      "Training: Episode = 335, Length = 10, Global step = 16477, Eps: 0.02\n",
      "Training: Episode = 336, Length = 10, Global step = 16487, Eps: 0.02\n",
      "Training: Episode = 337, Length = 9, Global step = 16496, Eps: 0.02\n",
      "Training: Episode = 338, Length = 9, Global step = 16505, Eps: 0.02\n",
      "Training: Episode = 339, Length = 10, Global step = 16515, Eps: 0.02\n",
      "Training: Episode = 340, Length = 10, Global step = 16525, Eps: 0.02\n",
      "Training: Episode = 341, Length = 9, Global step = 16534, Eps: 0.02\n",
      "Training: Episode = 342, Length = 9, Global step = 16543, Eps: 0.02\n",
      "Training: Episode = 343, Length = 11, Global step = 16554, Eps: 0.02\n",
      "Training: Episode = 344, Length = 10, Global step = 16564, Eps: 0.02\n",
      "Training: Episode = 345, Length = 11, Global step = 16575, Eps: 0.02\n",
      "Training: Episode = 346, Length = 9, Global step = 16584, Eps: 0.02\n",
      "Training: Episode = 347, Length = 9, Global step = 16593, Eps: 0.02\n",
      "Training: Episode = 348, Length = 11, Global step = 16604, Eps: 0.02\n",
      "Training: Episode = 349, Length = 9, Global step = 16613, Eps: 0.02\n",
      "Training: Episode = 350, Length = 12, Global step = 16625, Eps: 0.02\n",
      "Training: Episode = 351, Length = 13, Global step = 16638, Eps: 0.02\n",
      "Training: Episode = 352, Length = 13, Global step = 16651, Eps: 0.02\n",
      "Training: Episode = 353, Length = 10, Global step = 16661, Eps: 0.02\n",
      "Training: Episode = 354, Length = 12, Global step = 16673, Eps: 0.02\n",
      "Training: Episode = 355, Length = 21, Global step = 16694, Eps: 0.02\n",
      "Training: Episode = 356, Length = 95, Global step = 16789, Eps: 0.02\n",
      "Training: Episode = 357, Length = 55, Global step = 16844, Eps: 0.02\n",
      "Training: Episode = 358, Length = 81, Global step = 16925, Eps: 0.02\n",
      "Training: Episode = 359, Length = 38, Global step = 16963, Eps: 0.02\n",
      "Training: Episode = 360, Length = 89, Global step = 17052, Eps: 0.02\n",
      "Training: Episode = 361, Length = 42, Global step = 17094, Eps: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Episode = 362, Length = 16, Global step = 17110, Eps: 0.02\n",
      "Training: Episode = 363, Length = 11, Global step = 17121, Eps: 0.02\n",
      "Training: Episode = 364, Length = 9, Global step = 17130, Eps: 0.02\n",
      "Training: Episode = 365, Length = 200, Global step = 17330, Eps: 0.02\n",
      "Training: Episode = 366, Length = 120, Global step = 17450, Eps: 0.02\n",
      "Training: Episode = 367, Length = 25, Global step = 17475, Eps: 0.02\n",
      "Training: Episode = 368, Length = 93, Global step = 17568, Eps: 0.02\n",
      "Training: Episode = 369, Length = 94, Global step = 17662, Eps: 0.02\n",
      "Training: Episode = 370, Length = 87, Global step = 17749, Eps: 0.02\n",
      "Training: Episode = 371, Length = 68, Global step = 17817, Eps: 0.02\n",
      "Training: Episode = 372, Length = 124, Global step = 17941, Eps: 0.02\n",
      "Training: Episode = 373, Length = 24, Global step = 17965, Eps: 0.02\n",
      "Training: Episode = 374, Length = 26, Global step = 17991, Eps: 0.02\n",
      "Training: Episode = 375, Length = 103, Global step = 18094, Eps: 0.02\n",
      "Training: Episode = 376, Length = 200, Global step = 18294, Eps: 0.02\n",
      "Training: Episode = 377, Length = 22, Global step = 18316, Eps: 0.02\n",
      "Training: Episode = 378, Length = 12, Global step = 18328, Eps: 0.02\n",
      "Training: Episode = 379, Length = 61, Global step = 18389, Eps: 0.02\n",
      "Training: Episode = 380, Length = 189, Global step = 18578, Eps: 0.02\n",
      "Training: Episode = 381, Length = 20, Global step = 18598, Eps: 0.02\n",
      "Training: Episode = 382, Length = 40, Global step = 18638, Eps: 0.02\n",
      "Training: Episode = 383, Length = 200, Global step = 18838, Eps: 0.02\n",
      "Training: Episode = 384, Length = 43, Global step = 18881, Eps: 0.02\n",
      "Training: Episode = 385, Length = 73, Global step = 18954, Eps: 0.02\n",
      "Training: Episode = 386, Length = 73, Global step = 19027, Eps: 0.02\n",
      "Training: Episode = 387, Length = 13, Global step = 19040, Eps: 0.02\n",
      "Training: Episode = 388, Length = 10, Global step = 19050, Eps: 0.02\n",
      "Training: Episode = 389, Length = 9, Global step = 19059, Eps: 0.02\n",
      "Training: Episode = 390, Length = 9, Global step = 19068, Eps: 0.02\n",
      "Training: Episode = 391, Length = 9, Global step = 19077, Eps: 0.02\n",
      "Training: Episode = 392, Length = 9, Global step = 19086, Eps: 0.02\n",
      "Training: Episode = 393, Length = 9, Global step = 19095, Eps: 0.02\n",
      "Training: Episode = 394, Length = 8, Global step = 19103, Eps: 0.02\n",
      "Training: Episode = 395, Length = 10, Global step = 19113, Eps: 0.02\n",
      "Training: Episode = 396, Length = 10, Global step = 19123, Eps: 0.02\n",
      "Training: Episode = 397, Length = 11, Global step = 19134, Eps: 0.02\n",
      "Training: Episode = 398, Length = 57, Global step = 19191, Eps: 0.02\n",
      "Training: Episode = 399, Length = 68, Global step = 19259, Eps: 0.02\n",
      "Training: Episode = 400, Length = 109, Global step = 19368, Eps: 0.02\n",
      "Training: Episode = 401, Length = 61, Global step = 19429, Eps: 0.02\n",
      "Training: Episode = 402, Length = 97, Global step = 19526, Eps: 0.02\n",
      "Training: Episode = 403, Length = 37, Global step = 19563, Eps: 0.02\n",
      "Training: Episode = 404, Length = 51, Global step = 19614, Eps: 0.02\n",
      "Training: Episode = 405, Length = 94, Global step = 19708, Eps: 0.02\n",
      "Training: Episode = 406, Length = 33, Global step = 19741, Eps: 0.02\n",
      "Training: Episode = 407, Length = 43, Global step = 19784, Eps: 0.02\n",
      "Training: Episode = 408, Length = 200, Global step = 19984, Eps: 0.02\n",
      "Training: Episode = 409, Length = 40, Global step = 20024, Eps: 0.02\n",
      "Training: Episode = 410, Length = 168, Global step = 20192, Eps: 0.02\n",
      "Training: Episode = 411, Length = 92, Global step = 20284, Eps: 0.02\n",
      "Training: Episode = 412, Length = 42, Global step = 20326, Eps: 0.02\n",
      "Training: Episode = 413, Length = 61, Global step = 20387, Eps: 0.02\n",
      "Training: Episode = 414, Length = 92, Global step = 20479, Eps: 0.02\n",
      "Training: Episode = 415, Length = 88, Global step = 20567, Eps: 0.02\n",
      "Training: Episode = 416, Length = 104, Global step = 20671, Eps: 0.02\n",
      "Training: Episode = 417, Length = 84, Global step = 20755, Eps: 0.02\n",
      "Training: Episode = 418, Length = 77, Global step = 20832, Eps: 0.02\n",
      "Training: Episode = 419, Length = 113, Global step = 20945, Eps: 0.02\n",
      "Training: Episode = 420, Length = 87, Global step = 21032, Eps: 0.02\n",
      "Training: Episode = 421, Length = 35, Global step = 21067, Eps: 0.02\n",
      "Training: Episode = 422, Length = 90, Global step = 21157, Eps: 0.02\n",
      "Training: Episode = 423, Length = 40, Global step = 21197, Eps: 0.02\n",
      "Training: Episode = 424, Length = 200, Global step = 21397, Eps: 0.02\n",
      "Training: Episode = 425, Length = 44, Global step = 21441, Eps: 0.02\n",
      "Training: Episode = 426, Length = 176, Global step = 21617, Eps: 0.02\n",
      "Training: Episode = 427, Length = 43, Global step = 21660, Eps: 0.02\n",
      "Training: Episode = 428, Length = 105, Global step = 21765, Eps: 0.02\n",
      "Training: Episode = 429, Length = 35, Global step = 21800, Eps: 0.02\n",
      "Training: Episode = 430, Length = 51, Global step = 21851, Eps: 0.02\n",
      "Training: Episode = 431, Length = 91, Global step = 21942, Eps: 0.02\n",
      "Training: Episode = 432, Length = 200, Global step = 22142, Eps: 0.02\n",
      "Training: Episode = 433, Length = 37, Global step = 22179, Eps: 0.02\n",
      "Training: Episode = 434, Length = 34, Global step = 22213, Eps: 0.02\n",
      "Training: Episode = 435, Length = 200, Global step = 22413, Eps: 0.02\n",
      "Training: Episode = 436, Length = 9, Global step = 22422, Eps: 0.02\n",
      "Training: Episode = 437, Length = 10, Global step = 22432, Eps: 0.02\n",
      "Training: Episode = 438, Length = 10, Global step = 22442, Eps: 0.02\n",
      "Training: Episode = 439, Length = 10, Global step = 22452, Eps: 0.02\n",
      "Training: Episode = 440, Length = 10, Global step = 22462, Eps: 0.02\n",
      "Training: Episode = 441, Length = 10, Global step = 22472, Eps: 0.02\n",
      "Training: Episode = 442, Length = 9, Global step = 22481, Eps: 0.02\n",
      "Training: Episode = 443, Length = 9, Global step = 22490, Eps: 0.02\n",
      "Training: Episode = 444, Length = 12, Global step = 22502, Eps: 0.02\n",
      "Training: Episode = 445, Length = 45, Global step = 22547, Eps: 0.02\n",
      "Training: Episode = 446, Length = 59, Global step = 22606, Eps: 0.02\n",
      "Training: Episode = 447, Length = 188, Global step = 22794, Eps: 0.02\n",
      "Training: Episode = 448, Length = 92, Global step = 22886, Eps: 0.02\n",
      "Training: Episode = 449, Length = 131, Global step = 23017, Eps: 0.02\n",
      "Training: Episode = 450, Length = 66, Global step = 23083, Eps: 0.02\n",
      "Training: Episode = 451, Length = 108, Global step = 23191, Eps: 0.02\n",
      "Training: Episode = 452, Length = 41, Global step = 23232, Eps: 0.02\n",
      "Training: Episode = 453, Length = 49, Global step = 23281, Eps: 0.02\n",
      "Training: Episode = 454, Length = 91, Global step = 23372, Eps: 0.02\n",
      "Training: Episode = 455, Length = 54, Global step = 23426, Eps: 0.02\n",
      "Training: Episode = 456, Length = 193, Global step = 23619, Eps: 0.02\n",
      "Training: Episode = 457, Length = 40, Global step = 23659, Eps: 0.02\n",
      "Training: Episode = 458, Length = 117, Global step = 23776, Eps: 0.02\n",
      "Training: Episode = 459, Length = 193, Global step = 23969, Eps: 0.02\n",
      "Training: Episode = 460, Length = 163, Global step = 24132, Eps: 0.02\n",
      "Training: Episode = 461, Length = 107, Global step = 24239, Eps: 0.02\n",
      "Training: Episode = 462, Length = 141, Global step = 24380, Eps: 0.02\n",
      "Training: Episode = 463, Length = 103, Global step = 24483, Eps: 0.02\n",
      "Training: Episode = 464, Length = 72, Global step = 24555, Eps: 0.02\n",
      "Training: Episode = 465, Length = 45, Global step = 24600, Eps: 0.02\n",
      "Training: Episode = 466, Length = 11, Global step = 24611, Eps: 0.02\n",
      "Training: Episode = 467, Length = 9, Global step = 24620, Eps: 0.02\n",
      "Training: Episode = 468, Length = 11, Global step = 24631, Eps: 0.02\n",
      "Training: Episode = 469, Length = 8, Global step = 24639, Eps: 0.02\n",
      "Training: Episode = 470, Length = 9, Global step = 24648, Eps: 0.02\n",
      "Training: Episode = 471, Length = 10, Global step = 24658, Eps: 0.02\n",
      "Training: Episode = 472, Length = 9, Global step = 24667, Eps: 0.02\n",
      "Training: Episode = 473, Length = 11, Global step = 24678, Eps: 0.02\n",
      "Training: Episode = 474, Length = 11, Global step = 24689, Eps: 0.02\n",
      "Training: Episode = 475, Length = 9, Global step = 24698, Eps: 0.02\n",
      "Training: Episode = 476, Length = 11, Global step = 24709, Eps: 0.02\n",
      "Training: Episode = 477, Length = 13, Global step = 24722, Eps: 0.02\n",
      "Training: Episode = 478, Length = 11, Global step = 24733, Eps: 0.02\n",
      "Training: Episode = 479, Length = 11, Global step = 24744, Eps: 0.02\n",
      "Training: Episode = 480, Length = 9, Global step = 24753, Eps: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Episode = 481, Length = 10, Global step = 24763, Eps: 0.02\n",
      "Training: Episode = 482, Length = 10, Global step = 24773, Eps: 0.02\n",
      "Training: Episode = 483, Length = 11, Global step = 24784, Eps: 0.02\n",
      "Training: Episode = 484, Length = 11, Global step = 24795, Eps: 0.02\n",
      "Training: Episode = 485, Length = 9, Global step = 24804, Eps: 0.02\n",
      "Training: Episode = 486, Length = 10, Global step = 24814, Eps: 0.02\n",
      "Training: Episode = 487, Length = 11, Global step = 24825, Eps: 0.02\n",
      "Training: Episode = 488, Length = 9, Global step = 24834, Eps: 0.02\n",
      "Training: Episode = 489, Length = 52, Global step = 24886, Eps: 0.02\n",
      "Training: Episode = 490, Length = 23, Global step = 24909, Eps: 0.02\n",
      "Training: Episode = 491, Length = 18, Global step = 24927, Eps: 0.02\n",
      "Training: Episode = 492, Length = 12, Global step = 24939, Eps: 0.02\n",
      "Training: Episode = 493, Length = 11, Global step = 24950, Eps: 0.02\n",
      "Training: Episode = 494, Length = 9, Global step = 24959, Eps: 0.02\n",
      "Training: Episode = 495, Length = 10, Global step = 24969, Eps: 0.02\n",
      "Training: Episode = 496, Length = 9, Global step = 24978, Eps: 0.02\n",
      "Training: Episode = 497, Length = 8, Global step = 24986, Eps: 0.02\n",
      "Training: Episode = 498, Length = 9, Global step = 24995, Eps: 0.02\n",
      "Training: Episode = 499, Length = 9, Global step = 25004, Eps: 0.02\n",
      "Training: Episode = 500, Length = 9, Global step = 25013, Eps: 0.02\n",
      "Training: Episode = 501, Length = 8, Global step = 25021, Eps: 0.02\n",
      "Training: Episode = 502, Length = 9, Global step = 25030, Eps: 0.02\n",
      "Training: Episode = 503, Length = 9, Global step = 25039, Eps: 0.02\n",
      "Training: Episode = 504, Length = 9, Global step = 25048, Eps: 0.02\n",
      "Training: Episode = 505, Length = 9, Global step = 25057, Eps: 0.02\n",
      "Training: Episode = 506, Length = 10, Global step = 25067, Eps: 0.02\n",
      "Training: Episode = 507, Length = 10, Global step = 25077, Eps: 0.02\n",
      "Training: Episode = 508, Length = 8, Global step = 25085, Eps: 0.02\n",
      "Training: Episode = 509, Length = 8, Global step = 25093, Eps: 0.02\n",
      "Training: Episode = 510, Length = 9, Global step = 25102, Eps: 0.02\n",
      "Training: Episode = 511, Length = 9, Global step = 25111, Eps: 0.02\n",
      "Training: Episode = 512, Length = 10, Global step = 25121, Eps: 0.02\n",
      "Training: Episode = 513, Length = 8, Global step = 25129, Eps: 0.02\n",
      "Training: Episode = 514, Length = 10, Global step = 25139, Eps: 0.02\n",
      "Training: Episode = 515, Length = 11, Global step = 25150, Eps: 0.02\n",
      "Training: Episode = 516, Length = 10, Global step = 25160, Eps: 0.02\n",
      "Training: Episode = 517, Length = 9, Global step = 25169, Eps: 0.02\n",
      "Training: Episode = 518, Length = 10, Global step = 25179, Eps: 0.02\n",
      "Training: Episode = 519, Length = 10, Global step = 25189, Eps: 0.02\n",
      "Training: Episode = 520, Length = 9, Global step = 25198, Eps: 0.02\n",
      "Training: Episode = 521, Length = 11, Global step = 25209, Eps: 0.02\n",
      "Training: Episode = 522, Length = 11, Global step = 25220, Eps: 0.02\n",
      "Training: Episode = 523, Length = 11, Global step = 25231, Eps: 0.02\n",
      "Training: Episode = 524, Length = 12, Global step = 25243, Eps: 0.02\n",
      "Training: Episode = 525, Length = 9, Global step = 25252, Eps: 0.02\n",
      "Training: Episode = 526, Length = 10, Global step = 25262, Eps: 0.02\n",
      "Training: Episode = 527, Length = 12, Global step = 25274, Eps: 0.02\n",
      "Training: Episode = 528, Length = 10, Global step = 25284, Eps: 0.02\n",
      "Training: Episode = 529, Length = 15, Global step = 25299, Eps: 0.02\n",
      "Training: Episode = 530, Length = 15, Global step = 25314, Eps: 0.02\n",
      "Training: Episode = 531, Length = 11, Global step = 25325, Eps: 0.02\n",
      "Training: Episode = 532, Length = 14, Global step = 25339, Eps: 0.02\n",
      "Training: Episode = 533, Length = 12, Global step = 25351, Eps: 0.02\n",
      "Training: Episode = 534, Length = 21, Global step = 25372, Eps: 0.02\n",
      "Training: Episode = 535, Length = 39, Global step = 25411, Eps: 0.02\n",
      "Training: Episode = 536, Length = 9, Global step = 25420, Eps: 0.02\n",
      "Training: Episode = 537, Length = 11, Global step = 25431, Eps: 0.02\n",
      "Training: Episode = 538, Length = 10, Global step = 25441, Eps: 0.02\n",
      "Training: Episode = 539, Length = 11, Global step = 25452, Eps: 0.02\n",
      "Training: Episode = 540, Length = 9, Global step = 25461, Eps: 0.02\n",
      "Training: Episode = 541, Length = 9, Global step = 25470, Eps: 0.02\n",
      "Training: Episode = 542, Length = 9, Global step = 25479, Eps: 0.02\n",
      "Training: Episode = 543, Length = 11, Global step = 25490, Eps: 0.02\n",
      "Training: Episode = 544, Length = 9, Global step = 25499, Eps: 0.02\n",
      "Training: Episode = 545, Length = 10, Global step = 25509, Eps: 0.02\n",
      "Training: Episode = 546, Length = 9, Global step = 25518, Eps: 0.02\n",
      "Training: Episode = 547, Length = 11, Global step = 25529, Eps: 0.02\n",
      "Training: Episode = 548, Length = 11, Global step = 25540, Eps: 0.02\n",
      "Training: Episode = 549, Length = 14, Global step = 25554, Eps: 0.02\n",
      "Training: Episode = 550, Length = 200, Global step = 25754, Eps: 0.02\n",
      "Training: Episode = 551, Length = 84, Global step = 25838, Eps: 0.02\n",
      "Training: Episode = 552, Length = 101, Global step = 25939, Eps: 0.02\n",
      "Training: Episode = 553, Length = 104, Global step = 26043, Eps: 0.02\n",
      "Training: Episode = 554, Length = 183, Global step = 26226, Eps: 0.02\n",
      "Training: Episode = 555, Length = 157, Global step = 26383, Eps: 0.02\n",
      "Training: Episode = 556, Length = 125, Global step = 26508, Eps: 0.02\n",
      "Training: Episode = 557, Length = 89, Global step = 26597, Eps: 0.02\n",
      "Training: Episode = 558, Length = 180, Global step = 26777, Eps: 0.02\n",
      "Training: Episode = 559, Length = 98, Global step = 26875, Eps: 0.02\n",
      "Training: Episode = 560, Length = 126, Global step = 27001, Eps: 0.02\n",
      "Training: Episode = 561, Length = 106, Global step = 27107, Eps: 0.02\n",
      "Training: Episode = 562, Length = 179, Global step = 27286, Eps: 0.02\n",
      "Training: Episode = 563, Length = 175, Global step = 27461, Eps: 0.02\n",
      "Training: Episode = 564, Length = 90, Global step = 27551, Eps: 0.02\n",
      "Training: Episode = 565, Length = 84, Global step = 27635, Eps: 0.02\n",
      "Training: Episode = 566, Length = 91, Global step = 27726, Eps: 0.02\n",
      "Training: Episode = 567, Length = 120, Global step = 27846, Eps: 0.02\n",
      "Training: Episode = 568, Length = 104, Global step = 27950, Eps: 0.02\n",
      "Training: Episode = 569, Length = 168, Global step = 28118, Eps: 0.02\n",
      "Training: Episode = 570, Length = 115, Global step = 28233, Eps: 0.02\n",
      "Training: Episode = 571, Length = 138, Global step = 28371, Eps: 0.02\n",
      "Training: Episode = 572, Length = 79, Global step = 28450, Eps: 0.02\n",
      "Training: Episode = 573, Length = 77, Global step = 28527, Eps: 0.02\n",
      "Training: Episode = 574, Length = 65, Global step = 28592, Eps: 0.02\n",
      "Training: Episode = 575, Length = 54, Global step = 28646, Eps: 0.02\n",
      "Training: Episode = 576, Length = 67, Global step = 28713, Eps: 0.02\n",
      "Training: Episode = 577, Length = 49, Global step = 28762, Eps: 0.02\n",
      "Training: Episode = 578, Length = 12, Global step = 28774, Eps: 0.02\n",
      "Training: Episode = 579, Length = 10, Global step = 28784, Eps: 0.02\n",
      "Training: Episode = 580, Length = 69, Global step = 28853, Eps: 0.02\n",
      "Training: Episode = 581, Length = 57, Global step = 28910, Eps: 0.02\n",
      "Training: Episode = 582, Length = 71, Global step = 28981, Eps: 0.02\n",
      "Training: Episode = 583, Length = 38, Global step = 29019, Eps: 0.02\n",
      "Training: Episode = 584, Length = 9, Global step = 29028, Eps: 0.02\n",
      "Training: Episode = 585, Length = 9, Global step = 29037, Eps: 0.02\n",
      "Training: Episode = 586, Length = 10, Global step = 29047, Eps: 0.02\n",
      "Training: Episode = 587, Length = 9, Global step = 29056, Eps: 0.02\n",
      "Training: Episode = 588, Length = 9, Global step = 29065, Eps: 0.02\n",
      "Training: Episode = 589, Length = 8, Global step = 29073, Eps: 0.02\n",
      "Training: Episode = 590, Length = 9, Global step = 29082, Eps: 0.02\n",
      "Training: Episode = 591, Length = 9, Global step = 29091, Eps: 0.02\n",
      "Training: Episode = 592, Length = 10, Global step = 29101, Eps: 0.02\n",
      "Training: Episode = 593, Length = 9, Global step = 29110, Eps: 0.02\n",
      "Training: Episode = 594, Length = 10, Global step = 29120, Eps: 0.02\n",
      "Training: Episode = 595, Length = 11, Global step = 29131, Eps: 0.02\n",
      "Training: Episode = 596, Length = 76, Global step = 29207, Eps: 0.02\n",
      "Training: Episode = 597, Length = 119, Global step = 29326, Eps: 0.02\n",
      "Training: Episode = 598, Length = 108, Global step = 29434, Eps: 0.02\n",
      "Training: Episode = 599, Length = 51, Global step = 29485, Eps: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Episode = 600, Length = 200, Global step = 29685, Eps: 0.02\n",
      "Training: Episode = 601, Length = 13, Global step = 29698, Eps: 0.02\n",
      "Training: Episode = 602, Length = 11, Global step = 29709, Eps: 0.02\n",
      "Training: Episode = 603, Length = 10, Global step = 29719, Eps: 0.02\n",
      "Training: Episode = 604, Length = 12, Global step = 29731, Eps: 0.02\n",
      "Training: Episode = 605, Length = 9, Global step = 29740, Eps: 0.02\n",
      "Training: Episode = 606, Length = 9, Global step = 29749, Eps: 0.02\n",
      "Training: Episode = 607, Length = 11, Global step = 29760, Eps: 0.02\n",
      "Training: Episode = 608, Length = 15, Global step = 29775, Eps: 0.02\n",
      "Training: Episode = 609, Length = 45, Global step = 29820, Eps: 0.02\n",
      "Training: Episode = 610, Length = 200, Global step = 30020, Eps: 0.02\n",
      "Training: Episode = 611, Length = 16, Global step = 30036, Eps: 0.02\n",
      "Training: Episode = 612, Length = 93, Global step = 30129, Eps: 0.02\n",
      "Training: Episode = 613, Length = 63, Global step = 30192, Eps: 0.02\n",
      "Training: Episode = 614, Length = 22, Global step = 30214, Eps: 0.02\n",
      "Training: Episode = 615, Length = 19, Global step = 30233, Eps: 0.02\n",
      "Training: Episode = 616, Length = 92, Global step = 30325, Eps: 0.02\n",
      "Training: Episode = 617, Length = 54, Global step = 30379, Eps: 0.02\n",
      "Training: Episode = 618, Length = 183, Global step = 30562, Eps: 0.02\n",
      "Training: Episode = 619, Length = 35, Global step = 30597, Eps: 0.02\n",
      "Training: Episode = 620, Length = 41, Global step = 30638, Eps: 0.02\n",
      "Training: Episode = 621, Length = 98, Global step = 30736, Eps: 0.02\n",
      "Training: Episode = 622, Length = 36, Global step = 30772, Eps: 0.02\n",
      "Training: Episode = 623, Length = 50, Global step = 30822, Eps: 0.02\n",
      "Training: Episode = 624, Length = 58, Global step = 30880, Eps: 0.02\n",
      "Training: Episode = 625, Length = 24, Global step = 30904, Eps: 0.02\n",
      "Training: Episode = 626, Length = 22, Global step = 30926, Eps: 0.02\n",
      "Training: Episode = 627, Length = 18, Global step = 30944, Eps: 0.02\n",
      "Training: Episode = 628, Length = 13, Global step = 30957, Eps: 0.02\n",
      "Training: Episode = 629, Length = 11, Global step = 30968, Eps: 0.02\n",
      "Training: Episode = 630, Length = 10, Global step = 30978, Eps: 0.02\n",
      "Training: Episode = 631, Length = 8, Global step = 30986, Eps: 0.02\n",
      "Training: Episode = 632, Length = 9, Global step = 30995, Eps: 0.02\n",
      "Training: Episode = 633, Length = 10, Global step = 31005, Eps: 0.02\n",
      "Training: Episode = 634, Length = 10, Global step = 31015, Eps: 0.02\n",
      "Training: Episode = 635, Length = 11, Global step = 31026, Eps: 0.02\n",
      "Training: Episode = 636, Length = 11, Global step = 31037, Eps: 0.02\n",
      "Training: Episode = 637, Length = 10, Global step = 31047, Eps: 0.02\n",
      "Training: Episode = 638, Length = 9, Global step = 31056, Eps: 0.02\n",
      "Training: Episode = 639, Length = 9, Global step = 31065, Eps: 0.02\n",
      "Training: Episode = 640, Length = 10, Global step = 31075, Eps: 0.02\n",
      "Training: Episode = 641, Length = 12, Global step = 31087, Eps: 0.02\n",
      "Training: Episode = 642, Length = 12, Global step = 31099, Eps: 0.02\n",
      "Training: Episode = 643, Length = 10, Global step = 31109, Eps: 0.02\n",
      "Training: Episode = 644, Length = 10, Global step = 31119, Eps: 0.02\n",
      "Training: Episode = 645, Length = 9, Global step = 31128, Eps: 0.02\n",
      "Training: Episode = 646, Length = 12, Global step = 31140, Eps: 0.02\n",
      "Training: Episode = 647, Length = 9, Global step = 31149, Eps: 0.02\n",
      "Training: Episode = 648, Length = 10, Global step = 31159, Eps: 0.02\n",
      "Training: Episode = 649, Length = 9, Global step = 31168, Eps: 0.02\n",
      "Training: Episode = 650, Length = 12, Global step = 31180, Eps: 0.02\n",
      "Training: Episode = 651, Length = 14, Global step = 31194, Eps: 0.02\n",
      "Training: Episode = 652, Length = 22, Global step = 31216, Eps: 0.02\n",
      "Training: Episode = 653, Length = 74, Global step = 31290, Eps: 0.02\n",
      "Training: Episode = 654, Length = 99, Global step = 31389, Eps: 0.02\n",
      "Training: Episode = 655, Length = 88, Global step = 31477, Eps: 0.02\n",
      "Training: Episode = 656, Length = 86, Global step = 31563, Eps: 0.02\n",
      "Training: Episode = 657, Length = 120, Global step = 31683, Eps: 0.02\n",
      "Training: Episode = 658, Length = 88, Global step = 31771, Eps: 0.02\n",
      "Training: Episode = 659, Length = 91, Global step = 31862, Eps: 0.02\n",
      "Training: Episode = 660, Length = 77, Global step = 31939, Eps: 0.02\n",
      "Training: Episode = 661, Length = 88, Global step = 32027, Eps: 0.02\n",
      "Training: Episode = 662, Length = 99, Global step = 32126, Eps: 0.02\n",
      "Training: Episode = 663, Length = 81, Global step = 32207, Eps: 0.02\n",
      "Training: Episode = 664, Length = 98, Global step = 32305, Eps: 0.02\n",
      "Training: Episode = 665, Length = 86, Global step = 32391, Eps: 0.02\n",
      "Training: Episode = 666, Length = 76, Global step = 32467, Eps: 0.02\n",
      "Training: Episode = 667, Length = 85, Global step = 32552, Eps: 0.02\n",
      "Training: Episode = 668, Length = 80, Global step = 32632, Eps: 0.02\n",
      "Training: Episode = 669, Length = 76, Global step = 32708, Eps: 0.02\n",
      "Training: Episode = 670, Length = 83, Global step = 32791, Eps: 0.02\n",
      "Training: Episode = 671, Length = 68, Global step = 32859, Eps: 0.02\n",
      "Training: Episode = 672, Length = 80, Global step = 32939, Eps: 0.02\n",
      "Training: Episode = 673, Length = 84, Global step = 33023, Eps: 0.02\n",
      "Training: Episode = 674, Length = 75, Global step = 33098, Eps: 0.02\n",
      "Training: Episode = 675, Length = 94, Global step = 33192, Eps: 0.02\n",
      "Training: Episode = 676, Length = 92, Global step = 33284, Eps: 0.02\n",
      "Training: Episode = 677, Length = 74, Global step = 33358, Eps: 0.02\n",
      "Training: Episode = 678, Length = 83, Global step = 33441, Eps: 0.02\n",
      "Training: Episode = 679, Length = 61, Global step = 33502, Eps: 0.02\n",
      "Training: Episode = 680, Length = 96, Global step = 33598, Eps: 0.02\n",
      "Training: Episode = 681, Length = 70, Global step = 33668, Eps: 0.02\n",
      "Training: Episode = 682, Length = 73, Global step = 33741, Eps: 0.02\n",
      "Training: Episode = 683, Length = 46, Global step = 33787, Eps: 0.02\n",
      "Training: Episode = 684, Length = 61, Global step = 33848, Eps: 0.02\n",
      "Training: Episode = 685, Length = 14, Global step = 33862, Eps: 0.02\n",
      "Training: Episode = 686, Length = 10, Global step = 33872, Eps: 0.02\n",
      "Training: Episode = 687, Length = 9, Global step = 33881, Eps: 0.02\n",
      "Training: Episode = 688, Length = 10, Global step = 33891, Eps: 0.02\n",
      "Training: Episode = 689, Length = 8, Global step = 33899, Eps: 0.02\n",
      "Training: Episode = 690, Length = 16, Global step = 33915, Eps: 0.02\n",
      "Training: Episode = 691, Length = 13, Global step = 33928, Eps: 0.02\n",
      "Training: Episode = 692, Length = 61, Global step = 33989, Eps: 0.02\n",
      "Training: Episode = 693, Length = 67, Global step = 34056, Eps: 0.02\n",
      "Training: Episode = 694, Length = 95, Global step = 34151, Eps: 0.02\n",
      "Training: Episode = 695, Length = 73, Global step = 34224, Eps: 0.02\n",
      "Training: Episode = 696, Length = 78, Global step = 34302, Eps: 0.02\n",
      "Training: Episode = 697, Length = 71, Global step = 34373, Eps: 0.02\n",
      "Training: Episode = 698, Length = 79, Global step = 34452, Eps: 0.02\n",
      "Training: Episode = 699, Length = 101, Global step = 34553, Eps: 0.02\n",
      "Training: Episode = 700, Length = 93, Global step = 34646, Eps: 0.02\n",
      "Training: Episode = 701, Length = 109, Global step = 34755, Eps: 0.02\n",
      "Training: Episode = 702, Length = 111, Global step = 34866, Eps: 0.02\n",
      "Training: Episode = 703, Length = 111, Global step = 34977, Eps: 0.02\n",
      "Training: Episode = 704, Length = 108, Global step = 35085, Eps: 0.02\n",
      "Training: Episode = 705, Length = 97, Global step = 35182, Eps: 0.02\n",
      "Training: Episode = 706, Length = 121, Global step = 35303, Eps: 0.02\n",
      "Training: Episode = 707, Length = 110, Global step = 35413, Eps: 0.02\n",
      "Training: Episode = 708, Length = 111, Global step = 35524, Eps: 0.02\n",
      "Training: Episode = 709, Length = 108, Global step = 35632, Eps: 0.02\n",
      "Training: Episode = 710, Length = 105, Global step = 35737, Eps: 0.02\n",
      "Training: Episode = 711, Length = 102, Global step = 35839, Eps: 0.02\n",
      "Training: Episode = 712, Length = 132, Global step = 35971, Eps: 0.02\n",
      "Training: Episode = 713, Length = 150, Global step = 36121, Eps: 0.02\n",
      "Training: Episode = 714, Length = 111, Global step = 36232, Eps: 0.02\n",
      "Training: Episode = 715, Length = 63, Global step = 36295, Eps: 0.02\n",
      "Training: Episode = 716, Length = 79, Global step = 36374, Eps: 0.02\n",
      "Training: Episode = 717, Length = 31, Global step = 36405, Eps: 0.02\n",
      "Training: Episode = 718, Length = 16, Global step = 36421, Eps: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Episode = 719, Length = 10, Global step = 36431, Eps: 0.02\n",
      "Training: Episode = 720, Length = 10, Global step = 36441, Eps: 0.02\n",
      "Training: Episode = 721, Length = 10, Global step = 36451, Eps: 0.02\n",
      "Training: Episode = 722, Length = 9, Global step = 36460, Eps: 0.02\n",
      "Training: Episode = 723, Length = 9, Global step = 36469, Eps: 0.02\n",
      "Training: Episode = 724, Length = 10, Global step = 36479, Eps: 0.02\n",
      "Training: Episode = 725, Length = 10, Global step = 36489, Eps: 0.02\n",
      "Training: Episode = 726, Length = 10, Global step = 36499, Eps: 0.02\n",
      "Training: Episode = 727, Length = 11, Global step = 36510, Eps: 0.02\n",
      "Training: Episode = 728, Length = 12, Global step = 36522, Eps: 0.02\n",
      "Training: Episode = 729, Length = 11, Global step = 36533, Eps: 0.02\n",
      "Training: Episode = 730, Length = 9, Global step = 36542, Eps: 0.02\n",
      "Training: Episode = 731, Length = 10, Global step = 36552, Eps: 0.02\n",
      "Training: Episode = 732, Length = 9, Global step = 36561, Eps: 0.02\n",
      "Training: Episode = 733, Length = 8, Global step = 36569, Eps: 0.02\n",
      "Training: Episode = 734, Length = 10, Global step = 36579, Eps: 0.02\n",
      "Training: Episode = 735, Length = 11, Global step = 36590, Eps: 0.02\n",
      "Training: Episode = 736, Length = 9, Global step = 36599, Eps: 0.02\n",
      "Training: Episode = 737, Length = 11, Global step = 36610, Eps: 0.02\n",
      "Training: Episode = 738, Length = 11, Global step = 36621, Eps: 0.02\n",
      "Training: Episode = 739, Length = 14, Global step = 36635, Eps: 0.02\n",
      "Training: Episode = 740, Length = 132, Global step = 36767, Eps: 0.02\n",
      "Training: Episode = 741, Length = 102, Global step = 36869, Eps: 0.02\n",
      "Training: Episode = 742, Length = 30, Global step = 36899, Eps: 0.02\n",
      "Training: Episode = 743, Length = 32, Global step = 36931, Eps: 0.02\n",
      "Training: Episode = 744, Length = 18, Global step = 36949, Eps: 0.02\n",
      "Training: Episode = 745, Length = 11, Global step = 36960, Eps: 0.02\n",
      "Training: Episode = 746, Length = 18, Global step = 36978, Eps: 0.02\n",
      "Training: Episode = 747, Length = 20, Global step = 36998, Eps: 0.02\n",
      "Training: Episode = 748, Length = 10, Global step = 37008, Eps: 0.02\n",
      "Training: Episode = 749, Length = 10, Global step = 37018, Eps: 0.02\n",
      "Training: Episode = 750, Length = 10, Global step = 37028, Eps: 0.02\n",
      "Training: Episode = 751, Length = 10, Global step = 37038, Eps: 0.02\n",
      "Training: Episode = 752, Length = 11, Global step = 37049, Eps: 0.02\n",
      "Training: Episode = 753, Length = 9, Global step = 37058, Eps: 0.02\n",
      "Training: Episode = 754, Length = 10, Global step = 37068, Eps: 0.02\n",
      "Training: Episode = 755, Length = 10, Global step = 37078, Eps: 0.02\n",
      "Training: Episode = 756, Length = 10, Global step = 37088, Eps: 0.02\n",
      "Training: Episode = 757, Length = 10, Global step = 37098, Eps: 0.02\n",
      "Training: Episode = 758, Length = 9, Global step = 37107, Eps: 0.02\n",
      "Training: Episode = 759, Length = 9, Global step = 37116, Eps: 0.02\n",
      "Training: Episode = 760, Length = 10, Global step = 37126, Eps: 0.02\n",
      "Training: Episode = 761, Length = 10, Global step = 37136, Eps: 0.02\n",
      "Training: Episode = 762, Length = 9, Global step = 37145, Eps: 0.02\n",
      "Training: Episode = 763, Length = 12, Global step = 37157, Eps: 0.02\n",
      "Training: Episode = 764, Length = 11, Global step = 37168, Eps: 0.02\n",
      "Training: Episode = 765, Length = 9, Global step = 37177, Eps: 0.02\n",
      "Training: Episode = 766, Length = 8, Global step = 37185, Eps: 0.02\n",
      "Training: Episode = 767, Length = 10, Global step = 37195, Eps: 0.02\n",
      "Training: Episode = 768, Length = 11, Global step = 37206, Eps: 0.02\n",
      "Training: Episode = 769, Length = 9, Global step = 37215, Eps: 0.02\n",
      "Training: Episode = 770, Length = 14, Global step = 37229, Eps: 0.02\n",
      "Training: Episode = 771, Length = 14, Global step = 37243, Eps: 0.02\n",
      "Training: Episode = 772, Length = 55, Global step = 37298, Eps: 0.02\n",
      "Training: Episode = 773, Length = 200, Global step = 37498, Eps: 0.02\n",
      "Training: Episode = 774, Length = 10, Global step = 37508, Eps: 0.02\n",
      "Training: Episode = 775, Length = 13, Global step = 37521, Eps: 0.02\n",
      "Training: Episode = 776, Length = 10, Global step = 37531, Eps: 0.02\n",
      "Training: Episode = 777, Length = 11, Global step = 37542, Eps: 0.02\n",
      "Training: Episode = 778, Length = 200, Global step = 37742, Eps: 0.02\n",
      "Training: Episode = 779, Length = 200, Global step = 37942, Eps: 0.02\n",
      "Training: Episode = 780, Length = 198, Global step = 38140, Eps: 0.02\n",
      "Training: Episode = 781, Length = 43, Global step = 38183, Eps: 0.02\n",
      "Training: Episode = 782, Length = 182, Global step = 38365, Eps: 0.02\n",
      "Training: Episode = 783, Length = 200, Global step = 38565, Eps: 0.02\n",
      "Training: Episode = 784, Length = 172, Global step = 38737, Eps: 0.02\n",
      "Training: Episode = 785, Length = 58, Global step = 38795, Eps: 0.02\n",
      "Training: Episode = 786, Length = 11, Global step = 38806, Eps: 0.02\n",
      "Training: Episode = 787, Length = 9, Global step = 38815, Eps: 0.02\n",
      "Training: Episode = 788, Length = 9, Global step = 38824, Eps: 0.02\n",
      "Training: Episode = 789, Length = 9, Global step = 38833, Eps: 0.02\n",
      "Training: Episode = 790, Length = 10, Global step = 38843, Eps: 0.02\n",
      "Training: Episode = 791, Length = 8, Global step = 38851, Eps: 0.02\n",
      "Training: Episode = 792, Length = 10, Global step = 38861, Eps: 0.02\n",
      "Training: Episode = 793, Length = 10, Global step = 38871, Eps: 0.02\n",
      "Training: Episode = 794, Length = 10, Global step = 38881, Eps: 0.02\n",
      "Training: Episode = 795, Length = 9, Global step = 38890, Eps: 0.02\n",
      "Training: Episode = 796, Length = 10, Global step = 38900, Eps: 0.02\n",
      "Training: Episode = 797, Length = 8, Global step = 38908, Eps: 0.02\n",
      "Training: Episode = 798, Length = 12, Global step = 38920, Eps: 0.02\n",
      "Training: Episode = 799, Length = 12, Global step = 38932, Eps: 0.02\n",
      "Training: Episode = 800, Length = 47, Global step = 38979, Eps: 0.02\n",
      "Training: Episode = 801, Length = 97, Global step = 39076, Eps: 0.02\n",
      "Training: Episode = 802, Length = 200, Global step = 39276, Eps: 0.02\n",
      "Training: Episode = 803, Length = 174, Global step = 39450, Eps: 0.02\n",
      "Training: Episode = 804, Length = 200, Global step = 39650, Eps: 0.02\n",
      "Training: Episode = 805, Length = 200, Global step = 39850, Eps: 0.02\n",
      "Training: Episode = 806, Length = 125, Global step = 39975, Eps: 0.02\n",
      "Training: Episode = 807, Length = 200, Global step = 40175, Eps: 0.02\n",
      "Training: Episode = 808, Length = 188, Global step = 40363, Eps: 0.02\n",
      "Training: Episode = 809, Length = 164, Global step = 40527, Eps: 0.02\n",
      "Training: Episode = 810, Length = 153, Global step = 40680, Eps: 0.02\n",
      "Training: Episode = 811, Length = 29, Global step = 40709, Eps: 0.02\n",
      "Training: Episode = 812, Length = 23, Global step = 40732, Eps: 0.02\n",
      "Training: Episode = 813, Length = 78, Global step = 40810, Eps: 0.02\n",
      "Training: Episode = 814, Length = 38, Global step = 40848, Eps: 0.02\n",
      "Training: Episode = 815, Length = 14, Global step = 40862, Eps: 0.02\n",
      "Training: Episode = 816, Length = 39, Global step = 40901, Eps: 0.02\n",
      "Training: Episode = 817, Length = 10, Global step = 40911, Eps: 0.02\n",
      "Training: Episode = 818, Length = 8, Global step = 40919, Eps: 0.02\n",
      "Training: Episode = 819, Length = 10, Global step = 40929, Eps: 0.02\n",
      "Training: Episode = 820, Length = 12, Global step = 40941, Eps: 0.02\n",
      "Training: Episode = 821, Length = 16, Global step = 40957, Eps: 0.02\n",
      "Training: Episode = 822, Length = 27, Global step = 40984, Eps: 0.02\n",
      "Training: Episode = 823, Length = 38, Global step = 41022, Eps: 0.02\n",
      "Training: Episode = 824, Length = 11, Global step = 41033, Eps: 0.02\n",
      "Training: Episode = 825, Length = 12, Global step = 41045, Eps: 0.02\n",
      "Training: Episode = 826, Length = 10, Global step = 41055, Eps: 0.02\n",
      "Training: Episode = 827, Length = 24, Global step = 41079, Eps: 0.02\n",
      "Training: Episode = 828, Length = 12, Global step = 41091, Eps: 0.02\n",
      "Training: Episode = 829, Length = 15, Global step = 41106, Eps: 0.02\n",
      "Training: Episode = 830, Length = 199, Global step = 41305, Eps: 0.02\n",
      "Training: Episode = 831, Length = 147, Global step = 41452, Eps: 0.02\n",
      "Training: Episode = 832, Length = 39, Global step = 41491, Eps: 0.02\n",
      "Training: Episode = 833, Length = 117, Global step = 41608, Eps: 0.02\n",
      "Training: Episode = 834, Length = 44, Global step = 41652, Eps: 0.02\n",
      "Training: Episode = 835, Length = 11, Global step = 41663, Eps: 0.02\n",
      "Training: Episode = 836, Length = 36, Global step = 41699, Eps: 0.02\n",
      "Training: Episode = 837, Length = 78, Global step = 41777, Eps: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Episode = 838, Length = 129, Global step = 41906, Eps: 0.02\n",
      "Training: Episode = 839, Length = 139, Global step = 42045, Eps: 0.02\n",
      "Training: Episode = 840, Length = 91, Global step = 42136, Eps: 0.02\n",
      "Training: Episode = 841, Length = 95, Global step = 42231, Eps: 0.02\n",
      "Training: Episode = 842, Length = 95, Global step = 42326, Eps: 0.02\n",
      "Training: Episode = 843, Length = 99, Global step = 42425, Eps: 0.02\n",
      "Training: Episode = 844, Length = 83, Global step = 42508, Eps: 0.02\n",
      "Training: Episode = 845, Length = 87, Global step = 42595, Eps: 0.02\n",
      "Training: Episode = 846, Length = 18, Global step = 42613, Eps: 0.02\n",
      "Training: Episode = 847, Length = 11, Global step = 42624, Eps: 0.02\n",
      "Training: Episode = 848, Length = 10, Global step = 42634, Eps: 0.02\n",
      "Training: Episode = 849, Length = 10, Global step = 42644, Eps: 0.02\n",
      "Training: Episode = 850, Length = 10, Global step = 42654, Eps: 0.02\n",
      "Training: Episode = 851, Length = 8, Global step = 42662, Eps: 0.02\n",
      "Training: Episode = 852, Length = 11, Global step = 42673, Eps: 0.02\n",
      "Training: Episode = 853, Length = 8, Global step = 42681, Eps: 0.02\n",
      "Training: Episode = 854, Length = 68, Global step = 42749, Eps: 0.02\n",
      "Training: Episode = 855, Length = 36, Global step = 42785, Eps: 0.02\n",
      "Training: Episode = 856, Length = 9, Global step = 42794, Eps: 0.02\n",
      "Training: Episode = 857, Length = 11, Global step = 42805, Eps: 0.02\n",
      "Training: Episode = 858, Length = 10, Global step = 42815, Eps: 0.02\n",
      "Training: Episode = 859, Length = 52, Global step = 42867, Eps: 0.02\n",
      "Training: Episode = 860, Length = 10, Global step = 42877, Eps: 0.02\n",
      "Training: Episode = 861, Length = 8, Global step = 42885, Eps: 0.02\n",
      "Training: Episode = 862, Length = 9, Global step = 42894, Eps: 0.02\n",
      "Training: Episode = 863, Length = 10, Global step = 42904, Eps: 0.02\n",
      "Training: Episode = 864, Length = 11, Global step = 42915, Eps: 0.02\n",
      "Training: Episode = 865, Length = 12, Global step = 42927, Eps: 0.02\n",
      "Training: Episode = 866, Length = 13, Global step = 42940, Eps: 0.02\n",
      "Training: Episode = 867, Length = 13, Global step = 42953, Eps: 0.02\n",
      "Training: Episode = 868, Length = 15, Global step = 42968, Eps: 0.02\n",
      "Training: Episode = 869, Length = 65, Global step = 43033, Eps: 0.02\n",
      "Training: Episode = 870, Length = 20, Global step = 43053, Eps: 0.02\n",
      "Training: Episode = 871, Length = 70, Global step = 43123, Eps: 0.02\n",
      "Training: Episode = 872, Length = 11, Global step = 43134, Eps: 0.02\n",
      "Training: Episode = 873, Length = 10, Global step = 43144, Eps: 0.02\n",
      "Training: Episode = 874, Length = 96, Global step = 43240, Eps: 0.02\n",
      "Training: Episode = 875, Length = 11, Global step = 43251, Eps: 0.02\n",
      "Training: Episode = 876, Length = 15, Global step = 43266, Eps: 0.02\n",
      "Training: Episode = 877, Length = 51, Global step = 43317, Eps: 0.02\n",
      "Training: Episode = 878, Length = 16, Global step = 43333, Eps: 0.02\n",
      "Training: Episode = 879, Length = 28, Global step = 43361, Eps: 0.02\n",
      "Training: Episode = 880, Length = 56, Global step = 43417, Eps: 0.02\n",
      "Training: Episode = 881, Length = 46, Global step = 43463, Eps: 0.02\n",
      "Training: Episode = 882, Length = 71, Global step = 43534, Eps: 0.02\n",
      "Training: Episode = 883, Length = 13, Global step = 43547, Eps: 0.02\n",
      "Training: Episode = 884, Length = 16, Global step = 43563, Eps: 0.02\n",
      "Training: Episode = 885, Length = 25, Global step = 43588, Eps: 0.02\n",
      "Training: Episode = 886, Length = 36, Global step = 43624, Eps: 0.02\n",
      "Training: Episode = 887, Length = 23, Global step = 43647, Eps: 0.02\n",
      "Training: Episode = 888, Length = 60, Global step = 43707, Eps: 0.02\n",
      "Training: Episode = 889, Length = 18, Global step = 43725, Eps: 0.02\n",
      "Training: Episode = 890, Length = 60, Global step = 43785, Eps: 0.02\n",
      "Training: Episode = 891, Length = 70, Global step = 43855, Eps: 0.02\n",
      "Training: Episode = 892, Length = 14, Global step = 43869, Eps: 0.02\n",
      "Training: Episode = 893, Length = 30, Global step = 43899, Eps: 0.02\n",
      "Training: Episode = 894, Length = 49, Global step = 43948, Eps: 0.02\n",
      "Training: Episode = 895, Length = 21, Global step = 43969, Eps: 0.02\n",
      "Training: Episode = 896, Length = 46, Global step = 44015, Eps: 0.02\n",
      "Training: Episode = 897, Length = 17, Global step = 44032, Eps: 0.02\n",
      "Training: Episode = 898, Length = 17, Global step = 44049, Eps: 0.02\n",
      "Training: Episode = 899, Length = 37, Global step = 44086, Eps: 0.02\n",
      "Training: Episode = 900, Length = 59, Global step = 44145, Eps: 0.02\n",
      "Training: Episode = 901, Length = 24, Global step = 44169, Eps: 0.02\n",
      "Training: Episode = 902, Length = 69, Global step = 44238, Eps: 0.02\n",
      "Training: Episode = 903, Length = 12, Global step = 44250, Eps: 0.02\n",
      "Training: Episode = 904, Length = 11, Global step = 44261, Eps: 0.02\n",
      "Training: Episode = 905, Length = 16, Global step = 44277, Eps: 0.02\n",
      "Training: Episode = 906, Length = 22, Global step = 44299, Eps: 0.02\n",
      "Training: Episode = 907, Length = 19, Global step = 44318, Eps: 0.02\n",
      "Training: Episode = 908, Length = 133, Global step = 44451, Eps: 0.02\n",
      "Training: Episode = 909, Length = 23, Global step = 44474, Eps: 0.02\n",
      "Training: Episode = 910, Length = 119, Global step = 44593, Eps: 0.02\n",
      "Training: Episode = 911, Length = 19, Global step = 44612, Eps: 0.02\n",
      "Training: Episode = 912, Length = 103, Global step = 44715, Eps: 0.02\n",
      "Training: Episode = 913, Length = 48, Global step = 44763, Eps: 0.02\n",
      "Training: Episode = 914, Length = 10, Global step = 44773, Eps: 0.02\n",
      "Training: Episode = 915, Length = 11, Global step = 44784, Eps: 0.02\n",
      "Training: Episode = 916, Length = 9, Global step = 44793, Eps: 0.02\n",
      "Training: Episode = 917, Length = 13, Global step = 44806, Eps: 0.02\n",
      "Training: Episode = 918, Length = 120, Global step = 44926, Eps: 0.02\n",
      "Training: Episode = 919, Length = 23, Global step = 44949, Eps: 0.02\n",
      "Training: Episode = 920, Length = 144, Global step = 45093, Eps: 0.02\n",
      "Training: Episode = 921, Length = 149, Global step = 45242, Eps: 0.02\n",
      "Training: Episode = 922, Length = 31, Global step = 45273, Eps: 0.02\n",
      "Training: Episode = 923, Length = 121, Global step = 45394, Eps: 0.02\n",
      "Training: Episode = 924, Length = 13, Global step = 45407, Eps: 0.02\n",
      "Training: Episode = 925, Length = 71, Global step = 45478, Eps: 0.02\n",
      "Training: Episode = 926, Length = 31, Global step = 45509, Eps: 0.02\n",
      "Training: Episode = 927, Length = 87, Global step = 45596, Eps: 0.02\n",
      "Training: Episode = 928, Length = 16, Global step = 45612, Eps: 0.02\n",
      "Training: Episode = 929, Length = 74, Global step = 45686, Eps: 0.02\n",
      "Training: Episode = 930, Length = 55, Global step = 45741, Eps: 0.02\n",
      "Training: Episode = 931, Length = 92, Global step = 45833, Eps: 0.02\n",
      "Training: Episode = 932, Length = 21, Global step = 45854, Eps: 0.02\n",
      "Training: Episode = 933, Length = 29, Global step = 45883, Eps: 0.02\n",
      "Training: Episode = 934, Length = 19, Global step = 45902, Eps: 0.02\n",
      "Training: Episode = 935, Length = 21, Global step = 45923, Eps: 0.02\n",
      "Training: Episode = 936, Length = 30, Global step = 45953, Eps: 0.02\n",
      "Training: Episode = 937, Length = 87, Global step = 46040, Eps: 0.02\n",
      "Training: Episode = 938, Length = 42, Global step = 46082, Eps: 0.02\n",
      "Training: Episode = 939, Length = 83, Global step = 46165, Eps: 0.02\n",
      "Training: Episode = 940, Length = 23, Global step = 46188, Eps: 0.02\n",
      "Training: Episode = 941, Length = 109, Global step = 46297, Eps: 0.02\n",
      "Training: Episode = 942, Length = 23, Global step = 46320, Eps: 0.02\n",
      "Training: Episode = 943, Length = 93, Global step = 46413, Eps: 0.02\n",
      "Training: Episode = 944, Length = 40, Global step = 46453, Eps: 0.02\n",
      "Training: Episode = 945, Length = 82, Global step = 46535, Eps: 0.02\n",
      "Training: Episode = 946, Length = 29, Global step = 46564, Eps: 0.02\n",
      "Training: Episode = 947, Length = 102, Global step = 46666, Eps: 0.02\n",
      "Training: Episode = 948, Length = 28, Global step = 46694, Eps: 0.02\n",
      "Training: Episode = 949, Length = 88, Global step = 46782, Eps: 0.02\n",
      "Training: Episode = 950, Length = 86, Global step = 46868, Eps: 0.02\n",
      "Training: Episode = 951, Length = 78, Global step = 46946, Eps: 0.02\n",
      "Training: Episode = 952, Length = 42, Global step = 46988, Eps: 0.02\n",
      "Training: Episode = 953, Length = 60, Global step = 47048, Eps: 0.02\n",
      "Training: Episode = 954, Length = 77, Global step = 47125, Eps: 0.02\n",
      "Training: Episode = 955, Length = 49, Global step = 47174, Eps: 0.02\n",
      "Training: Episode = 956, Length = 65, Global step = 47239, Eps: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Episode = 957, Length = 82, Global step = 47321, Eps: 0.02\n",
      "Training: Episode = 958, Length = 134, Global step = 47455, Eps: 0.02\n",
      "Training: Episode = 959, Length = 92, Global step = 47547, Eps: 0.02\n",
      "Training: Episode = 960, Length = 84, Global step = 47631, Eps: 0.02\n",
      "Training: Episode = 961, Length = 74, Global step = 47705, Eps: 0.02\n",
      "Training: Episode = 962, Length = 49, Global step = 47754, Eps: 0.02\n",
      "Training: Episode = 963, Length = 49, Global step = 47803, Eps: 0.02\n",
      "Training: Episode = 964, Length = 30, Global step = 47833, Eps: 0.02\n",
      "Training: Episode = 965, Length = 12, Global step = 47845, Eps: 0.02\n",
      "Training: Episode = 966, Length = 9, Global step = 47854, Eps: 0.02\n",
      "Training: Episode = 967, Length = 10, Global step = 47864, Eps: 0.02\n",
      "Training: Episode = 968, Length = 9, Global step = 47873, Eps: 0.02\n",
      "Training: Episode = 969, Length = 9, Global step = 47882, Eps: 0.02\n",
      "Training: Episode = 970, Length = 9, Global step = 47891, Eps: 0.02\n",
      "Training: Episode = 971, Length = 10, Global step = 47901, Eps: 0.02\n",
      "Training: Episode = 972, Length = 49, Global step = 47950, Eps: 0.02\n",
      "Training: Episode = 973, Length = 32, Global step = 47982, Eps: 0.02\n",
      "Training: Episode = 974, Length = 11, Global step = 47993, Eps: 0.02\n",
      "Training: Episode = 975, Length = 10, Global step = 48003, Eps: 0.02\n",
      "Training: Episode = 976, Length = 11, Global step = 48014, Eps: 0.02\n",
      "Training: Episode = 977, Length = 10, Global step = 48024, Eps: 0.02\n",
      "Training: Episode = 978, Length = 10, Global step = 48034, Eps: 0.02\n",
      "Training: Episode = 979, Length = 10, Global step = 48044, Eps: 0.02\n",
      "Training: Episode = 980, Length = 9, Global step = 48053, Eps: 0.02\n",
      "Training: Episode = 981, Length = 9, Global step = 48062, Eps: 0.02\n",
      "Training: Episode = 982, Length = 9, Global step = 48071, Eps: 0.02\n",
      "Training: Episode = 983, Length = 11, Global step = 48082, Eps: 0.02\n",
      "Training: Episode = 984, Length = 10, Global step = 48092, Eps: 0.02\n",
      "Training: Episode = 985, Length = 8, Global step = 48100, Eps: 0.02\n",
      "Training: Episode = 986, Length = 9, Global step = 48109, Eps: 0.02\n",
      "Training: Episode = 987, Length = 10, Global step = 48119, Eps: 0.02\n",
      "Training: Episode = 988, Length = 12, Global step = 48131, Eps: 0.02\n",
      "Training: Episode = 989, Length = 12, Global step = 48143, Eps: 0.02\n",
      "Training: Episode = 990, Length = 13, Global step = 48156, Eps: 0.02\n",
      "Training: Episode = 991, Length = 34, Global step = 48190, Eps: 0.02\n",
      "Training: Episode = 992, Length = 67, Global step = 48257, Eps: 0.02\n",
      "Training: Episode = 993, Length = 40, Global step = 48297, Eps: 0.02\n",
      "Training: Episode = 994, Length = 124, Global step = 48421, Eps: 0.02\n",
      "Training: Episode = 995, Length = 32, Global step = 48453, Eps: 0.02\n",
      "Training: Episode = 996, Length = 59, Global step = 48512, Eps: 0.02\n",
      "Training: Episode = 997, Length = 88, Global step = 48600, Eps: 0.02\n",
      "Training: Episode = 998, Length = 55, Global step = 48655, Eps: 0.02\n",
      "Training: Episode = 999, Length = 102, Global step = 48757, Eps: 0.02\n",
      "Training: Episode = 1000, Length = 36, Global step = 48793, Eps: 0.02\n",
      "Training: Episode = 1001, Length = 77, Global step = 48870, Eps: 0.02\n",
      "Training: Episode = 1002, Length = 57, Global step = 48927, Eps: 0.02\n",
      "Training: Episode = 1003, Length = 169, Global step = 49096, Eps: 0.02\n",
      "Training: Episode = 1004, Length = 33, Global step = 49129, Eps: 0.02\n",
      "Training: Episode = 1005, Length = 200, Global step = 49329, Eps: 0.02\n",
      "Training: Episode = 1006, Length = 30, Global step = 49359, Eps: 0.02\n",
      "Training: Episode = 1007, Length = 130, Global step = 49489, Eps: 0.02\n",
      "Training: Episode = 1008, Length = 51, Global step = 49540, Eps: 0.02\n",
      "Training: Episode = 1009, Length = 148, Global step = 49688, Eps: 0.02\n",
      "Training: Episode = 1010, Length = 24, Global step = 49712, Eps: 0.02\n",
      "Training: Episode = 1011, Length = 32, Global step = 49744, Eps: 0.02\n",
      "Training: Episode = 1012, Length = 35, Global step = 49779, Eps: 0.02\n",
      "Training: Episode = 1013, Length = 200, Global step = 49979, Eps: 0.02\n",
      "Training: Episode = 1014, Length = 131, Global step = 50110, Eps: 0.02\n",
      "Training: Episode = 1015, Length = 116, Global step = 50226, Eps: 0.02\n",
      "Training: Episode = 1016, Length = 34, Global step = 50260, Eps: 0.02\n",
      "Training: Episode = 1017, Length = 49, Global step = 50309, Eps: 0.02\n",
      "Training: Episode = 1018, Length = 59, Global step = 50368, Eps: 0.02\n",
      "Training: Episode = 1019, Length = 89, Global step = 50457, Eps: 0.02\n",
      "Training: Episode = 1020, Length = 106, Global step = 50563, Eps: 0.02\n",
      "Training: Episode = 1021, Length = 152, Global step = 50715, Eps: 0.02\n",
      "Training: Episode = 1022, Length = 12, Global step = 50727, Eps: 0.02\n",
      "Training: Episode = 1023, Length = 19, Global step = 50746, Eps: 0.02\n",
      "Training: Episode = 1024, Length = 17, Global step = 50763, Eps: 0.02\n",
      "Training: Episode = 1025, Length = 16, Global step = 50779, Eps: 0.02\n",
      "Training: Episode = 1026, Length = 11, Global step = 50790, Eps: 0.02\n",
      "Training: Episode = 1027, Length = 19, Global step = 50809, Eps: 0.02\n",
      "Training: Episode = 1028, Length = 11, Global step = 50820, Eps: 0.02\n",
      "Training: Episode = 1029, Length = 15, Global step = 50835, Eps: 0.02\n",
      "Training: Episode = 1030, Length = 20, Global step = 50855, Eps: 0.02\n",
      "Training: Episode = 1031, Length = 19, Global step = 50874, Eps: 0.02\n",
      "Training: Episode = 1032, Length = 29, Global step = 50903, Eps: 0.02\n",
      "Training: Episode = 1033, Length = 92, Global step = 50995, Eps: 0.02\n",
      "Training: Episode = 1034, Length = 52, Global step = 51047, Eps: 0.02\n",
      "Training: Episode = 1035, Length = 63, Global step = 51110, Eps: 0.02\n",
      "Training: Episode = 1036, Length = 128, Global step = 51238, Eps: 0.02\n",
      "Training: Episode = 1037, Length = 22, Global step = 51260, Eps: 0.02\n",
      "Training: Episode = 1038, Length = 20, Global step = 51280, Eps: 0.02\n",
      "Training: Episode = 1039, Length = 24, Global step = 51304, Eps: 0.02\n",
      "Training: Episode = 1040, Length = 88, Global step = 51392, Eps: 0.02\n",
      "Training: Episode = 1041, Length = 16, Global step = 51408, Eps: 0.02\n",
      "Training: Episode = 1042, Length = 20, Global step = 51428, Eps: 0.02\n",
      "Training: Episode = 1043, Length = 19, Global step = 51447, Eps: 0.02\n",
      "Training: Episode = 1044, Length = 15, Global step = 51462, Eps: 0.02\n",
      "Training: Episode = 1045, Length = 34, Global step = 51496, Eps: 0.02\n",
      "Training: Episode = 1046, Length = 131, Global step = 51627, Eps: 0.02\n",
      "Training: Episode = 1047, Length = 23, Global step = 51650, Eps: 0.02\n",
      "Training: Episode = 1048, Length = 17, Global step = 51667, Eps: 0.02\n",
      "Training: Episode = 1049, Length = 84, Global step = 51751, Eps: 0.02\n",
      "Training: Episode = 1050, Length = 104, Global step = 51855, Eps: 0.02\n",
      "Training: Episode = 1051, Length = 17, Global step = 51872, Eps: 0.02\n",
      "Training: Episode = 1052, Length = 28, Global step = 51900, Eps: 0.02\n",
      "Training: Episode = 1053, Length = 59, Global step = 51959, Eps: 0.02\n",
      "Training: Episode = 1054, Length = 21, Global step = 51980, Eps: 0.02\n",
      "Training: Episode = 1055, Length = 110, Global step = 52090, Eps: 0.02\n",
      "Training: Episode = 1056, Length = 20, Global step = 52110, Eps: 0.02\n",
      "Training: Episode = 1057, Length = 24, Global step = 52134, Eps: 0.02\n",
      "Training: Episode = 1058, Length = 68, Global step = 52202, Eps: 0.02\n",
      "Training: Episode = 1059, Length = 14, Global step = 52216, Eps: 0.02\n",
      "Training: Episode = 1060, Length = 45, Global step = 52261, Eps: 0.02\n",
      "Training: Episode = 1061, Length = 14, Global step = 52275, Eps: 0.02\n",
      "Training: Episode = 1062, Length = 12, Global step = 52287, Eps: 0.02\n",
      "Training: Episode = 1063, Length = 10, Global step = 52297, Eps: 0.02\n",
      "Training: Episode = 1064, Length = 11, Global step = 52308, Eps: 0.02\n",
      "Training: Episode = 1065, Length = 11, Global step = 52319, Eps: 0.02\n",
      "Training: Episode = 1066, Length = 10, Global step = 52329, Eps: 0.02\n",
      "Training: Episode = 1067, Length = 11, Global step = 52340, Eps: 0.02\n",
      "Training: Episode = 1068, Length = 10, Global step = 52350, Eps: 0.02\n",
      "Training: Episode = 1069, Length = 53, Global step = 52403, Eps: 0.02\n",
      "Training: Episode = 1070, Length = 137, Global step = 52540, Eps: 0.02\n",
      "Training: Episode = 1071, Length = 35, Global step = 52575, Eps: 0.02\n",
      "Training: Episode = 1072, Length = 114, Global step = 52689, Eps: 0.02\n",
      "Training: Episode = 1073, Length = 26, Global step = 52715, Eps: 0.02\n",
      "Training: Episode = 1074, Length = 102, Global step = 52817, Eps: 0.02\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: Episode = 1075, Length = 24, Global step = 52841, Eps: 0.02\n",
      "Training: Episode = 1076, Length = 106, Global step = 52947, Eps: 0.02\n",
      "Training: Episode = 1077, Length = 18, Global step = 52965, Eps: 0.02\n",
      "Training: Episode = 1078, Length = 21, Global step = 52986, Eps: 0.02\n",
      "Training: Episode = 1079, Length = 165, Global step = 53151, Eps: 0.02\n",
      "Training: Episode = 1080, Length = 16, Global step = 53167, Eps: 0.02\n",
      "Training: Episode = 1081, Length = 20, Global step = 53187, Eps: 0.02\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-f6cea5b7a4ce>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nStarting training...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdqn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nFinished training...\\nCheck out some demonstrations\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-8c4df7452bdf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, episodes_num)\u001b[0m\n\u001b[1;32m    184\u001b[0m                         \u001b[0mst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m                     \u001b[0mmax_Q\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m                     \u001b[0mbatch_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m                     \u001b[0;31m# for st, act, rwd, nst, d in replay_batch:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m                     \u001b[0;31m#     if d:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1238\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m       \u001b[0;31m# Creates a `tf.data.Dataset` and handles batch and epoch iteration.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1240\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1241\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    326\u001b[0m     \u001b[0;31m# trigger the next permutation. On the other hand, too many simultaneous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[0;31m# shuffles can contend on a hardware level and degrade all performance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1619\u001b[0m     \"\"\"\n\u001b[1;32m   1620\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1621\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1622\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1623\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   3975\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3976\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3977\u001b[0;31m     self._map_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m   3978\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3979\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3219\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3220\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3221\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2529\u001b[0m       \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputs\u001b[0m \u001b[0mto\u001b[0m \u001b[0mspecialize\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2530\u001b[0m     \"\"\"\n\u001b[0;32m-> 2531\u001b[0;31m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[1;32m   2532\u001b[0m         *args, **kwargs)\n\u001b[1;32m   2533\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2494\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2495\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2496\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2497\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2498\u001b[0m         \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   2775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2776\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2777\u001b[0;31m       \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2778\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2779\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   2655\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 2657\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   2658\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2659\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    983\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m       \u001b[0;31m# TensorArrays and `None`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 985\u001b[0;31m       func_outputs = nest.map_structure(convert, func_outputs,\n\u001b[0m\u001b[1;32m    986\u001b[0m                                         expand_composites=True)\n\u001b[1;32m    987\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    615\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 617\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    618\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    619\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    943\u001b[0m               (str(python_func), type(x)))\n\u001b[1;32m    944\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0madd_control_dependencies\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 945\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeps_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmark_as_return\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    946\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/auto_control_deps.py\u001b[0m in \u001b[0;36mmark_as_return\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m# of a new identity operation that the stateful operations definitely don't\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m     \u001b[0;31m# depend on.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0mtensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_returned_tensors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    178\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[0;31m# variables. Variables have correct handle data when graph building.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_to_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m   \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen_array_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midentity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m   \u001b[0;31m# Propagate handle data for happier shape inference for resource variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_handle_data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_array_ops.py\u001b[0m in \u001b[0;36midentity\u001b[0;34m(input, name)\u001b[0m\n\u001b[1;32m   3898\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3899\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3900\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   3901\u001b[0m         \"Identity\", input=input, name=name)\n\u001b[1;32m   3902\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    740\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 742\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    743\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    744\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    591\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m       \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 593\u001b[0;31m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    594\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    595\u001b[0m         compute_device)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3317\u001b[0m     \u001b[0;31m# Session.run call cannot occur between creating and mutating the op.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3318\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3319\u001b[0;31m       ret = Operation(\n\u001b[0m\u001b[1;32m   3320\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3321\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   1814\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mop_def\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1815\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1816\u001b[0;31m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0m\u001b[1;32m   1817\u001b[0m                                 control_input_ops, op_def)\n\u001b[1;32m   1818\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1636\u001b[0m                                         [t._as_tf_output() for t in op_input])\n\u001b[1;32m   1637\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1638\u001b[0;31m       \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_AddInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_as_tf_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1640\u001b[0m   \u001b[0;31m# Add control inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create and initialize the model\n",
    "# dqn = DQN('CartPole-v0')\n",
    "# dqn.initialize_network()\n",
    "\n",
    "print(\"\\nStarting training...\\n\")\n",
    "dqn.train()\n",
    "print(\"\\nFinished training...\\nCheck out some demonstrations\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "replay_batch = np.array(rd.sample(dqn.replay_buffer,dqn.MINIBATCH_SIZE))\n",
    "nst = []\n",
    "st = []\n",
    "acts = []\n",
    "for y in replay_batch:\n",
    "    nst.append(y[3])\n",
    "    st.append(y[0])\n",
    "    acts.append(y[1])\n",
    "max_Q = np.amax(dqn.target_model.predict(np.array(nst),1))\n",
    "tgts = replay_batch[:,2] + dqn.DISCOUNT_FACTOR * max_Q * (1-replay_batch[:,4])\n",
    "batch_targets = dqn.target_model.predict(np.array(st))\n",
    "                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(batch_targets[1],tgts[1])\n",
    "batch_targets[:,list(replay_batch[:,1])] = tgts\n",
    "for y in range(len(batch_targets)):\n",
    "    batch_targets[y][replay_batch[y,1]] = tgts[y]\n",
    "print(batch_targets[1],replay_batch[1,1])\n",
    "# x = [1,2,3]\n",
    "# batch_targets[x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dqn.model.fit(np.array(st), batch_targets,epochs=1, verbose = 0, workers=8, use_multiprocessing=True)\n",
    "batch_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# average steps\n",
    "results = []\n",
    "for i in range(50):\n",
    "    episode_length = dqn.playPolicy()\n",
    "    print(\"Test steps = \", episode_length)\n",
    "    results.append(episode_length)\n",
    "print(\"Mean steps = \", sum(results) / len(results))\t\n",
    "dqn.env.close()\n",
    "print(\"\\nFinished.\")\n",
    "print(\"\\nCiao, and hasta la vista...\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = 100\n",
    "n = len(dqn.episodic_rewards)//m\n",
    "ep_rwd = np.reshape(dqn.episodic_rewards[:n*m],(n,m))\n",
    "avg_eprwd = np.mean(ep_rwd,axis=1)\n",
    "x_plot = [(i+1)*m for i in range(n)]\n",
    "plt.plot(x_plot, avg_eprwd)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Average Reward for every '+str(m)+' Episodes')\n",
    "plt.title('DQN, Cart-pole')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/subbu/.local/lib/python3.8/site-packages/tensorflow/python/ops/resource_variable_ops.py:1813: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: dqn_weights_final_copy/assets\n"
     ]
    }
   ],
   "source": [
    "dqn.save_model('dqn_weights_final_nobuff_copy')\n",
    "np.save('dqn_ep_rwd_final_nobuff_copy.npy',dqn.episodic_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps:200\n",
      "Steps:200\n",
      "Steps:200\n",
      "Steps:200\n",
      "Steps:200\n",
      "Steps:200\n",
      "Steps:200\n",
      "Steps:200\n",
      "Steps:200\n",
      "Steps:200\n"
     ]
    }
   ],
   "source": [
    "# to visualize it No need to train again\n",
    "\n",
    "dqn_vis = DQN('CartPole-v0')\n",
    "dqn_vis.load_model('dqn_weights_final_nobuff_copy') # loading trained model from memory\n",
    "for i in range(10):\n",
    "    done = False\n",
    "    steps = 0\n",
    "    state = dqn_vis.env.reset()\n",
    "\n",
    "    while not done and steps < 200: \n",
    "        dqn_vis.env.render()\n",
    "        action = np.argmax(dqn_vis.model.predict(np.array([state]))[0])\n",
    "        state, _, done, _ = dqn_vis.env.step(action)\n",
    "        steps += 1\n",
    "        \n",
    "    print('Steps:'+str(steps))\n",
    "\n",
    "dqn_vis.env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# to visualize it No need to train again\n",
    "\n",
    "ep_rwd = np.load('dqn_ep_rwd_final_nobuff_copy.npy') # loading training data from memory\n",
    "avg_eprwd = []\n",
    "tot = 0\n",
    "for i in range(1,100):\n",
    "    avg_eprwd.append(tot/i)\n",
    "    tot += ep_rwd[i]\n",
    "for i in range(100,len(ep_rwd)):\n",
    "    tot += ep_rwd[i]\n",
    "    tot -= ep_rwd[i-100]\n",
    "    avg_eprwd.append(tot/100)\n",
    "plt.plot(ep_rwd,'c',linewidth=0.3)\n",
    "plt.plot(avg_eprwd,'b',linewidth=2)\n",
    "plt.xlabel('Episodes')\n",
    "plt.ylabel('Average Reward for every '+str(100)+' Episodes')\n",
    "plt.title('DQN, Cart-pole')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
